{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:09:29.860919: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-03 15:09:29.860968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-03 15:09:29.861701: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-03 15:09:29.867919: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-03 15:09:30.657743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetSpec, ExecutionConfiguration, DerivaML, Workflow\n",
    "from deriva_ml import MLVocab as vc\n",
    "from deriva_ml.deriva_definitions import ColumnDefinition, BuiltinTypes\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "# Login\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "host = 'dev.eye-ai.org'\n",
    "# host = 'www.eye-ai.org'\n",
    "catalog_id = \"eye-ai\"\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetVersion(major=4, minor=1, patch=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dataset = '2-7P5P'\n",
    "EA.dataset_version(source_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:40,046 - WARNING - File /home/lizhiwei/Repos/eye-ai-exec/notebooks/feature/create_condition_label_feature.ipynb has been modified since last commit. Consider commiting before executing\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Execution RID: https://dev.eye-ai.org/id/eye-ai/5-Y0NE@33D-CMAR-H6NW"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:40,524 - INFO - Materialize bag 2-7P5P... \n",
      "2025-06-03 15:38:41,976 - INFO - Creating new MINID for dataset 2-7P5P\n",
      "2025-06-03 15:38:44,243 - INFO - Downloading dataset minid for catalog: 2-7P5P@4.1.1\n",
      "2025-06-03 15:38:44,278 - INFO - Processing export config file: /tmp/tmpvv_7iu6q/download_spec.json\n",
      "2025-06-03 15:38:44,280 - INFO - Requesting bdbag export at: https://dev.eye-ai.org/deriva/export/bdbag\n",
      "2025-06-03 15:40:36,401 - INFO - Export successful. Service responded with URL list: ['https://identifiers.fair-research.org/hdl:20.500.12582/5NJRtLwtaGP3', 'https://dev.eye-ai.org/deriva/export/bdbag/5cdf977f-0730-40b3-9cd2-64d6ba68abb2']\n",
      "2025-06-03 15:40:36,629 - INFO - Attempting GET from URL: https://eye-ai-shared.s3.amazonaws.com/6656e08709b2f7c0bbed8284fdfb550d/2025-06-03_15.40.34/Dataset_2-7P5P.zip\n",
      "2025-06-03 15:40:36,735 - INFO - File [/home/lizhiwei/Repos/eye-ai-exec/notebooks/feature/Dataset_2-7P5P.zip] transfer complete. 6.421 MB transferred. Elapsed time: 0:00:00.026266.\n",
      "2025-06-03 15:40:36,737 - INFO - Extracting ZIP archived file: /home/lizhiwei/Repos/eye-ai-exec/notebooks/feature/Dataset_2-7P5P.zip\n",
      "2025-06-03 15:40:36,883 - INFO - File /home/lizhiwei/Repos/eye-ai-exec/notebooks/feature/Dataset_2-7P5P.zip was successfully extracted to directory /data/2-7P5P_3a221986a2dd9be58492db1d171af652c4f691affcbd332b4826fef6ea2c8e31/Dataset_2-7P5P\n",
      "2025-06-03 15:40:36,884 - INFO - Validating bag structure: /data/2-7P5P_3a221986a2dd9be58492db1d171af652c4f691affcbd332b4826fef6ea2c8e31/Dataset_2-7P5P\n",
      "2025-06-03 15:40:37,621 - INFO - Checking payload consistency. This can take some time for large bags with many payload files...\n",
      "2025-06-03 15:40:38,375 - INFO - The directory /data/2-7P5P_3a221986a2dd9be58492db1d171af652c4f691affcbd332b4826fef6ea2c8e31/Dataset_2-7P5P is a valid bag structure\n",
      "2025-06-03 15:40:38,378 - INFO - Loading /data/2-7P5P_3a221986a2dd9be58492db1d171af652c4f691affcbd332b4826fef6ea2c8e31/Dataset_2-7P5P\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'/hatrac/Fundus_Bounding_Box/79350e86acb19f13a56a842eab671525.box2-BDBT.txt.txt:caP8FG0_CiH2HyrX8mIh_Q_ejLVOPj75'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m\n\u001b[1;32m     12\u001b[0m config \u001b[38;5;241m=\u001b[39m ExecutionConfiguration(\n\u001b[1;32m     13\u001b[0m     datasets\u001b[38;5;241m=\u001b[39m[DatasetSpec(rid\u001b[38;5;241m=\u001b[39msource_dataset, version\u001b[38;5;241m=\u001b[39mEA\u001b[38;5;241m.\u001b[39mdataset_version(source_dataset), materialize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)],\n\u001b[1;32m     14\u001b[0m     workflow\u001b[38;5;241m=\u001b[39m workflow_instance, \u001b[38;5;66;03m# dev'5-SG9W'\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate Condition_Label for multimodal data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# config = ExecutionConfiguration(\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     datasets=[DatasetSpec(rid=source_dataset, version=EA.dataset_version(source_dataset), materialize=False)],\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     assets=[],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize execution\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m execution \u001b[38;5;241m=\u001b[39m \u001b[43mEA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/deriva_ml_base.py:1014\u001b[0m, in \u001b[0;36mDerivaML.create_execution\u001b[0;34m(self, configuration, dry_run)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an execution object\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03mGiven an execution configuration, initialize the local compute environment to prepare for executing an\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03m    An execution object.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexecution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Execution\n\u001b[0;32m-> 1014\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution \u001b[38;5;241m=\u001b[39m \u001b[43mExecution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/pydantic/_internal/_validate_call.py:39\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/pydantic/_internal/_validate_call.py:136\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_complete__:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_validators()\n\u001b[0;32m--> 136\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/execution.py:261\u001b[0m, in \u001b[0;36mExecution.__init__\u001b[0;34m(self, configuration, ml_object, reload, dry_run)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Create a directory for execution rid so we can recover state in case of a crash.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m execution_root(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ml_object\u001b[38;5;241m.\u001b[39mworking_dir, exec_rid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_rid)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreload\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/execution.py:289\u001b[0m, in \u001b[0;36mExecution._initialize_execution\u001b[0;34m(self, reload)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration\u001b[38;5;241m.\u001b[39mdatasets:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_status(\n\u001b[1;32m    287\u001b[0m         Status\u001b[38;5;241m.\u001b[39minitializing, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaterialize bag \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mrid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m... \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dataset_bag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_rids\u001b[38;5;241m.\u001b[39mappend(dataset\u001b[38;5;241m.\u001b[39mrid)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Update execution info\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/pydantic/_internal/_validate_call.py:39\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/pydantic/_internal/_validate_call.py:136\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_complete__:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_validators()\n\u001b[0;32m--> 136\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/execution.py:391\u001b[0m, in \u001b[0;36mExecution.download_dataset_bag\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;129m@validate_call\u001b[39m(config\u001b[38;5;241m=\u001b[39mConfigDict(arbitrary_types_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_dataset_bag\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DatasetSpec) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DatasetBag:\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a RID to a dataset_table, or a MINID to an existing bag, download the bag file, extract it and validate\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    that all the metadata is correct\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m        the location of the unpacked and validated dataset_table bag and the RID of the bag\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ml_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dataset_bag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_rid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_rid\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/pydantic/_internal/_validate_call.py:39\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/pydantic/_internal/_validate_call.py:136\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_complete__:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_validators()\n\u001b[0;32m--> 136\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/deriva_ml_base.py:780\u001b[0m, in \u001b[0;36mDerivaML.download_dataset_bag\u001b[0;34m(self, dataset, execution_rid)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;129m@validate_call\u001b[39m(config\u001b[38;5;241m=\u001b[39mConfigDict(arbitrary_types_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_dataset_bag\u001b[39m(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    767\u001b[0m     dataset: DatasetSpec,\n\u001b[1;32m    768\u001b[0m     execution_rid: Optional[RID] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    769\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DatasetBag:\n\u001b[1;32m    770\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download a dataset onto the local file system.  Create a MINID for the dataset if one doesn't already exist.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \n\u001b[1;32m    772\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m        for the dataset.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_dataset_bag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_rid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_rid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43msnapshot_catalog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDerivaML\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version_snapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/dataset.py:1006\u001b[0m, in \u001b[0;36mDataset._download_dataset_bag\u001b[0;34m(self, dataset, execution_rid, snapshot_catalog)\u001b[0m\n\u001b[1;32m    999\u001b[0m minid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_minid(dataset, snapshot_catalog\u001b[38;5;241m=\u001b[39msnapshot_catalog)\n\u001b[1;32m   1001\u001b[0m bag_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_materialize_dataset_bag(minid, execution_rid\u001b[38;5;241m=\u001b[39mexecution_rid)\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mmaterialize\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_dataset_minid(minid)\n\u001b[1;32m   1005\u001b[0m )\n\u001b[0;32m-> 1006\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatabaseModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbag_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_working_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_dataset()\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/database_model.py:38\u001b[0m, in \u001b[0;36mDatabaseModelMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bag_path\u001b[38;5;241m.\u001b[39mas_posix() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_paths_loaded:\n\u001b[1;32m     37\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbag_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_paths_loaded[bag_path] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_paths_loaded[bag_path]\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/database_model.py:113\u001b[0m, in \u001b[0;36mDatabaseModel.__init__\u001b[0;34m(self, minid, bag_path, dbase_path)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mml_schema \u001b[38;5;241m=\u001b[39m ML_SCHEMA\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sqlite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating new database for dataset: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_rid,\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbase_file,\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mml_schema]\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/database_model.py:191\u001b[0m, in \u001b[0;36mDatabaseModel._load_sqlite\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbase:\n\u001b[1;32m    187\u001b[0m     object_table \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_localize_asset(o, asset_indexes, asset_map)\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m csv_reader\n\u001b[1;32m    190\u001b[0m     )\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINSERT OR REPLACE INTO \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcolumn_list\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m) VALUES (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvalue_template\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobject_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/database_model.py:188\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    185\u001b[0m column_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m column_names])\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbase:\n\u001b[1;32m    187\u001b[0m     object_table \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_localize_asset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m csv_reader\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbase\u001b[38;5;241m.\u001b[39mexecutemany(\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINSERT OR REPLACE INTO \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) VALUES (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue_template\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    193\u001b[0m         object_table,\n\u001b[1;32m    194\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/deriva_ml/database_model.py:255\u001b[0m, in \u001b[0;36mDatabaseModel._localize_asset\u001b[0;34m(o, indexes, asset_map)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexes:\n\u001b[1;32m    254\u001b[0m     file_column, url_column \u001b[38;5;241m=\u001b[39m indexes\n\u001b[0;32m--> 255\u001b[0m     o[file_column] \u001b[38;5;241m=\u001b[39m \u001b[43masset_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[43m[\u001b[49m\u001b[43murl_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m o[url_column] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(o)\n",
      "\u001b[0;31mKeyError\u001b[0m: '/hatrac/Fundus_Bounding_Box/79350e86acb19f13a56a842eab671525.box2-BDBT.txt.txt:caP8FG0_CiH2HyrX8mIh_Q_ejLVOPj75'"
     ]
    }
   ],
   "source": [
    "# RID of source dataset, if any.\n",
    "source_dataset = '2-7P5P'\n",
    "\n",
    "# EA.add_term(\"Workflow_Type\", term_name=\"Feature_Creation\", \n",
    "#             description=\"Workflow for feature creation\")\n",
    "\n",
    "workflow_instance = EA.create_workflow(\n",
    "    name=\"Create Condition_Label feature\",\n",
    "    workflow_type=\"Feature_Creation\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=[DatasetSpec(rid=source_dataset, version=EA.dataset_version(source_dataset), materialize=False)],\n",
    "    workflow= workflow_instance, # dev'5-SG9W'\n",
    "    description=\"Create Condition_Label for multimodal data\")\n",
    "\n",
    "# Initialize execution\n",
    "execution = EA.create_execution(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_cv = EA.create_vocabulary(vocab_name='Severity_Label', schema='eye-ai')\n",
    "severity_feature = EA.create_feature(target_table='Clinical_Records', feature_name='Glaucoma_Severity', \n",
    "                  terms=[severity_cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deriva_ml.feature.Clinical_RecordsFeatureGlaucoma_Severity"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "severity_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GS, Mild Glaucoma, Moderate Glaucoma, Severe Glaucoma, Unspecified/Indeterminate Glaucoma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
