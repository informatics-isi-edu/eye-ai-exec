{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f6e9b-57c2-4dd5-82bc-5834f32b1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     !pip install deriva\n",
    "#     !pip install bdbag\n",
    "#     !pip install --upgrade --force pydantic\n",
    "#     !pip install git+https://github.com/informatics-isi-edu/deriva-ml git+https://github.com/informatics-isi-edu/eye-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235d595-c68f-4146-a0b7-fb2c754c9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c603cb-e1e1-4c90-8a91-a3e44451cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "# import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c4d60-a01f-4b16-816f-228dc849ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b7779-06d0-4678-adbe-a411da14ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "\n",
    "cache_dir = '/data'        # Directory in which to cache materialized BDBags for datasets\n",
    "working_dir = '/data'    # Directory in which to place output files for later upload.\n",
    "\n",
    "configuration_rid = \"2-C988\" #\"2-C8ZG\" # rid\n",
    "# Change the confi_file with bag_url=[\"minid: train\", \"minid: Valid\", \"minid: test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee651c-3c59-4f75-8f8b-2f8f41d79f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c50050-65da-4130-b56a-1d3fde5959b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initiate an Execution\n",
    "configuration_records = EA.execution_init(configuration_rid=configuration_rid)\n",
    "configuration_records.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d005a2a-2edc-4d35-b508-969f2f2be5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ebba9-43da-48e3-848d-f60636ba0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=str(configuration_records.bag_paths[0]) \n",
    "\n",
    "print(test_dir)\n",
    "\n",
    "subject_csv_path = os.path.join(test_dir, 'data', 'Image.csv')\n",
    "\n",
    "subject_df = pd.read_csv(subject_csv_path)\n",
    "subject_df = subject_df[subject_df.Image_Angle_Vocab == '2SK6']\n",
    "subject_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504515e-0656-41a4-8398-2b127723ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configure\n",
    "dataset_rid = \"2-277M\" # @param {type:\"string\"}\n",
    "diagnosis_tag_rid = \"2-35RM\" # @param {type:\"string\"}\n",
    "compare_value = \"Image_Quality\" #@param {type:\"string\"}[\"Diagnosis\", \"Image_Quality\", \"Cup/Disk_Ratio\"]\n",
    "initial_diagnosis_tag_rid = \"C1T4\"\n",
    "angle_two_rid = '2SK6'\n",
    "\n",
    "# @title Example of Graded Test Dataset\n",
    "\n",
    "Graded_test_initial_diag = EA.image_tall(dataset_rid, initial_diagnosis_tag_rid)\n",
    "Graded_test_grader_diag = EA.image_tall(dataset_rid, diagnosis_tag_rid)\n",
    "# Graded_test_gold = EA.image_tall(dataset_rid, \"2-5GXP\")\n",
    "long, wide = EA.reshape_table([Graded_test_initial_diag, Graded_test_grader_diag], compare_value)\n",
    "\n",
    "\n",
    "long = long[long.Full_Name\t== 'Van Nguyen']\n",
    "\n",
    "long.reset_index(inplace=True)\n",
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6768aa-627f-4713-b988-d1d1ab4bbd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f7d22-869d-48c5-b088-783345d66e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path, PurePath\n",
    "from tqdm import tqdm\n",
    "\n",
    "def crop_to_eye(im):\n",
    "    mask = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    cropped_im = im[y:y + h, x:x + w]\n",
    "    return cropped_im\n",
    "\n",
    "def create_LACDHS_quality_test_dataset(test_dir: str, output_dir: str, long_df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Creates a test dataset for LACDHS image quality classification by organizing images into folders\n",
    "    based on their Image_Quality from the provided long DataFrame, filtered for Field 2 images and cropped to the eye.\n",
    "    Maps 'Good' to '690J' and 'Bad' to '692J'.\n",
    "\n",
    "    Parameters:\n",
    "    - test_dir (str): Path to the raw test dataset bag.\n",
    "    - output_dir (str): Path to the output directory where the organized dataset will be created.\n",
    "    - long_df (pd.DataFrame): DataFrame containing Image_Quality information.\n",
    "\n",
    "    Returns:\n",
    "    - str: The path to the test directory.\n",
    "    \"\"\"\n",
    "    # Define the class mapping\n",
    "    class_mapping = {'Good': '690J', 'Bad': '692J'}\n",
    "    \n",
    "    # Read the Image CSV\n",
    "    image_csv_path = os.path.join(test_dir, 'data', 'Image.csv')\n",
    "    image_df = pd.read_csv(image_csv_path)\n",
    "    \n",
    "    # Filter for Field 2 images\n",
    "    image_df = image_df[image_df['Image_Angle_Vocab'] == \"2SK6\"]\n",
    "    \n",
    "    # Merge dataframes, keeping only the rows that match with long_df\n",
    "    merged_df = image_df.merge(long_df[['Image', 'Image_Quality']], left_on='RID', right_on='Image', how='inner')\n",
    "    \n",
    "    # Map 'Good' and 'Bad' to their corresponding codes\n",
    "    merged_df['Image_Quality_Code'] = merged_df['Image_Quality'].map(class_mapping)\n",
    "    \n",
    "    # Filter out any rows where mapping didn't work (i.e., Image_Quality was neither 'Good' nor 'Bad')\n",
    "    merged_df = merged_df.dropna(subset=['Image_Quality_Code'])\n",
    "    \n",
    "    image_root_path = os.path.join(test_dir, 'data', 'assets', 'Image')\n",
    "    \n",
    "    # Add tqdm progress bar\n",
    "    for _, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=\"Processing test dataset\"):\n",
    "        quality_code = row['Image_Quality_Code']\n",
    "        filename = row['Filename']\n",
    "        src_path = os.path.join(image_root_path, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        img = cv2.imread(src_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {src_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Crop the image to the eye\n",
    "        cropped_img = crop_to_eye(img)\n",
    "        \n",
    "        dst_dir = os.path.join(output_dir, 'test', quality_code)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(dst_dir, filename)\n",
    "        \n",
    "        # Save the cropped image\n",
    "        cv2.imwrite(dst_path, cropped_img)\n",
    "    \n",
    "    # Print the count of images in each category\n",
    "    print(\"\\nImage count for test dataset:\")\n",
    "    print(merged_df['Image_Quality_Code'].value_counts())\n",
    "\n",
    "    test_path = os.path.join(output_dir, 'test')\n",
    "    return test_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fa7a6-3fa2-4218-b526-5f142a328096",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_records.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8dc53-3b7f-45b9-94c7-04cdabf12a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Data Preprocessing (Filtering Image.csv for just Field_2 Images)\n",
    "\n",
    "test_dir = str(configuration_records.bag_paths[0])\n",
    "\n",
    "# Call the create_LACDHS_quality_test_dataset function\n",
    "test_path = create_LACDHS_quality_test_dataset(\n",
    "    test_dir=test_dir,\n",
    "    output_dir=str(configuration_records.working_dir),\n",
    "    long_df = long\n",
    ") \n",
    "\n",
    "# Print the paths to verify\n",
    "print(\"Test dataset path:\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4788d5-e8af-4883-9099-e35325b4c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "def analyze_lacdhs_angle_dataset(base_path):\n",
    "    main_folders = ['test'] #, \n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nAnalyzing {main_folder} folder:\")\n",
    "        \n",
    "        total_files = 0\n",
    "        for angle_folder in os.listdir(main_folder_path):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            if os.path.isdir(angle_folder_path):\n",
    "                file_count = count_files(angle_folder_path)\n",
    "                print(f\"  {angle_folder}: {file_count} images\")\n",
    "                total_files += file_count\n",
    "        \n",
    "        print(f\"Total images in {main_folder}: {total_files}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "analyze_lacdhs_angle_dataset(base_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839e9a3-3752-44b0-aed5-3e818b47f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_lacdhs_quality_dataset(base_path, samples_per_angle=6):\n",
    "    main_folders = ['test'] #, 'test'\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nVisualizing samples from {main_folder} folder:\")\n",
    "        \n",
    "        angle_folders = [f for f in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, f))]\n",
    "        \n",
    "        # Calculate grid size\n",
    "        n_angles = len(angle_folders)\n",
    "        n_cols = samples_per_angle\n",
    "        n_rows = n_angles\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3.5))\n",
    "        fig.suptitle(f'Sample Images from {main_folder.capitalize()} Set', fontsize=16)\n",
    "        \n",
    "        for i, angle_folder in enumerate(angle_folders):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            image_files = [f for f in os.listdir(angle_folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            if len(image_files) < samples_per_angle:\n",
    "                print(f\"Warning: Not enough images in {angle_folder}. Using all available images.\")\n",
    "                selected_files = image_files\n",
    "            else:\n",
    "                selected_files = random.sample(image_files, samples_per_angle)\n",
    "            \n",
    "            for j, image_file in enumerate(selected_files):\n",
    "                img_path = os.path.join(angle_folder_path, image_file)\n",
    "                img = Image.open(img_path)\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "                # Add image filename as title for each subplot\n",
    "                axes[i, j].set_title(image_file, fontsize=8)\n",
    "                \n",
    "                if j == 0:\n",
    "                    axes[i, j].set_ylabel(angle_folder, rotation=0, labelpad=40, va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95, bottom=0.05, left=0.2, right=0.98)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print confirmation of angles\n",
    "        print(f\"Angles in {main_folder} set:\")\n",
    "        for angle in angle_folders:\n",
    "            print(f\"  - {angle}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "# visualize_lacdhs_quality_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab84cbc-bac9-4909-9923-3a2bf27f8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = str(EA.working_dir) + \"/Execution_Assets/\" + configuration_records.vocabs['Execution_Asset_Type'][0].name\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b49509-32d4-47b7-88d3-f224a00b01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbfb90-53ce-4730-9721-b35d11458ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path = str(configuration_records.assets_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f135924-3e0f-4b71-beb5-173a7a9533e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00467376-8ed7-43df-a31e-b16e341183f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = str(configuration_records.assets_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2ad33-1192-41ca-9940-f295e0182b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39d015-c811-48e4-92f6-4b1db0f4d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(best_hyper_parameters_json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e46e2f-4401-41a3-a75b-1437f8735477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Execute Evaluation algorithm\n",
    "\n",
    "from eye_ai.models.vgg19_lacdhs_quality_predict import predict_and_evaluate\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "    predict_and_evaluate(\n",
    "        model_path=model_path,\n",
    "        image_path=test_path,\n",
    "        output_dir=output_path,\n",
    "        best_hyperparameters_json_path=best_hyper_parameters_json_path\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a3f3d-d49d-4899-af5a-c1565de9a28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a367dd-445a-41f9-bc97-354e6def6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Save Execution Assets (model) and Metadata\n",
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bb207-df9b-4ddc-933c-045eb08388fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7460350-738f-4ab0-aaef-a7a65ed2b303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
