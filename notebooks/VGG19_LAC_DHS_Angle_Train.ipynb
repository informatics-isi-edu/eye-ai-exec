{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3f6e9b-57c2-4dd5-82bc-5834f32b1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     !pip install deriva\n",
    "#     !pip install bdbag\n",
    "#     !pip install --upgrade --force pydantic\n",
    "#     !pip install git+https://github.com/informatics-isi-edu/deriva-ml git+https://github.com/informatics-isi-edu/eye-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d235d595-c68f-4146-a0b7-fb2c754c9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c603cb-e1e1-4c90-8a91-a3e44451cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "# import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633c4d60-a01f-4b16-816f-228dc849ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:55:42,707 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 15:55:42,708 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1b7779-06d0-4678-adbe-a411da14ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "\n",
    "cache_dir = '/data'        # Directory in which to cache materialized BDBags for datasets\n",
    "working_dir = '/data'    # Directory in which to place output files for later upload.\n",
    "\n",
    "configuration_rid = \"2-C8PJ\" # rid\n",
    "# Change the confi_file with bag_url=[\"minid: train\", \"minid: Valid\", \"minid: test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ee651c-3c59-4f75-8f8b-2f8f41d79f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:55:42,748 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 15:55:42,749 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    }
   ],
   "source": [
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c50050-65da-4130-b56a-1d3fde5959b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 15:55:43,118 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json] transfer successful. 0.94 KB transferred. Elapsed time: 0:00:00.000068.\n",
      "2024-06-28 15:55:43,118 - INFO - Verifying SHA256 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json]\n",
      "2024-06-28 15:55:43,136 - INFO - Configuration validation successful!\n",
      "2024-06-28 15:55:49,282 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json] transfer successful. 0.69 KB transferred. Elapsed time: 0:00:00.000053.\n",
      "2024-06-28 15:55:49,282 - INFO - Verifying SHA256 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json]\n",
      "2024-06-28 15:55:49,530 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv] transfer successful. 0.34 KB transferred. Elapsed time: 0:00:00.000059.\n",
      "2024-06-28 15:55:49,530 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv]\n",
      "2024-06-28 15:55:49,807 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv] transfer successful. 0.15 KB transferred. Elapsed time: 0:00:00.000076.\n",
      "2024-06-28 15:55:49,807 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'caching_dir': PosixPath('/data'),\n",
       " 'working_dir': PosixPath('/data/sreenidhi/EyeAI_working'),\n",
       " 'vocabs': {'Workflow_Type': [{'name': 'VGG19_Catalog_Model_LACDHS_angle_training',\n",
       "    'rid': '2-C8PP'}],\n",
       "  'Execution_Asset_Type': [{'name': 'VGG19_Catalog_Model_LACDHS_angle_training',\n",
       "    'rid': '2-C8PR'}]},\n",
       " 'execution_rid': '2-C8V0',\n",
       " 'workflow_rid': '2-C8PT',\n",
       " 'bag_paths': [PosixPath('/data/2-277G_6aa1a6861eee5a79bce4bf071065355f95a066c2a1ff326089d43048a7e0f185/Dataset_2-277G'),\n",
       "  PosixPath('/data/2-277J_81c873a311aa6a67cf2eef44bd9056cb19181b299a6e44327ea3553616f18725/Dataset_2-277J'),\n",
       "  PosixPath('/data/2-277M_8c4b855c2752e098580a5bb0d1b63a8cedde4462805fe74cddc912a72fb39963/Dataset_2-277M')],\n",
       " 'assets_paths': [PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'),\n",
       "  PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv'),\n",
       "  PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv')],\n",
       " 'configuration_path': PosixPath('/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Initiate an Execution\n",
    "configuration_records = EA.execution_init(configuration_rid=configuration_rid)\n",
    "configuration_records.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d005a2a-2edc-4d35-b508-969f2f2be5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigurationRecord(caching_dir=PosixPath('/data'), working_dir=PosixPath('/data/sreenidhi/EyeAI_working'), vocabs={'Workflow_Type': [Term(name='VGG19_Catalog_Model_LACDHS_angle_training', rid='2-C8PP')], 'Execution_Asset_Type': [Term(name='VGG19_Catalog_Model_LACDHS_angle_training', rid='2-C8PR')]}, execution_rid='2-C8V0', workflow_rid='2-C8PT', bag_paths=[PosixPath('/data/2-277G_6aa1a6861eee5a79bce4bf071065355f95a066c2a1ff326089d43048a7e0f185/Dataset_2-277G'), PosixPath('/data/2-277J_81c873a311aa6a67cf2eef44bd9056cb19181b299a6e44327ea3553616f18725/Dataset_2-277J'), PosixPath('/data/2-277M_8c4b855c2752e098580a5bb0d1b63a8cedde4462805fe74cddc912a72fb39963/Dataset_2-277M')], assets_paths=[PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'), PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv'), PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv')], configuration_path=PosixPath('/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff0eff0-f063-412c-b382-01d0a82ab33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_train = pd.read_csv(configuration_records.assets_paths[1])['ID'].to_list()\n",
    "exclude_valid = pd.read_csv(configuration_records.assets_paths[2])['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f6175f-2fc7-48b5-b2a7-6bc537e7857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def create_LACDHS_angle_dataset(train_dir: str, validation_dir: str, test_dir: str, output_dir: str, exclude_train: list = [], exclude_valid: list = []) -> tuple:\n",
    "    \"\"\"\n",
    "    Creates a dataset for LACDHS angle classification by organizing images into train, valid, and test folders\n",
    "    based on their Image_Angle_Vocab.\n",
    "\n",
    "    Parameters:\n",
    "    - train_dir (str): Path to the raw train dataset bag.\n",
    "    - validation_dir (str): Path to the raw validation dataset bag.\n",
    "    - test_dir (str): Path to the raw test dataset bag.\n",
    "    - output_dir (str): Path to the output directory where the organized dataset will be created.\n",
    "    - exclude_train (list): List of image RIDs to exclude from the train set.\n",
    "    - exclude_valid (list): List of image RIDs to exclude from the validation set.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the paths to the train, validation, and test directories.\n",
    "    \"\"\"\n",
    "    def process_dataset(bag_path: str, output_subdir: str, exclude_list: list = []):\n",
    "        image_csv_path = os.path.join(bag_path, 'data', 'Image.csv')\n",
    "        image_df = pd.read_csv(image_csv_path)\n",
    "        image_root_path = os.path.join(bag_path, 'data', 'assets', 'Image')\n",
    "\n",
    "        for _, row in image_df.iterrows():\n",
    "            if row['RID'] not in exclude_list:\n",
    "                angle = row['Image_Angle_Vocab']\n",
    "                filename = row['Filename']\n",
    "                src_path = os.path.join(image_root_path, filename)\n",
    "                dst_dir = os.path.join(output_dir, output_subdir, angle)\n",
    "                os.makedirs(dst_dir, exist_ok=True)\n",
    "                dst_path = os.path.join(dst_dir, filename)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    # Process train dataset\n",
    "    process_dataset(train_dir, 'train', exclude_train)\n",
    "\n",
    "    # Process validation dataset\n",
    "    process_dataset(validation_dir, 'valid', exclude_valid)\n",
    "\n",
    "    # Process test dataset\n",
    "    process_dataset(test_dir, 'test')\n",
    "\n",
    "    train_path = os.path.join(output_dir, 'train')\n",
    "    valid_path = os.path.join(output_dir, 'valid')\n",
    "    test_path = os.path.join(output_dir, 'test')\n",
    "\n",
    "    return train_path, valid_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "334ed1a5-4a9c-4478-a110-6555a5066622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/sreenidhi/EyeAI_working')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_records.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1076c83-5acc-4668-bcef-bd00998ace6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset path: /data/sreenidhi/EyeAI_working/train\n",
      "Validation dataset path: /data/sreenidhi/EyeAI_working/valid\n",
      "Test dataset path: /data/sreenidhi/EyeAI_working/test\n"
     ]
    }
   ],
   "source": [
    "# @title Data Preprocessing (Filtering Image.csv for just Field_2 Images)\n",
    "train_dir = configuration_records.bag_paths[0] # path to the raw train dataset\n",
    "validation_dir = configuration_records.bag_paths[1]\n",
    "test_dir = configuration_records.bag_paths[2]\n",
    "\n",
    "exclude_train = pd.read_csv(configuration_records.assets_paths[1])['ID'].to_list()\n",
    "exclude_valid = pd.read_csv(configuration_records.assets_paths[2])['ID'].to_list()\n",
    "\n",
    "# Call the create_LACDHS_angle_dataset function\n",
    "train_path, valid_path, test_path = create_LACDHS_angle_dataset(\n",
    "    train_dir=str(train_dir),\n",
    "    validation_dir=str(validation_dir),\n",
    "    test_dir=str(test_dir),\n",
    "    output_dir=str(configuration_records.working_dir),\n",
    "    exclude_train=exclude_train,\n",
    "    exclude_valid=exclude_valid\n",
    ")\n",
    "\n",
    "# Print the paths to verify\n",
    "print(\"Train dataset path:\", train_path)\n",
    "print(\"Validation dataset path:\", valid_path)\n",
    "print(\"Test dataset path:\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45475801-2b48-4930-9fe2-befc1a79423d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b600173-42b1-49d1-8602-2dac5ad97f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing train folder:\n",
      "  2SK8: 9505 images\n",
      "  2SK6: 8996 images\n",
      "  2SK4: 8666 images\n",
      "Total images in train: 27167\n",
      "\n",
      "Analyzing valid folder:\n",
      "  2SK8: 3175 images\n",
      "  2SK6: 3002 images\n",
      "  2SK4: 2887 images\n",
      "Total images in valid: 9064\n",
      "\n",
      "Analyzing test folder:\n",
      "  2SK6: 1094 images\n",
      "  2SK4: 1042 images\n",
      "  2SK8: 1152 images\n",
      "Total images in test: 3288\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "def analyze_lacdhs_angle_dataset(base_path):\n",
    "    main_folders = ['train', 'valid', 'test']\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nAnalyzing {main_folder} folder:\")\n",
    "        \n",
    "        total_files = 0\n",
    "        for angle_folder in os.listdir(main_folder_path):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            if os.path.isdir(angle_folder_path):\n",
    "                file_count = count_files(angle_folder_path)\n",
    "                print(f\"  {angle_folder}: {file_count} images\")\n",
    "                total_files += file_count\n",
    "        \n",
    "        print(f\"Total images in {main_folder}: {total_files}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "analyze_lacdhs_angle_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "380f149a-dbf7-44e3-8d15-0daa2f3158cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_lacdhs_angle_dataset(base_path, samples_per_angle=6):\n",
    "    main_folders = ['train', 'valid', 'test']\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nVisualizing samples from {main_folder} folder:\")\n",
    "        \n",
    "        angle_folders = [f for f in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, f))]\n",
    "        \n",
    "        # Calculate grid size\n",
    "        n_angles = len(angle_folders)\n",
    "        n_cols = samples_per_angle\n",
    "        n_rows = n_angles\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3.5))\n",
    "        fig.suptitle(f'Sample Images from {main_folder.capitalize()} Set', fontsize=16)\n",
    "        \n",
    "        for i, angle_folder in enumerate(angle_folders):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            image_files = [f for f in os.listdir(angle_folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            if len(image_files) < samples_per_angle:\n",
    "                print(f\"Warning: Not enough images in {angle_folder}. Using all available images.\")\n",
    "                selected_files = image_files\n",
    "            else:\n",
    "                selected_files = random.sample(image_files, samples_per_angle)\n",
    "            \n",
    "            for j, image_file in enumerate(selected_files):\n",
    "                img_path = os.path.join(angle_folder_path, image_file)\n",
    "                img = Image.open(img_path)\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "                # Add image filename as title for each subplot\n",
    "                axes[i, j].set_title(image_file, fontsize=8)\n",
    "                \n",
    "                if j == 0:\n",
    "                    axes[i, j].set_ylabel(angle_folder, rotation=0, labelpad=40, va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95, bottom=0.05, left=0.2, right=0.98)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print confirmation of angles\n",
    "        print(f\"Angles in {main_folder} set:\")\n",
    "        for angle in angle_folders:\n",
    "            print(f\"  - {angle}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "# visualize_lacdhs_angle_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e6312b8-9faa-4ea5-9f2e-4de7380ffb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = str(EA.working_dir) + \"/Execution_Assets/\" + configuration_records.vocabs['Execution_Asset_Type'][0].name\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49177652-13f5-4464-99fe-bc5a240e2557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a799f240-96f7-473a-b9b4-3feb8cf6e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path = str(configuration_records.assets_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f93ec10b-be38-404c-9a96-4df4f0e3ca1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper_parameters_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42b57610-80ee-43a1-9d43-c27f4acf3896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"rotation_range\": -6,\n",
      "    \"width_shift_range\": 0.049283662164352315,\n",
      "    \"height_shift_range\": 0.062129040368351915,\n",
      "    \"horizontal_flip\": true,\n",
      "    \"vertical_flip\": true,\n",
      "    \"zoom_range\": -0.03493437617512693,\n",
      "    \"brightness_range\": 0.016808387649284325,\n",
      "    \"use_class_weights\": true,\n",
      "    \"pooling\": \"global_average\",\n",
      "    \"dense_layers\": 2,\n",
      "    \"units_layer_0\": 512,\n",
      "    \"activation_func_0\": \"sigmoid\",\n",
      "    \"batch_norm_0\": true,\n",
      "    \"dropout_0\": 0.10646478371824658,\n",
      "    \"units_layer_1\": 64,\n",
      "    \"activation_func_1\": \"relu\",\n",
      "    \"batch_norm_1\": false,\n",
      "    \"dropout_1\": 0.2830490167548361,\n",
      "    \"fine_tune_at\": 0,\n",
      "    \"fine_tuning_learning_rate_adam\": 1.1688327470992886e-05,\n",
      "    \"batch_size\": 32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(best_hyper_parameters_json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeccf0bb-c5b7-4d04-a84c-32e98e9870b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 16:00:58.584777: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-28 16:00:58.584838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-28 16:00:58.723003: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-28 16:00:59.007862: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-28 16:01:01.021472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27167 images belonging to 3 classes.\n",
      "Found 9064 images belonging to 3 classes.\n",
      "Found 3288 images belonging to 3 classes.\n",
      "train_generator.class_indices :  {'2SK6': 0, '2SK4': 1, '2SK8': 2}\n",
      "validation_generator.class_indices :  {'2SK6': 0, '2SK4': 1, '2SK8': 2}\n",
      "test_generator.class_indices :  {'2SK6': 0, '2SK4': 1, '2SK8': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 16:01:03.495065: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:03.999528: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.003268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.007446: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.011020: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.014438: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.209688: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.211158: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.212561: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-28 16:01:04.213884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 16:01:12.468554: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-06-28 16:01:19.664768: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fb17a99e0d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-28 16:01:19.664812: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-06-28 16:01:19.693978: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719615679.946022   30934 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849/849 [==============================] - 729s 831ms/step - loss: 0.2154 - roc_auc_score: 0.9846 - accuracy_score: 0.9379 - f1_score_metric: 0.9345 - val_loss: 0.1244 - val_roc_auc_score: 0.9935 - val_accuracy_score: 0.9625 - val_f1_score_metric: 0.9604\n",
      "Epoch 2/100\n",
      "849/849 [==============================] - 639s 747ms/step - loss: 0.1409 - roc_auc_score: 0.9913 - accuracy_score: 0.9617 - f1_score_metric: 0.9596 - val_loss: 0.1116 - val_roc_auc_score: 0.9945 - val_accuracy_score: 0.9654 - val_f1_score_metric: 0.9634\n",
      "Epoch 3/100\n",
      "849/849 [==============================] - 647s 758ms/step - loss: 0.1305 - roc_auc_score: 0.9922 - accuracy_score: 0.9636 - f1_score_metric: 0.9614 - val_loss: 0.1068 - val_roc_auc_score: 0.9947 - val_accuracy_score: 0.9669 - val_f1_score_metric: 0.9659\n",
      "Epoch 4/100\n",
      "849/849 [==============================] - 633s 744ms/step - loss: 0.1252 - roc_auc_score: 0.9929 - accuracy_score: 0.9642 - f1_score_metric: 0.9620 - val_loss: 0.1225 - val_roc_auc_score: 0.9939 - val_accuracy_score: 0.9623 - val_f1_score_metric: 0.9608\n",
      "Epoch 5/100\n",
      "849/849 [==============================] - 644s 753ms/step - loss: 0.1223 - roc_auc_score: 0.9930 - accuracy_score: 0.9641 - f1_score_metric: 0.9618 - val_loss: 0.1067 - val_roc_auc_score: 0.9948 - val_accuracy_score: 0.9655 - val_f1_score_metric: 0.9638\n",
      "Epoch 6/100\n",
      "849/849 [==============================] - 634s 744ms/step - loss: 0.1223 - roc_auc_score: 0.9931 - accuracy_score: 0.9649 - f1_score_metric: 0.9625 - val_loss: 0.1054 - val_roc_auc_score: 0.9947 - val_accuracy_score: 0.9686 - val_f1_score_metric: 0.9672\n",
      "Epoch 7/100\n",
      "849/849 [==============================] - 637s 748ms/step - loss: 0.1161 - roc_auc_score: 0.9936 - accuracy_score: 0.9643 - f1_score_metric: 0.9622 - val_loss: 0.1172 - val_roc_auc_score: 0.9943 - val_accuracy_score: 0.9665 - val_f1_score_metric: 0.9646\n",
      "Epoch 8/100\n",
      "849/849 [==============================] - 627s 736ms/step - loss: 0.1124 - roc_auc_score: 0.9941 - accuracy_score: 0.9660 - f1_score_metric: 0.9642 - val_loss: 0.1128 - val_roc_auc_score: 0.9936 - val_accuracy_score: 0.9671 - val_f1_score_metric: 0.9651\n",
      "Epoch 9/100\n",
      "849/849 [==============================] - 638s 749ms/step - loss: 0.1106 - roc_auc_score: 0.9941 - accuracy_score: 0.9665 - f1_score_metric: 0.9644 - val_loss: 0.0987 - val_roc_auc_score: 0.9958 - val_accuracy_score: 0.9680 - val_f1_score_metric: 0.9664\n",
      "Epoch 10/100\n",
      "849/849 [==============================] - 636s 744ms/step - loss: 0.1081 - roc_auc_score: 0.9945 - accuracy_score: 0.9666 - f1_score_metric: 0.9645 - val_loss: 0.1399 - val_roc_auc_score: 0.9943 - val_accuracy_score: 0.9647 - val_f1_score_metric: 0.9626\n",
      "Epoch 11/100\n",
      "849/849 [==============================] - 632s 742ms/step - loss: 0.1063 - roc_auc_score: 0.9948 - accuracy_score: 0.9680 - f1_score_metric: 0.9660 - val_loss: 0.1087 - val_roc_auc_score: 0.9954 - val_accuracy_score: 0.9671 - val_f1_score_metric: 0.9662\n",
      "Epoch 12/100\n",
      "849/849 [==============================] - 639s 748ms/step - loss: 0.1058 - roc_auc_score: 0.9950 - accuracy_score: 0.9676 - f1_score_metric: 0.9662 - val_loss: 0.1009 - val_roc_auc_score: 0.9950 - val_accuracy_score: 0.9687 - val_f1_score_metric: 0.9671\n",
      "Epoch 13/100\n",
      "849/849 [==============================] - 631s 741ms/step - loss: 0.0983 - roc_auc_score: 0.9955 - accuracy_score: 0.9682 - f1_score_metric: 0.9664 - val_loss: 0.1065 - val_roc_auc_score: 0.9957 - val_accuracy_score: 0.9651 - val_f1_score_metric: 0.9631\n",
      "Epoch 14/100\n",
      "849/849 [==============================] - 633s 743ms/step - loss: 0.0985 - roc_auc_score: 0.9956 - accuracy_score: 0.9686 - f1_score_metric: 0.9670 - val_loss: 0.1007 - val_roc_auc_score: 0.9958 - val_accuracy_score: 0.9702 - val_f1_score_metric: 0.9673\n",
      "Epoch 15/100\n",
      "849/849 [==============================] - 635s 746ms/step - loss: 0.0950 - roc_auc_score: 0.9961 - accuracy_score: 0.9695 - f1_score_metric: 0.9676 - val_loss: 0.1088 - val_roc_auc_score: 0.9953 - val_accuracy_score: 0.9683 - val_f1_score_metric: 0.9663\n",
      "Epoch 16/100\n",
      "849/849 [==============================] - 632s 742ms/step - loss: 0.0928 - roc_auc_score: 0.9961 - accuracy_score: 0.9699 - f1_score_metric: 0.9681 - val_loss: 0.1016 - val_roc_auc_score: 0.9954 - val_accuracy_score: 0.9684 - val_f1_score_metric: 0.9666\n",
      "Epoch 17/100\n",
      "849/849 [==============================] - 639s 748ms/step - loss: 0.0917 - roc_auc_score: 0.9963 - accuracy_score: 0.9704 - f1_score_metric: 0.9685 - val_loss: 0.1159 - val_roc_auc_score: 0.9955 - val_accuracy_score: 0.9695 - val_f1_score_metric: 0.9674\n",
      "Epoch 18/100\n",
      "849/849 [==============================] - 636s 747ms/step - loss: 0.0910 - roc_auc_score: 0.9965 - accuracy_score: 0.9705 - f1_score_metric: 0.9685 - val_loss: 0.1131 - val_roc_auc_score: 0.9937 - val_accuracy_score: 0.9688 - val_f1_score_metric: 0.9673\n",
      "Epoch 19/100\n",
      "849/849 [==============================] - 627s 735ms/step - loss: 0.0859 - roc_auc_score: 0.9967 - accuracy_score: 0.9713 - f1_score_metric: 0.9696 - val_loss: 0.1028 - val_roc_auc_score: 0.9954 - val_accuracy_score: 0.9697 - val_f1_score_metric: 0.9681\n",
      "Epoch 19: early stopping\n",
      "103/103 [==============================] - 134s 1s/step - loss: 0.1592 - roc_auc_score: 0.9909 - accuracy_score: 0.9644 - f1_score_metric: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 19:30:57,589 - INFO - Test results - [0.1592140644788742, 0.9909060597419739, 0.9644160866737366, 0.9628030061721802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Eval results: [0.1592140644788742, 0.9909060597419739, 0.9644160866737366, 0.9628030061721802]\n",
      "103/103 [==============================] - 124s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 19:33:03,124 - INFO - Detailed Classification Report:\n",
      "2024-06-28 19:33:03,125 - INFO - {\n",
      "  \"2SK6\": {\n",
      "    \"precision\": 0.31267345050878814,\n",
      "    \"recall\": 0.30895795246800734,\n",
      "    \"f1-score\": 0.31080459770114943,\n",
      "    \"support\": 1094.0\n",
      "  },\n",
      "  \"2SK4\": {\n",
      "    \"precision\": 0.3323727185398655,\n",
      "    \"recall\": 0.33205374280230326,\n",
      "    \"f1-score\": 0.33221315410465674,\n",
      "    \"support\": 1042.0\n",
      "  },\n",
      "  \"2SK8\": {\n",
      "    \"precision\": 0.32847341337907376,\n",
      "    \"recall\": 0.3324652777777778,\n",
      "    \"f1-score\": 0.33045729076790337,\n",
      "    \"support\": 1152.0\n",
      "  },\n",
      "  \"accuracy\": 0.3245133819951338,\n",
      "  \"macro avg\": {\n",
      "    \"precision\": 0.32450652747590913,\n",
      "    \"recall\": 0.3244923243493628,\n",
      "    \"f1-score\": 0.3244916808579032,\n",
      "    \"support\": 3288.0\n",
      "  },\n",
      "  \"weighted avg\": {\n",
      "    \"precision\": 0.32445209847562256,\n",
      "    \"recall\": 0.3245133819951338,\n",
      "    \"f1-score\": 0.32447479787917716,\n",
      "    \"support\": 3288.0\n",
      "  }\n",
      "}\n",
      "2024-06-28 19:33:03,130 - INFO - Macro F1 Score: 0.3244916808579032\n",
      "2024-06-28 19:33:03,131 - INFO - Weighted F1 Score: 0.32447479787917716\n",
      "/home/sreenidhi/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-06-28 19:33:03,751 - INFO - VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips Model trained, Model and training history are saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# @title Execute Training algorithm\n",
    "\n",
    "from eye_ai.models.vgg19_lacdhs_angle_train import main\n",
    "\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "  main(train_path=train_path,\n",
    "       valid_path=valid_path, \n",
    "       test_path=test_path, \n",
    "       output_path=output_path,\n",
    "       best_hyperparameters_json_path=best_hyper_parameters_json_path,\n",
    "       model_name=\"VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips\"\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b860a35-6c33-489c-bca1-fff1c3fe2eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rotation_range': -6,\n",
       " 'width_shift_range': 0.049283662164352315,\n",
       " 'height_shift_range': 0.062129040368351915,\n",
       " 'horizontal_flip': True,\n",
       " 'vertical_flip': True,\n",
       " 'zoom_range': -0.03493437617512693,\n",
       " 'brightness_range': 0.016808387649284325,\n",
       " 'use_class_weights': True,\n",
       " 'pooling': 'global_average',\n",
       " 'dense_layers': 2,\n",
       " 'units_layer_0': 512,\n",
       " 'activation_func_0': 'sigmoid',\n",
       " 'batch_norm_0': True,\n",
       " 'dropout_0': 0.10646478371824658,\n",
       " 'units_layer_1': 64,\n",
       " 'activation_func_1': 'relu',\n",
       " 'batch_norm_1': False,\n",
       " 'dropout_1': 0.2830490167548361,\n",
       " 'fine_tune_at': 0,\n",
       " 'fine_tuning_learning_rate_adam': 1.1688327470992886e-05,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "341b95cb-0c7a-4e6b-aaa8-b5be262412bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3288 images belonging to 3 classes.\n",
      "103/103 [==============================] - 122s 1s/step - loss: 0.1592 - roc_auc_score: 0.9909 - accuracy_score: 0.9644 - f1_score_metric: 0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 20:11:48,914 - INFO - loss: 0.15921413898468018\n",
      "2024-06-28 20:11:48,915 - INFO - roc_auc_score: 0.9909060597419739\n",
      "2024-06-28 20:11:48,915 - INFO - accuracy_score: 0.9644160866737366\n",
      "2024-06-28 20:11:48,916 - INFO - f1_score_metric: 0.6858655214309692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.15921413898468018\n",
      "roc_auc_score: 0.9909060597419739\n",
      "accuracy_score: 0.9644160866737366\n",
      "f1_score_metric: 0.6858655214309692\n",
      "103/103 [==============================] - 124s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 20:13:54,450 - INFO - \n",
      "Detailed Metrics:\n",
      "2024-06-28 20:13:54,451 - INFO - Accuracy: 0.9644160583941606\n",
      "2024-06-28 20:13:54,451 - INFO - Macro Precision: 0.9645130537580798\n",
      "2024-06-28 20:13:54,452 - INFO - Macro Recall: 0.9642038130979075\n",
      "2024-06-28 20:13:54,452 - INFO - Macro F1 Score: 0.9643350548119475\n",
      "2024-06-28 20:13:54,453 - INFO - Weighted F1 Score: 0.9644365931633555\n",
      "2024-06-28 20:13:54,468 - INFO - Classification Report:\n",
      "2024-06-28 20:13:54,468 - INFO - {\n",
      "  \"2SK6\": {\n",
      "    \"precision\": 0.9796484736355227,\n",
      "    \"recall\": 0.9680073126142597,\n",
      "    \"f1-score\": 0.9737931034482759,\n",
      "    \"support\": 1094.0\n",
      "  },\n",
      "  \"2SK4\": {\n",
      "    \"precision\": 0.9567723342939481,\n",
      "    \"recall\": 0.9558541266794626,\n",
      "    \"f1-score\": 0.9563130100816131,\n",
      "    \"support\": 1042.0\n",
      "  },\n",
      "  \"2SK8\": {\n",
      "    \"precision\": 0.9571183533447685,\n",
      "    \"recall\": 0.96875,\n",
      "    \"f1-score\": 0.9628990509059534,\n",
      "    \"support\": 1152.0\n",
      "  },\n",
      "  \"accuracy\": 0.9644160583941606,\n",
      "  \"macro avg\": {\n",
      "    \"precision\": 0.9645130537580798,\n",
      "    \"recall\": 0.9642038130979075,\n",
      "    \"f1-score\": 0.9643350548119475,\n",
      "    \"support\": 3288.0\n",
      "  },\n",
      "  \"weighted avg\": {\n",
      "    \"precision\": 0.9645050320999784,\n",
      "    \"recall\": 0.9644160583941606,\n",
      "    \"f1-score\": 0.9644365931633555,\n",
      "    \"support\": 3288.0\n",
      "  }\n",
      "}\n",
      "2024-06-28 20:13:54,488 - INFO - Macro-averaged ROC AUC: 0.9919978333130818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Metrics:\n",
      "Accuracy: 0.9644160583941606\n",
      "Macro Precision: 0.9645130537580798\n",
      "Macro Recall: 0.9642038130979075\n",
      "Macro F1 Score: 0.9643350548119475\n",
      "Weighted F1 Score: 0.9644365931633555\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2SK6       0.98      0.97      0.97      1094\n",
      "        2SK4       0.96      0.96      0.96      1042\n",
      "        2SK8       0.96      0.97      0.96      1152\n",
      "\n",
      "    accuracy                           0.96      3288\n",
      "   macro avg       0.96      0.96      0.96      3288\n",
      "weighted avg       0.96      0.96      0.96      3288\n",
      "\n",
      "Macro-averaged ROC AUC: 0.9919978333130818\n",
      "Predictions saved to angle_predictions.csv\n",
      "Confusion matrix saved as confusion_matrix.png (300 DPI)\n",
      "ROC curves saved as roc_curves.png (300 DPI)\n"
     ]
    }
   ],
   "source": [
    "# @title Execute Evaluation algorithm\n",
    "from eye_ai.models.vgg19_lacdhs_angle_predict import evaluate_model\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "    evaluate_model(\n",
    "        model_path=output_path + '/VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.h5',\n",
    "        test_path=test_path,\n",
    "        output_path=output_path,\n",
    "        best_params=data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17a367dd-445a-41f9-bc97-354e6def6100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 21:58:40,672 - INFO - Initializing uploader: GenericUploader v1.7.1 [Python 3.10.13, Linux-5.10.210-201.852.amzn2.x86_64-x86_64-with-glibc2.26]\n",
      "2024-06-28 21:58:40,678 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 21:58:40,681 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n",
      "2024-06-28 21:58:40,725 - INFO - Checking for updated configuration...\n",
      "2024-06-28 21:58:43,108 - INFO - Updated configuration found.\n",
      "2024-06-28 21:58:43,111 - INFO - Scanning files in directory [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training]...\n",
      "2024-06-28 21:58:43,115 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.h5].\n",
      "2024-06-28 21:58:43,116 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/training_history_VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.csv].\n",
      "2024-06-28 21:58:43,116 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/angle_predictions.csv].\n",
      "2024-06-28 21:58:43,117 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/confusion_matrix.png].\n",
      "2024-06-28 21:58:43,118 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/roc_curves.png].\n",
      "2024-06-28 21:58:43,118 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.h5]\n",
      "2024-06-28 21:58:43,119 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.h5].\n",
      "2024-06-28 21:58:43,120 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.h5]. Please wait...\n",
      "2024-06-28 21:58:43,698 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.h5] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 21:58:48,480 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.h5] upload successful. 232.71 MB transferred at 51.55 MB/second. Elapsed time: 0:00:04.514051.\n",
      "2024-06-28 21:58:48,654 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/training_history_VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.csv]\n",
      "2024-06-28 21:58:48,654 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/training_history_VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.csv].\n",
      "2024-06-28 21:58:48,655 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/training_history_VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.csv]. Please wait...\n",
      "2024-06-28 21:58:48,665 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/training_history_VGG19_Catalog_LAC_DHS_Angle_Trained_model_June_28_2024_without_H_and_V_angle_flips.csv] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 21:58:48,752 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/angle_predictions.csv]\n",
      "2024-06-28 21:58:48,753 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/angle_predictions.csv].\n",
      "2024-06-28 21:58:48,754 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/angle_predictions.csv]. Please wait...\n",
      "2024-06-28 21:58:48,764 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/angle_predictions.csv] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 21:58:48,972 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/confusion_matrix.png]\n",
      "2024-06-28 21:58:48,972 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/confusion_matrix.png].\n",
      "2024-06-28 21:58:48,973 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/confusion_matrix.png]. Please wait...\n",
      "2024-06-28 21:58:48,983 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/confusion_matrix.png] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 21:58:49,080 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/roc_curves.png]\n",
      "2024-06-28 21:58:49,080 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/roc_curves.png].\n",
      "2024-06-28 21:58:49,081 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/roc_curves.png]. Please wait...\n",
      "2024-06-28 21:58:49,091 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_angle_training/roc_curves.png] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 21:58:49,255 - INFO - File upload processing completed: 5 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n",
      "2024-06-28 21:58:49,345 - INFO - Initializing uploader: GenericUploader v1.7.1 [Python 3.10.13, Linux-5.10.210-201.852.amzn2.x86_64-x86_64-with-glibc2.26]\n",
      "2024-06-28 21:58:49,345 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 21:58:49,346 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n",
      "2024-06-28 21:58:49,386 - INFO - Checking for updated configuration...\n",
      "2024-06-28 21:58:49,502 - INFO - Updated configuration found.\n",
      "2024-06-28 21:58:49,505 - INFO - Scanning files in directory [/data/sreenidhi/EyeAI_working/Execution_Metadata]...\n",
      "2024-06-28 21:58:49,507 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json].\n",
      "2024-06-28 21:58:49,507 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt].\n",
      "2024-06-28 21:58:49,508 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json]\n",
      "2024-06-28 21:58:49,509 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json].\n",
      "2024-06-28 21:58:49,509 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json]. Please wait...\n",
      "2024-06-28 21:58:49,520 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_angle_sreenidhi_june_27_2024.json] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 21:58:49,571 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt]\n",
      "2024-06-28 21:58:49,571 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt].\n",
      "2024-06-28 21:58:49,572 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt]. Please wait...\n",
      "2024-06-28 21:58:49,586 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 21:58:49,604 - INFO - File upload processing completed: 2 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n"
     ]
    }
   ],
   "source": [
    "# # @title Save Execution Assets (model) and Metadata\n",
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bb207-df9b-4ddc-933c-045eb08388fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
