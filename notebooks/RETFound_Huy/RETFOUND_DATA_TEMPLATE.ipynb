{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ddd510-eaff-427f-b208-c900f3d00c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80accef7-a8f3-4484-9fff-5f0e4ecd4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a75e3e-e05f-4030-8fc6-eeed1ad964bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f047a4-e322-4dfe-8619-d46a44b0dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c8d7de-c35d-4727-830c-641bb47f2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RID of source dataset, if any.\n",
    "# RID of source dataset, if any.\n",
    "datasets = [\n",
    "                  '4-N9XE', \n",
    "                  '4-NAPT', \n",
    "                  '4-NBG6', \n",
    "                  '4-NC9J', \n",
    "                  '4-ND2Y', \n",
    "                  '2-39FY', \n",
    "                  '2-277M']\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "EA.add_term(vc.workflow_type, \"RETFound Model Train\", description=\"A workflow to train RETFound model\")\n",
    "\n",
    "# Workflow instance\n",
    "workflow_instance = EA.add_workflow(Workflow(\n",
    "    name=\"RETFound Model train - 200 images\",\n",
    "    url=\"https://github.com/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/RETFound_Huy/RETFOUND_DATA_200.ipynb\",\n",
    "    workflow_type=\"RETFound Model Train\",\n",
    "))\n",
    "# Configuration instance.\n",
    "\n",
    "# Set to False if you only need the metadata from the bag, and not the assets.\n",
    "download_assets = True\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    # Comment out the following line if you don't need the assets.\n",
    "    datasets=to_be_download if download_assets else [],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of training RETFound model - 200 images\")\n",
    "\n",
    "# Initialize execution\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a24dc-132c-45aa-a197-cb887096dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d6baf-eebf-4190-9541-667ea593c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_0 = execution.datasets[0]\n",
    "ds_bag_1 = execution.datasets[1]\n",
    "ds_bag_2 = execution.datasets[2]\n",
    "ds_bag_3 = execution.datasets[3]\n",
    "ds_bag_4 = execution.datasets[4]\n",
    "\n",
    "ds_bag_val = execution.datasets[5]\n",
    "ds_bag_test = execution.datasets[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c01db-fd88-493a-8045-cce6c25878ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_list = [ds_bag_0, ds_bag_1, ds_bag_2, ds_bag_3, ds_bag_4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455354f-158c-4cc9-ac8f-77e19b6b0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_excluded_df = pd.read_csv(\"valid_no_optic_disc_image_ids.csv\")\n",
    "val_excluded = val_excluded_df[\"ID\"].tolist()\n",
    "\n",
    "train_excluded_df = pd.read_csv(\"train_no_optic_disc_image_ids.csv\")\n",
    "train_excluded = train_excluded_df[\"ID\"].tolist()\n",
    "\n",
    "test_included_df = pd.read_csv(\"Graded_Test_Dataset_2-277M_With_Demographics_CDR_Diagnosis_Image_Quality_Model_Diagnosis_Predicitons_with_Jiun_Do_June8_2024_with_Catalog_model_predictions.csv\")\n",
    "test_included = test_included_df[\"Image_cd\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864968c-d6b8-4f48-8c13-a0b1b73e3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = execution._working_dir\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa59ee3-2190-407f-902f-f05bdbaba431",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_image_path_cropped, validation_csv_cropped = EA.create_cropped_images(ds_bag_val,\n",
    "                                                                                 output_dir = output_dir ,\n",
    "                                                                                 crop_to_eye=True,\n",
    "                                                                                exclude_list= val_excluded)\n",
    "\n",
    "validation_image_path_uncropped, validation_csv_uncropped = EA.create_cropped_images(ds_bag_val,\n",
    "                                                                                 output_dir = output_dir,\n",
    "                                                                                 crop_to_eye=False,\n",
    "                                                                                    exclude_list= val_excluded)\n",
    "\n",
    "test_image_path_cropped, test_csv_cropped = EA.create_cropped_images(ds_bag_test,\n",
    "                                                                     output_dir = output_dir,\n",
    "                                                                     crop_to_eye=True,\n",
    "                                                                     include_only_list= test_included)\n",
    "\n",
    "test_image_path_uncropped, test_csv_uncropped = EA.create_cropped_images(ds_bag_test,\n",
    "                                                                         output_dir = output_dir ,\n",
    "                                                                         crop_to_eye=False,\n",
    "                                                                         include_only_list = test_included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce965ff-43ff-43f8-a028-514abb0f869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path = \"best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9d170-cdf5-45d6-b147-9a395c24d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06398dda-6e4c-4947-b26d-58e8169dd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crete asset path\n",
    "asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Model_Prediction\")\n",
    "asset_path_logs = execution.execution_asset_path(\"Training_Log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb315b51-bd13-4d76-b558-b2e73fe918b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3103b8-632f-4cc6-9ea7-d26f701ba38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea95a4-6174-4b04-a34c-17765e1f0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a8b0b-257f-4a0f-a4d4-f9760fb8a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822843f4-127a-41a8-8490-d800215d0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def create_retfound_ds(output, train_dir, val_dir, test_dir, ds_bag_name, crop):\n",
    "    ds_bag_out_path = os.path.join(output, f\"{ds_bag_name}_RETFound\") if not crop else  os.path.join(output, f\"{ds_bag_name}_RETFound_cropped\") \n",
    "    os.makedirs(ds_bag_out_path, exist_ok= True)\n",
    "    \n",
    "    for subdir in ['train', 'val', 'test']:\n",
    "        subdir_path = os.path.join(ds_bag_out_path, subdir)\n",
    "        os.makedirs(subdir_path, exist_ok= True)\n",
    "        \n",
    "\n",
    "    dirs = [(train_dir, 'train'), (val_dir, 'val'), (test_dir, 'test')]\n",
    "    \n",
    "    for source_dir, subdir in dirs:\n",
    "        for class_dir in os.listdir(source_dir):\n",
    "            class_path = os.path.join(source_dir, class_dir)\n",
    "            target_class_dir = os.path.join(ds_bag_out_path, subdir, class_dir)\n",
    "            os.makedirs(target_class_dir, exist_ok= True)\n",
    "            for file_name in os.listdir(class_path):\n",
    "                source_file = os.path.join(class_path, file_name)\n",
    "                target_file = os.path.join(target_class_dir, file_name)\n",
    "                shutil.copy(source_file, target_file)\n",
    "    return ds_bag_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4488f-ab91-4dba-b10d-5abd3cdd85db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "repo_path = os.path.expanduser(\"~/Repos/RETFound_MAE\")\n",
    "with execution.execute() as exec:\n",
    "    for index, ds_bag in enumerate(ds_bag_list):\n",
    "        if index < 4:\n",
    "            continue\n",
    "        image_path_ds_bag_path_cropped, csv_ds_bag_cropped = EA.create_cropped_images(\n",
    "                                                   ds_bag, \n",
    "                                                   output_dir, \n",
    "                                                   crop_to_eye=True,\n",
    "                                                    exclude_list= train_excluded,\n",
    "                                                   )\n",
    "        image_path_ds_bag_path_uncropped, csv_ds_bag_uncropped = EA.create_cropped_images(\n",
    "                                                   ds_bag, \n",
    "                                                   output_dir, \n",
    "                                                   crop_to_eye=False,\n",
    "                                                    exclude_list= train_excluded,\n",
    "                                                 )\n",
    "       \n",
    "        print(\"Dataset: \", ds_bag.dataset_rid)\n",
    "        # retfound_ds_bag_path_uncropped= create_retfound_ds(output= output_dir, \n",
    "        #                                                    train_dir = image_path_ds_bag_path_uncropped, \n",
    "        #                                                    val_dir = validation_image_path_uncropped,  \n",
    "        #                                                    test_dir = test_image_path_uncropped, \n",
    "        #                                                    ds_bag_name =ds_bag.dataset_rid, crop = False)\n",
    "        retfound_ds_bag_path_cropped= create_retfound_ds(output= output_dir, \n",
    "                                                         train_dir = image_path_ds_bag_path_cropped, \n",
    "                                                         val_dir = validation_image_path_cropped,  \n",
    "                                                         test_dir = test_image_path_cropped, \n",
    "                                                         ds_bag_name =ds_bag.dataset_rid, crop = True)\n",
    "\n",
    "        \n",
    "\n",
    "        retfound_out_uncropped = output_dir / f\"{ds_bag.dataset_rid}/RETFound_task/Uncropped_\"\n",
    "        os.makedirs(retfound_out_uncropped, exist_ok=True)\n",
    "        \n",
    "        retfound_out_cropped = output_dir / f\"{ds_bag.dataset_rid}/RETFound_task/Cropped_\"\n",
    "        os.makedirs(retfound_out_cropped, exist_ok=True)\n",
    "        retfound_output_dirs = [\n",
    "           retfound_out_uncropped,\n",
    "            retfound_out_cropped\n",
    "        ]\n",
    "        \n",
    "        data_paths = [\n",
    "            # retfound_ds_bag_path_uncropped,\n",
    "            retfound_ds_bag_path_cropped\n",
    "        ]\n",
    "        \n",
    "        for data_path, retfound_output_dir in zip(data_paths, retfound_output_dirs):\n",
    "            os.makedirs(retfound_output_dir, exist_ok=True)\n",
    "            \n",
    "            command = [\n",
    "                \"torchrun\",\n",
    "                \"--nproc_per_node=1\", \"--master_port=48798\", \"main_finetune.py\",\n",
    "                \"--batch_size\", \"16\",\n",
    "                \"--world_size\", \"1\",\n",
    "                \"--model\", \"vit_large_patch16\",\n",
    "                \"--epochs\", \"50\",\n",
    "                \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "                \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "                \"--nb_classes\", \"5\",\n",
    "                \"--data_path\", data_path,\n",
    "                \"--task\", retfound_output_dir,\n",
    "                \"--finetune\", \"RETFound_cfp_weights.pth\",\n",
    "                \"--input_size\", \"224\"\n",
    "            ]\n",
    "                \n",
    "            # Run the command inside the RETFound_MAE repository\n",
    "            subprocess.run(command, check=True, cwd=repo_path)\n",
    "            \n",
    "        for data_path in data_paths:\n",
    "            if os.path.exists(data_path):\n",
    "                shutil.rmtree(data_path)\n",
    "                print(f\"Deleted folder: {data_path}\")\n",
    "            else:\n",
    "                print(f\"Folder does not exist: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d7c0f-ee12-4b20-af29-1aff6a82b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "for ds_bag in ds_bag_list:\n",
    "    source_dir = output_dir / ds_bag.dataset_rid /  \"RETFound_task\"\n",
    "    if not source_dir.exists():\n",
    "        print(f\"Skipping: {source_dir} does not exist.\")\n",
    "        continue\n",
    "        \n",
    "    for item in os.listdir(source_dir):\n",
    "        item_path = Path(source_dir)  / item\n",
    "        suffix = \"uncropped\" if \"Uncropped\" in item else \"cropped\"\n",
    "\n",
    "        if item.endswith(\".pth\"):\n",
    "            new_file_name = f\"{ds_bag.dataset_rid}_{suffix}.pth\"\n",
    "            destination_path = asset_path_models / new_file_name  \n",
    "            shutil.move(item_path, destination_path)\n",
    "        elif  \"test\" in item and (item.endswith(\".csv\") or item.endswith(\".jpg\")):\n",
    "            new_file_name = f\"{ds_bag.dataset_rid}_{suffix}_metrics_test.csv\" if item.endswith(\".csv\") else f\"{ds_bag.dataset_rid}_{suffix}_conf_matrix.jpg\"\n",
    "            destination_path = asset_path_output / new_file_name \n",
    "            shutil.move(item_path, destination_path)\n",
    "        elif \"val\" in item:\n",
    "              new_file_name = f\"{ds_bag.dataset_rid}_{suffix}_metrics_val.csv\"\n",
    "              destination_path = asset_path_logs / new_file_name  \n",
    "              shutil.move(item_path, destination_path)\n",
    "        elif item_path.is_dir():  \n",
    "              for sub_item in item_path.iterdir():\n",
    "                   if \"roc_\" in sub_item.name:\n",
    "                        new_file_name = f\"{ds_bag.dataset_rid}_{suffix}_{sub_item.name}\"\n",
    "                        destination_path = asset_path_output / new_file_name\n",
    "                        shutil.move(sub_item, destination_path)\n",
    "        \n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213eedf3-e449-45e6-ab42-352dbcdddb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
