{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup:\n",
    "This step initializes the necessary configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Repos && git clone --branch eye-ai-compatible https://github.com/huynguyentran/RETFound_MAE.git \n",
    "!cd Repos/RETFound_MAE && pip install -r requirements.txt\n",
    "!cd Repos/RETFound_MAE && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set this to be where your github repos are located.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, \"Repos/eye-ai-ml\")\n",
    "sys.path.insert(0, \"Repos/RETFound_MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Dataset:\n",
    "Downloading the datasets. We will work with three datasets: 2-A5T0 (train), 2-A5T2 (val), and 2-A5T4 (test). The dataset order when extracting is always set in the list provided when downloading. Additionally, this code will always download the latest version of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "        '2-A5T0',\n",
    "        '2-A5T2',\n",
    "        '2-A5T4',\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.add_workflow(Workflow(\n",
    "    name=\"RETFound Model train\",\n",
    "    url=\"https://github.com/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/RETFound_Huy/RETFOUND_DATA_TEMPLATE.ipynb\",\n",
    "    workflow_type=\"RETFound Model Train\",\n",
    "))\n",
    "\n",
    "download_assets = True\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    # Comment out the following line if you don't need the assets.\n",
    "    datasets=to_be_download  if download_assets else [],\n",
    "    assets = ['4-S3KR',  \n",
    "             #4-S3KP,\n",
    "             ],  #RETFound pre-trained weight.You should always has at least one when training.\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of training RETFound model\")\n",
    "\n",
    "# Initialize execution\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "Crop the images and move them to the designated folder for training, validation, and testing.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_train = execution.datasets[0]\n",
    "ds_bag_val = execution.datasets[1]\n",
    "ds_bag_test = execution.datasets[2]\n",
    "\n",
    "retfound_pretrained_weight = execution.asset_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = execution._working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_train_dict = {\"ds_bag\": ds_bag_train}\n",
    "ds_bag_val_dict = {\"ds_bag\": ds_bag_val}\n",
    "ds_bag_test_dict = {\"ds_bag\": ds_bag_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If the following function returns an error, it means that it has not been updated in Eye-AI.\n",
    "Instead, your dataset directory should follow the format below for the pipeline to work.\n",
    "\n",
    "├── data folder\n",
    "    ├──train\n",
    "        ├──class_a\n",
    "        ├──class_b\n",
    "        ├──class_c\n",
    "    ├──val\n",
    "        ├──class_a\n",
    "        ├──class_b\n",
    "        ├──class_c\n",
    "    ├──test\n",
    "        ├──class_a\n",
    "        ├──class_b\n",
    "        ├──class_c\n",
    "\"\"\"\n",
    "dataset_dir = EA.create_retfound_image_directory(ds_bag_train_dict =  ds_bag_train_dict, \n",
    "                                ds_bag_val_dict = ds_bag_val_dict, \n",
    "                                ds_bag_test_dict =  ds_bag_test_dict, \n",
    "                                output_dir =output_dir, \n",
    "                                crop_to_eye = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Model_Prediction\")\n",
    "asset_path_logs = execution.execution_asset_path(\"Training_Log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_date = datetime.now().strftime(\"%b_%d_%Y\") \n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETFound_output = \"./RETFound_output/task\"\n",
    "os.makedirs(RETFound_output, exist_ok= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_finetune import main, get_args_parser \n",
    "with execution.execute() as exec:\n",
    "    args_list = [\n",
    "        \"--model\", \"RETFound_mae\",\n",
    "        \"--savemodel\",\n",
    "        \"--global_pool\",\n",
    "        \"--batch_size\", \"16\",\n",
    "        \"--world_size\", \"1\",\n",
    "        \"--epochs\", \"100\",\n",
    "        \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "        \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "        \"--nb_classes\", \"2\",\n",
    "        \"--data_path\", str(dataset_dir),\n",
    "        \"--input_size\", \"224\",\n",
    "        \"--task\", str(RETFound_output),\n",
    "        \"--output_dir\", str(asset_path_output),\n",
    "        \"--finetune\", str(retfound_pretrained_weight),\n",
    "    ]\n",
    "\n",
    "    args = get_args_parser().parse_args(args_list)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    main(args, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Only:\n",
    "If you already have a RETFound model, provide its path here to evaluate it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with execution.execute() as exec:\n",
    "    path_to_model = \"path/to/model.pth\"\n",
    "    args_list = [\n",
    "        \"--model\", \"RETFound_mae\",\n",
    "        \"--eval\",\n",
    "        \"--savemodel\",\n",
    "        \"--global_pool\",\n",
    "        \"--batch_size\", \"16\",\n",
    "        \"--world_size\", \"1\",\n",
    "        \"--epochs\", \"100\",\n",
    "        \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "        \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "        \"--nb_classes\", \"2\",\n",
    "        \"--data_path\", str(dataset_dir),\n",
    "        \"--input_size\", \"224\",\n",
    "        \"--task\", str(dataset_dir),\n",
    "        \"--output_dir\", str(asset_path_output),\n",
    "        \"--resume\", path_to_model,\n",
    "    ]\n",
    "\n",
    "    args = get_args_parser().parse_args(args_list)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    main(args, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
