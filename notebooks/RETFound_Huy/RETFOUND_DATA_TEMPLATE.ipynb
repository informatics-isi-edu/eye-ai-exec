{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup:\n",
    "This step initializes the necessary configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"RETFound_MAE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Dataset:\n",
    "Downloading the datasets. We will work with three datasets: 2-A5T0 (train), 2-A5T2 (val), and 2-A5T4 (test). The dataset order when extracting is always set in the list provided when downloading. Additionally, this code will always download the latest version of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "        '2-A5T0',\n",
    "        '2-A5T2',\n",
    "        '2-A5T4',\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.add_workflow(Workflow(\n",
    "    name=\"RETFound Model train\",\n",
    "    url=\"https://github.com/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/RETFound_Huy/RETFOUND_DATA_TEMPLATE.ipynb\",\n",
    "    workflow_type=\"RETFound Model Train\",\n",
    "))\n",
    "\n",
    "download_assets = True\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    # Comment out the following line if you don't need the assets.\n",
    "    datasets=to_be_download  if download_assets else [],\n",
    "    assets = ['4-S3KR',  \n",
    "             #4-S3KP,\n",
    "             ],  #RETFound pre-trained weight.You should always has at least one when training.\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of training RETFound model\")\n",
    "\n",
    "# Initialize execution\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "Crop the images and move them to the designated folder for training, validation, and testing.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_train = execution.datasets[0]\n",
    "ds_bag_val = execution.datasets[1]\n",
    "ds_bag_test = execution.datasets[2]\n",
    "\n",
    "retfound_pretrained_weight = execution.asset_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = execution._working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_train_dict = {\"ds_bag\": ds_bag_train}\n",
    "ds_bag_val_dict = {\"ds_bag\": ds_bag_val}\n",
    "ds_bag_test_dict = {\"ds_bag\": ds_bag_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If the following function returns an error, it means that it has not been updated in Eye-AI.\n",
    "Instead, your dataset directory should follow the format below for the pipeline to work.\n",
    "\n",
    "├── data folder\n",
    "    ├──train\n",
    "        ├──class_a\n",
    "        ├──class_b\n",
    "        ├──class_c\n",
    "    ├──val\n",
    "        ├──class_a\n",
    "        ├──class_b\n",
    "        ├──class_c\n",
    "    ├──test\n",
    "        ├──class_a\n",
    "        ├──class_b\n",
    "        ├──class_c\n",
    "\"\"\"\n",
    "dataset_dir = EA.create_retfound_image_directory(ds_bag_train_dict =  ds_bag_train_dict, \n",
    "                                ds_bag_val_dict = ds_bag_val_dict, \n",
    "                                ds_bag_test_dict =  ds_bag_test_dict, \n",
    "                                output_dir =output_dir, \n",
    "                                crop_to_eye = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Model_Prediction\")\n",
    "asset_path_logs = execution.execution_asset_path(\"Training_Log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_date = datetime.now().strftime(\"%b_%d_%Y\") \n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETFound_output = \"./RETFound_output/task\"\n",
    "os.makedirs(RETFound_output, exist_ok= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the possible parameters that you can use for your training. You can find them in main_finetune.py.\n",
    "\n",
    "# Train parameters\n",
    "--batch_size: Batch size per GPU (default: 128)\n",
    "--epochs: Number of training epochs (default: 50)\n",
    "--accum_iter: Accumulate gradient iterations (default: 1)\n",
    "\n",
    "# Model parameters\n",
    "--model: Name of model to train (default: 'RETFound_mae')\n",
    "--input_size: Image input size (default: 256)\n",
    "--drop_path: Drop path rate (default: 0.2)\n",
    "\n",
    "# Optimizer parameters\n",
    "--clip_grad: Clip gradient norm (default: None)\n",
    "--weight_decay: Weight decay (default: 0.05)\n",
    "--lr: Learning rate (absolute lr) (default: None)\n",
    "--blr: Base learning rate (default: 5e-3)\n",
    "--layer_decay: Layer-wise learning rate decay (default: 0.65)\n",
    "--min_lr: Lower bound for cyclic schedulers (default: 1e-6)\n",
    "--warmup_epochs: Number of warmup epochs (default: 10)\n",
    "\n",
    "# Augmentation parameters\n",
    "--color_jitter: Color jitter factor (default: None)\n",
    "--aa: AutoAugment policy (default: 'rand-m9-mstd0.5-inc1')\n",
    "--smoothing: Label smoothing (default: 0.1)\n",
    "\n",
    "# Random Erase parameters\n",
    "--reprob: Random erase probability (default: 0.25)\n",
    "--remode: Random erase mode (default: 'pixel')\n",
    "--recount: Random erase count (default: 1)\n",
    "--resplit: Do not random erase first augmentation split (default: False)\n",
    "\n",
    "# Mixup parameters\n",
    "--mixup: Mixup alpha (default: 0, mixup enabled if > 0)\n",
    "--cutmix: CutMix alpha (default: 0, cutmix enabled if > 0)\n",
    "--cutmix_minmax: CutMix min/max ratio (default: None)\n",
    "--mixup_prob: Probability of performing Mixup or CutMix (default: 1.0)\n",
    "--mixup_switch_prob: Probability of switching to CutMix (default: 0.5)\n",
    "--mixup_mode: Mode of applying Mixup/CutMix (default: 'batch')\n",
    "\n",
    "# Finetuning parameters\n",
    "--finetune: Finetune from checkpoint (default: '')\n",
    "--task: Task type for finetuning (default: '')\n",
    "--global_pool: Use global pooling (default: True)\n",
    "--cls_token: Use class token instead of global pool (default: False)\n",
    "\n",
    "# Dataset parameters\n",
    "--data_path: Dataset path (default: './data/')\n",
    "--nb_classes: Number of classification categories (default: 8)\n",
    "--output_dir: Path to save output (default: './output_dir')\n",
    "--log_dir: Path for TensorBoard logs (default: './output_logs')\n",
    "--device: Device to use for training/testing (default: 'cuda')\n",
    "--seed: Random seed (default: 0)\n",
    "--resume: Resume from checkpoint (default: '')\n",
    "--start_epoch: Start epoch number (default: 0)\n",
    "--eval: Perform evaluation only (default: False)\n",
    "--dist_eval: Enable distributed evaluation (default: False)\n",
    "--num_workers: Number of DataLoader workers (default: 10)\n",
    "--pin_mem: Pin CPU memory in DataLoader for efficient GPU transfer (default: True)\n",
    "\n",
    "# Distributed training parameters\n",
    "--world_size: Number of distributed processes (default: 1)\n",
    "--local_rank: Local rank for distributed training (default: -1)\n",
    "--dist_on_itp: Enable distributed training on ITP (default: False)\n",
    "--dist_url: URL for distributed training setup (default: 'env://')\n",
    "\n",
    "# Additional fine-tuning parameters\n",
    "--savemodel: Save the trained model (default: True)\n",
    "--norm: Normalization method (default: 'IMAGENET')\n",
    "--enhance: Use enhanced data (default: False)\n",
    "--datasets_seed: Dataset random seed (default: 2026)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_finetune import main, get_args_parser \n",
    "with execution.execute() as exec:\n",
    "    args_list = [\n",
    "        \"--model\", \"RETFound_mae\", # If you are using 4-S3KP asset, this would be RETFound_dinov2, which I would recommend take a look into.\n",
    "        \"--savemodel\",\n",
    "        \"--global_pool\",\n",
    "        \"--batch_size\", \"16\",\n",
    "        \"--world_size\", \"1\",\n",
    "        \"--epochs\", \"100\",\n",
    "        \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "        \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "        \"--nb_classes\", \"2\",\n",
    "        \"--data_path\", str(dataset_dir),\n",
    "        \"--input_size\", \"224\",\n",
    "        \"--task\", str(asset_path_output), # You will need to move content in this folder to asset_path_output for upload\n",
    "        \"--output_dir\", str(asset_path_output),\n",
    "        \"--finetune\", str(retfound_pretrained_weight),\n",
    "    ]\n",
    "\n",
    "    args = get_args_parser().parse_args(args_list)\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Only:\n",
    "If you already have a RETFound model, provide its path here to evaluate it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_finetune import main, get_args_parser \n",
    "with execution.execute() as exec:\n",
    "    path_to_model = \"path/to/model.pth\"\n",
    "    args_list = [\n",
    "        \"--model\", \"RETFound_mae\",\n",
    "        \"--eval\",\n",
    "        \"--savemodel\",\n",
    "        \"--global_pool\",\n",
    "        \"--batch_size\", \"16\",\n",
    "        \"--world_size\", \"1\",\n",
    "        \"--epochs\", \"100\",\n",
    "        \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "        \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "        \"--nb_classes\", \"2\",\n",
    "        \"--data_path\", str(dataset_dir),\n",
    "        \"--input_size\", \"224\",\n",
    "        \"--task\", str(asset_path_output),\n",
    "        \"--output_dir\", str(asset_path_output),\n",
    "        \"--resume\", path_to_model,\n",
    "    ]\n",
    "\n",
    "    args = get_args_parser().parse_args(args_list)\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
