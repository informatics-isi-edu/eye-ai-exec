{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/VGG19_Diagnosis_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVq_jMdfx7Ni"
   },
   "source": [
    "# Develop rules for getting cropped images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "# import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "# host = 'dev.eye-ai.org'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imD3DJ4lx7Nm"
   },
   "source": [
    "Connect to Eye-AI catalog.  Configure to store data local cache and working directories.  Initialize Eye-AI for pending execution based on the provided configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "\n",
    "cache_dir = '/data'        # Directory in which to cache materialized BDBags for datasets\n",
    "working_dir = '/data'    # Directory in which to place output files for later upload.\n",
    "\n",
    "configuration_rid=\"2-C654\" # rid\n",
    "# Change the confi_file with bag_url=[\"minid: train\", \"minid: Valid\", \"minid: test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initiate an Execution\n",
    "configuration_records = EA.execution_init(configuration_rid=configuration_rid)\n",
    "configuration_records.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_train = pd.read_csv(configuration_records.assets_paths[0])['ID'].to_list()\n",
    "exclude_valid = pd.read_csv(configuration_records.assets_paths[1])['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Data Preprocessing (Filtering Image.csv for just Field_2 Images)\n",
    "train_dir = configuration_records.bag_paths[0] # path to the raw train dataset\n",
    "validation_dir = configuration_records.bag_paths[1]\n",
    "test_dir = configuration_records.bag_paths[2]\n",
    "\n",
    "train_cropped_image_path = path to training cropped images\n",
    "train_cropped_image_path, train_cropped_csv = EA.create_cropped_images(str(train_dir),\n",
    "                                                                       output_dir = str(EA.working_dir) +'/train',\n",
    "                                                                       crop_to_eye=True,\n",
    "                                                                       exclude_list=exclude_train)\n",
    "validation_cropped_image_path, validation_cropped_csv = EA.create_cropped_images(str(validation_dir),\n",
    "                                                                                 output_dir = str(EA.working_dir) +'/valid',\n",
    "                                                                                 crop_to_eye=True,\n",
    "                                                                                 exclude_list=exclude_valid)\n",
    "test_cropped_image_path, test_cropped_csv = EA.create_cropped_images(str(test_dir),\n",
    "                                                                     output_dir = str(EA.working_dir) +'/test',\n",
    "                                                                     crop_to_eye=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Save Execution Assets (model) and Metadata\n",
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Tensorflow",
   "language": "python",
   "name": "my-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
