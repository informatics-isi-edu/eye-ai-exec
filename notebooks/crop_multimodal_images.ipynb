{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfec52-cdba-4f8d-919f-a79ef124a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-vgg19\" / \"src\" / \"vgg19\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"RETFound_MAE\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb792c6d-c5d6-4a15-915e-d901863fa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909fad7-f14a-4276-a8c9-b2f91b29c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246e454-9d83-4b52-af12-1d61b471cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2edfa-8a58-4a7a-b346-a0755da019c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    '4-4116', # Selected images for training\n",
    "    '4-411G', # Selected images for testing\n",
    "    '2-7P5P', # Full multimodal dataset\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.create_workflow(\n",
    "    name=\"Multimodal workflow\",\n",
    "    workflow_type=\"Multimodal workflow\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download,\n",
    "    assets = ['2-4JR6',],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of cropping multimodal images.\")\n",
    "\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5a104-349c-48a7-8a8c-8ba1e249f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090db8d3-775b-4b88-9a75-beaa63f584b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds_bag = execution.datasets[0]\n",
    "testing_ds_bag = execution.datasets[1]\n",
    "multimodal_full_ds_bag = execution.datasets[2]\n",
    "\n",
    "crop_image_model =  execution.asset_paths[\"Execution_Asset\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e311b-c7ad-4f20-8b60-df91f8a369a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_bag(ds_bag: DatasetBag, multimodal_full_ds_bag: DatasetBag):\n",
    "    observation_table = ds_bag.get_table_as_dataframe('Observation')\n",
    "    image_table = ds_bag.get_table_as_dataframe('Image')\n",
    "    laterality_table = ds_bag.get_table_as_dataframe('Execution_Image_Fundus_Laterality')\n",
    "\n",
    "    image_table_filtered = image_table[['RID', 'Filename', 'Observation']].rename(columns={'RID': 'RID_Image'})\n",
    "    laterality_table_filtered = laterality_table[['Image', 'Image_Side']].rename(columns={'Image': 'RID_Image'})\n",
    "    image_laterality = pd.merge(image_table_filtered, laterality_table_filtered, left_on='RID_Image', right_on='RID_Image', how='inner')\n",
    "    observation_table_filtered = observation_table[['RID',  'Subject']].rename(columns={'RID': 'RID_Observation'})\n",
    "    image_laterality_observation = pd.merge(image_laterality, observation_table_filtered, left_on='Observation', right_on='RID_Observation', how='inner')\n",
    "\n",
    "    wide = EA.multimodal_wide(multimodal_full_ds_bag) \n",
    "    \n",
    "    image_observation_laterality_subject_wide = pd.merge(\n",
    "     wide, \n",
    "     image_laterality_observation, \n",
    "     left_on=['RID_Subject', 'Image_Side'], \n",
    "     right_on=['Subject', 'Image_Side'], \n",
    "     how='inner'\n",
    "    )\n",
    "\n",
    "    return image_observation_laterality_subject_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1b2bf-05e8-46e1-afbd-2cf8bbc93bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_dataframe_from_bag(training_ds_bag, multimodal_full_ds_bag)\n",
    "test_df= get_dataframe_from_bag(testing_ds_bag, multimodal_full_ds_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbaa602-7011-4c1d-842e-2c53ef86eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Ensure working_dir is a Path object\n",
    "working_dir = Path(\"~/working_dir\")\n",
    "\n",
    "# Save DataFrames as CSV files\n",
    "train_csv_path = working_dir / \"train.csv\"\n",
    "test_csv_path = working_dir / \"test.csv\"\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "test_df.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178c2f6-33e4-4e33-a2e4-523dfad9f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'Image'\n",
    "EA.find_features(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536de7ee-527e-4cd4-b67f-48ddfff79100",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageAnnotationFeature = EA.feature_record_class(\"Image\", \"Annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e15835-9f9b-4edd-935c-ed76c8d240e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = execution._working_dir / \"image_svg_output\"\n",
    "output.mkdir(parents= True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af5530-cb5f-4105-8f8b-453cce78f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_disk_crop_predict import preprocess_and_crop\n",
    "with execution.execute() as exec:\n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/train.csv',\n",
    "      '~/working_dir/output/output_train.csv',\n",
    "      'template.jpg',\n",
    "      str(output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )\n",
    "    \n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/test.csv',\n",
    "      '~/working_dir/output/output_test.csv',\n",
    "      'template.jpg',\n",
    "      str(output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f97871-b6bc-48cb-b0cb-27e29ddcfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageAnnotationFeature = EA.feature_record_class(\"Image\", \"Annotation\")\n",
    "ImageAnnotationFeature.feature_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3cfbf6-ccc7-4ead-a7c7-415cd236c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rids = []\n",
    "for file_name in os.listdir(output):\n",
    "    image_rids.append(file_name.split(\"_\")[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8af492-b43d-45ed-869c-b0bbe8e38dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = Path(\"~/working_dir/output/output_train.csv\")\n",
    "df = pd.read_csv(csv_train)\n",
    "cropping_func_map_train = dict(zip(df[\"Image RID\"], df[\"Worked Image Cropping Function\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa3b48-c93a-4020-9cf7-d232979b8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = Path(\"~/working_dir/output/output_test.csv\")\n",
    "df = pd.read_csv(csv_test)\n",
    "cropping_func_map_test = dict(zip(df[\"Image RID\"], df[\"Worked Image Cropping Function\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb5085-2b4f-4e91-9069-2966f9f488cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have the files yet\n",
    "\n",
    "# for image_rid in image_rids:\n",
    "#     bounding_box_file = execution.asset_file_path(\n",
    "#         \"Fundus_Bounding_Box\", f\"Cropped_{image_rid}.svg\"\n",
    "#     )\n",
    "#     bounding_box_file_paths.append(bounding_box_file)\n",
    "\n",
    "# target_directory  = os.path.dirname(bounding_box_file_paths[0])\n",
    "# os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# for filename in os.listdir(output):\n",
    "#     source_path = os.path.join(output, filename)\n",
    "#     if os.path.isfile(source_path):\n",
    "#         shutil.move(source_path, os.path.join(target_directory, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3e794-5e02-4fc7-9be1-768bda16645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "\n",
    "bounding_box_file_paths = []\n",
    "for file_name in os.listdir(output):\n",
    "    full_path_name = os.path.join(output, file_name)\n",
    "    bounding_box_file = execution.asset_file_path(\n",
    "        \"Fundus_Bounding_Box\", full_path_name, \n",
    "    )\n",
    "    bounding_box_file_paths.append(bounding_box_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d352d0-3df4-4bb3-8187-ad76fcd129a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box_file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc402431-15f4-4075-b1ef-103dc829db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bounding_box_feature_list = []\n",
    "\n",
    "\n",
    "for image_rid, asset_file_path in zip(image_rids, bounding_box_file_paths):\n",
    "    expected_name = f\"Cropped_{image_rid}.svg\"\n",
    "    actual_name = os.path.basename(asset_file_path)\n",
    "    assert expected_name == actual_name, f\"Expected {expected_name}, got {actual_name}\"\n",
    "\n",
    "    annotation_func = cropping_func_map_train.get(image_rid) or cropping_func_map_test.get(image_rid)\n",
    "    if annotation_func:\n",
    "        image_bounding_box_feature_list.append(\n",
    "            ImageAnnotationFeature(\n",
    "                Image=image_rid,\n",
    "                Execution=execution.execution_rid,\n",
    "                Fundus_Bounding_Box=asset_file_path,\n",
    "                Annotation_Function=annotation_func,\n",
    "                Annotation_Type='Optic Nerve',\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc67b4-596b-4256-a442-b22a9f8009e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bounding_box_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab0368-0d0c-45b6-87ca-222cf650b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "with execution.execute() as execution:\n",
    "    execution.add_features(image_bounding_box_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a35548-5d8e-4243-bea2-fa70e79e0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
