{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfec52-cdba-4f8d-919f-a79ef124a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-vgg19\" / \"src\" / \"vgg19\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"RETFound_MAE\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb792c6d-c5d6-4a15-915e-d901863fa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909fad7-f14a-4276-a8c9-b2f91b29c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246e454-9d83-4b52-af12-1d61b471cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2edfa-8a58-4a7a-b346-a0755da019c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    '4-4116', # Selected images for training\n",
    "    '4-411G', # Selected images for testing\n",
    "    '2-7P5P', # Full multimodal dataset\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.create_workflow(\n",
    "    name=\"Multimodal workflow\",\n",
    "    workflow_type=\"Multimodal workflow\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download,\n",
    "    assets = ['2-4JR6',],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of cropping multimodal images.\")\n",
    "\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5a104-349c-48a7-8a8c-8ba1e249f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090db8d3-775b-4b88-9a75-beaa63f584b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds_bag = execution.datasets[0]\n",
    "testing_ds_bag = execution.datasets[1]\n",
    "multimodal_full_ds_bag = execution.datasets[2]\n",
    "\n",
    "crop_image_model = execution.asset_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e311b-c7ad-4f20-8b60-df91f8a369a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_bag(ds_bag: DatasetBag, multimodal_full_ds_bag: DatasetBag):\n",
    "    observation_table = ds_bag.get_table_as_dataframe('Observation')\n",
    "    image_table = ds_bag.get_table_as_dataframe('Image')\n",
    "    laterality_table = ds_bag.get_table_as_dataframe('Execution_Image_Fundus_Laterality')\n",
    "\n",
    "    image_table_filtered = image_table[['RID', 'Filename', 'Observation']].rename(columns={'RID': 'RID_Image'})\n",
    "    laterality_table_filtered = laterality_table[['Image', 'Image_Side']].rename(columns={'Image': 'RID_Image'})\n",
    "    image_laterality = pd.merge(image_table_filtered, laterality_table_filtered, left_on='RID_Image', right_on='RID_Image', how='inner')\n",
    "    observation_table_filtered = observation_table[['RID',  'Subject']].rename(columns={'RID': 'RID_Observation'})\n",
    "    image_laterality_observation = pd.merge(image_laterality, observation_table_filtered, left_on='Observation', right_on='RID_Observation', how='inner')\n",
    "\n",
    "    wide = EA.multimodal_wide(multimodal_full_ds_bag) \n",
    "    \n",
    "    image_observation_laterality_subject_wide = pd.merge(\n",
    "     wide, \n",
    "     image_laterality_observation, \n",
    "     left_on=['RID_Subject', 'Image_Side'], \n",
    "     right_on=['Subject', 'Image_Side'], \n",
    "     how='inner'\n",
    "    )\n",
    "\n",
    "    return image_observation_laterality_subject_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1b2bf-05e8-46e1-afbd-2cf8bbc93bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_dataframe_from_bag(training_ds_bag, multimodal_full_ds_bag)\n",
    "test_df= get_dataframe_from_bag(testing_ds_bag, multimodal_full_ds_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbaa602-7011-4c1d-842e-2c53ef86eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Ensure working_dir is a Path object\n",
    "working_dir = Path(\"~/working_dir\")\n",
    "\n",
    "# Save DataFrames as CSV files\n",
    "train_csv_path = working_dir / \"train.csv\"\n",
    "test_csv_path = working_dir / \"test.csv\"\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "test_df.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178c2f6-33e4-4e33-a2e4-523dfad9f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'Image'\n",
    "EA.find_features(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536de7ee-527e-4cd4-b67f-48ddfff79100",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'Annotation'\n",
    "Feature = EA.feature_record_class(table_name, feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07d7ff-19e6-4741-a523-d20efb25a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(\n",
    "    Markdown('### Feature Name'),\n",
    "    [ f'Name: {c.name}, Required: {not c.nullok}' for c in Feature.feature.feature_columns]\n",
    ")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0f517-38c5-442f-bc78-7da22df44389",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = [c for c in Feature.feature.feature_columns]\n",
    "help(cl[0].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6c452-cfbd-4c57-97dc-57903337a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Image_Annotation\")\n",
    "asset_path_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e15835-9f9b-4edd-935c-ed76c8d240e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_csv_path, bb_asset_paths = execution.feature_paths('Image', 'Annotation')\n",
    "bb_asset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3ca46-43b2-490e-b338-1a166b4a9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "src_dir = Path(\"/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S524/execution-asset/Image_Annotation\")\n",
    "dst_dir = Path(\"/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S524/feature/eye-ai/Image/Annotation/asset/Fundus_Bounding_Box\")\n",
    "\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in src_dir.iterdir():\n",
    "    if file.is_file():\n",
    "        shutil.move(str(file), dst_dir / file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af5530-cb5f-4105-8f8b-453cce78f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_disk_crop_predict import preprocess_and_crop\n",
    "with execution.execute() as exec:\n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/train.csv',\n",
    "      '~/working_dir/output/output_train.csv',\n",
    "      'template.jpg',\n",
    "      str(asset_path_output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )\n",
    "    \n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/test.csv',\n",
    "      '~/working_dir/output/output_test.csv',\n",
    "      'template.jpg',\n",
    "      str(asset_path_output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020271a-3f2c-4b6c-8dce-11ed6eca6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"checkpoint test 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f97871-b6bc-48cb-b0cb-27e29ddcfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageBoundingboxFeature = EA.feature_record_class(\"Image\", feature_name)\n",
    "ImageBoundingboxFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3cfbf6-ccc7-4ead-a7c7-415cd236c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rids = []\n",
    "for file_name in os.listdir(asset_path_output):\n",
    "    image_rids.append(file_name.split(\"_\")[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8af492-b43d-45ed-869c-b0bbe8e38dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = Path(\"~/working_dir/output/output_train.csv\")\n",
    "df = pd.read_csv(csv_train)\n",
    "\n",
    "# Create a mapping from Image RID to Worked Image Cropping Function\n",
    "cropping_func_map_train = dict(zip(df[\"Image RID\"], df[\"Worked Image Cropping Function\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa3b48-c93a-4020-9cf7-d232979b8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = Path(\"~/working_dir/output/output_test.csv\")\n",
    "df = pd.read_csv(csv_test)\n",
    "\n",
    "# Create a mapping from Image RID to Worked Image Cropping Function\n",
    "cropping_func_map_test = dict(zip(df[\"Image RID\"], df[\"Worked Image Cropping Function\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3804e-8a38-41d5-9de2-cefbb4fe14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list\n",
    "image_bounding_box_feature_list = []\n",
    "for image_rid in image_rids:\n",
    "    if (asset_path_output / f\"Cropped_{image_rid}.svg\").exists():\n",
    "        if image_rid in cropping_func_map_train:\n",
    "            image_bounding_box_feature_list.append(\n",
    "                ImageBoundingboxFeature(\n",
    "                    Image=image_rid,\n",
    "                    Execution=execution.execution_rid,\n",
    "                    Fundus_Bounding_Box=asset_path_output / f\"Cropped_{image_rid}.svg\",\n",
    "                    Annotation_Function=cropping_func_map_train.get(image_rid),\n",
    "                    Annotation_Type='Optic Nerve',\n",
    "                ))\n",
    "        if image_rid in cropping_func_map_test:\n",
    "            image_bounding_box_feature_list.append(\n",
    "                ImageBoundingboxFeature(\n",
    "                    Image=image_rid,\n",
    "                    Execution=execution.execution_rid,\n",
    "                    Fundus_Bounding_Box=asset_path_output / f\"Cropped_{image_rid}.svg\",\n",
    "                    Annotation_Function=cropping_func_map_test.get(image_rid),\n",
    "                    Annotation_Type='Optic Nerve',\n",
    "                ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84267f-c29d-4666-8d2d-b6c8f55c5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bounding_box_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab0368-0d0c-45b6-87ca-222cf650b333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c89d5b-e159-4627-b36b-5bbdc77e255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution.write_feature_file(image_bounding_box_feature_list)\n",
    "# execution.upload_execution_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972986a1-1fb0-4c9b-afea-7ef524de0bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
