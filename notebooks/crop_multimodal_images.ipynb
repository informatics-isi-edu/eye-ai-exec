{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bfec52-cdba-4f8d-919f-a79ef124a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-vgg19\" / \"src\" / \"vgg19\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"RETFound_MAE\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb792c6d-c5d6-4a15-915e-d901863fa5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 15:52:35.890834: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-31 15:52:35.890879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-31 15:52:35.895324: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-31 15:52:35.908772: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-31 15:52:37.394817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4909fad7-f14a-4276-a8c9-b2f91b29c753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7246e454-9d83-4b52-af12-1d61b471cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 15:52:39,506 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n"
     ]
    }
   ],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b2edfa-8a58-4a7a-b346-a0755da019c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 15:52:40,514 - INFO - Materialize bag 4-4116... \n",
      "2025-03-31 15:52:41,450 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-31 15:52:42,218 - INFO - Loading /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116\n",
      "2025-03-31 15:52:42,830 - INFO - Creating new database for dataset: 4-4116 in /data/nguyent8/EyeAI_working/4-4116@330-B1Z0-2NHT.db\n",
      "2025-03-31 15:52:42,831 - INFO - Materialize bag 4-411G... \n",
      "2025-03-31 15:52:43,970 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-31 15:52:44,832 - INFO - Loading /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d70f7b3bfd0a0cd3931d4e2edbade797d/Dataset_4-411G\n",
      "2025-03-31 15:52:45,231 - INFO - Creating new database for dataset: 4-411G in /data/nguyent8/EyeAI_working/4-411G@330-B1Z0-GC2Y.db\n",
      "2025-03-31 15:52:45,232 - INFO - Materialize bag 2-7P5P... \n",
      "2025-03-31 15:52:46,348 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-31 15:52:47,205 - INFO - Loading /data/2-7P5P_52942baeabd3e1cee91bbbea4e58f3aca680a8f59aa72d4184823e7df474fd2a/Dataset_2-7P5P\n",
      "2025-03-31 15:52:52,198 - INFO - Creating new database for dataset: 2-7P5P in /data/nguyent8/EyeAI_working/2-7P5P@330-B1YY-G4RR.db\n",
      "2025-03-31 15:52:52,305 - INFO - Downloading assets ...\n",
      "2025-03-31 15:52:56,219 - INFO - File [/data/nguyent8/EyeAI_working/4-S524/asset/optic_disk_crop_model.hdf5] transfer successful. 76.75 MB transferred at 23.51 MB/second. Elapsed time: 0:00:03.264355.\n",
      "2025-03-31 15:52:56,728 - INFO - Initialize status finished.\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    '4-4116', # Selected images for training\n",
    "    '4-411G', # Selected images for testing\n",
    "    '2-7P5P', # Full multimodal dataset\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.create_workflow(\n",
    "    name=\"Multimodal workflow\",\n",
    "    workflow_type=\"Multimodal workflow\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download,\n",
    "    assets = ['2-4JR6',],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of cropping multimodal images.\")\n",
    "\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d5a104-349c-48a7-8a8c-8ba1e249f901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching_dir: /data\n",
      "_working_dir: /data/nguyent8/EyeAI_working\n",
      "execution_rid: 4-S524\n",
      "workflow_rid: 4-S522\n",
      "asset_paths: [PosixPath('/data/nguyent8/EyeAI_working/4-S524/asset/optic_disk_crop_model.hdf5')]\n",
      "configuration: datasets=[DatasetSpec(rid='4-4116', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0)), DatasetSpec(rid='4-411G', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0)), DatasetSpec(rid='2-7P5P', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0))] assets=['2-4JR6'] workflow=Workflow(name='Multimodal workflow', url='https://github.com/informatics-isi-edu/eye-ai-exec/blob/bb26e92ce4746a3637372d73a887a36bbdde2aa9--/notebooks/crop_multimodal_images.ipynb', workflow_type='Multimodal workflow', version=None, description='', rid=None, checksum='e69de29bb2d1d6434b8b29ae775ad8c2e48c5391') parameters={} description='Instance of cropping multimodal images.' argv=['/home/nguyent8/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/ipykernel_launcher.py', '-f', '/home/nguyent8/.local/share/jupyter/runtime/kernel-58a74d22-42b7-4b11-866b-8ca10afabfa0.json']\n"
     ]
    }
   ],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090db8d3-775b-4b88-9a75-beaa63f584b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds_bag = execution.datasets[0]\n",
    "testing_ds_bag = execution.datasets[1]\n",
    "multimodal_full_ds_bag = execution.datasets[2]\n",
    "\n",
    "crop_image_model = execution.asset_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8e311b-c7ad-4f20-8b60-df91f8a369a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_bag(ds_bag: DatasetBag, multimodal_full_ds_bag: DatasetBag):\n",
    "    observation_table = ds_bag.get_table_as_dataframe('Observation')\n",
    "    image_table = ds_bag.get_table_as_dataframe('Image')\n",
    "    laterality_table = ds_bag.get_table_as_dataframe('Execution_Image_Fundus_Laterality')\n",
    "\n",
    "    image_table_filtered = image_table[['RID', 'Filename', 'Observation']].rename(columns={'RID': 'RID_Image'})\n",
    "    laterality_table_filtered = laterality_table[['Image', 'Image_Side']].rename(columns={'Image': 'RID_Image'})\n",
    "    image_laterality = pd.merge(image_table_filtered, laterality_table_filtered, left_on='RID_Image', right_on='RID_Image', how='inner')\n",
    "    observation_table_filtered = observation_table[['RID',  'Subject']].rename(columns={'RID': 'RID_Observation'})\n",
    "    image_laterality_observation = pd.merge(image_laterality, observation_table_filtered, left_on='Observation', right_on='RID_Observation', how='inner')\n",
    "\n",
    "    wide = EA.multimodal_wide(multimodal_full_ds_bag) \n",
    "    \n",
    "    image_observation_laterality_subject_wide = pd.merge(\n",
    "     wide, \n",
    "     image_laterality_observation, \n",
    "     left_on=['RID_Subject', 'Image_Side'], \n",
    "     right_on=['Subject', 'Image_Side'], \n",
    "     how='inner'\n",
    "    )\n",
    "\n",
    "    return image_observation_laterality_subject_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a1b2bf-05e8-46e1-afbd-2cf8bbc93bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyent8/Repos/eye-ai-ml/eye_ai/eye_ai.py:425: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hvf_clean.loc[:, 'priority'] = hvf_clean['Field_Size'].map(priority)\n",
      "/home/nguyent8/Repos/eye-ai-ml/eye_ai/eye_ai.py:425: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hvf_clean.loc[:, 'priority'] = hvf_clean['Field_Size'].map(priority)\n"
     ]
    }
   ],
   "source": [
    "train_df = get_dataframe_from_bag(training_ds_bag, multimodal_full_ds_bag)\n",
    "test_df= get_dataframe_from_bag(testing_ds_bag, multimodal_full_ds_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbaa602-7011-4c1d-842e-2c53ef86eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Ensure working_dir is a Path object\n",
    "working_dir = Path(\"~/working_dir\")\n",
    "\n",
    "# Save DataFrames as CSV files\n",
    "train_csv_path = working_dir / \"train.csv\"\n",
    "test_csv_path = working_dir / \"test.csv\"\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "test_df.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a178c2f6-33e4-4e33-a2e4-523dfad9f680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Feature(target_table=Image, feature_name=Annotation, feature_table=Annotation),\n",
       " Feature(target_table=Image, feature_name=Image_Diagnosis, feature_table=Image_Diagnosis),\n",
       " Feature(target_table=Image, feature_name=Fundus_Laterality, feature_table=Execution_Image_Fundus_Laterality),\n",
       " Feature(target_table=Image, feature_name=Fundus_Angle, feature_table=Execution_Image_Fundus_Angle)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name = 'Image'\n",
    "EA.find_features(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "536de7ee-527e-4cd4-b67f-48ddfff79100",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'Annotation'\n",
    "Feature = EA.feature_record_class(table_name, feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a07d7ff-19e6-4741-a523-d20efb25a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Feature Name"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Name: Fundus_Bounding_Box, Required: True',\n",
       " 'Name: Annotation_Function, Required: True',\n",
       " 'Name: Annotation_Type, Required: True']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(\n",
    "    Markdown('### Feature Name'),\n",
    "    [ f'Name: {c.name}, Required: {not c.nullok}' for c in Feature.feature.feature_columns]\n",
    ")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb0f517-38c5-442f-bc78-7da22df44389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Type in module deriva.core.ermrest_model object:\n",
      "\n",
      "class Type(builtins.object)\n",
      " |  Type(type_doc)\n",
      " |  \n",
      " |  Named type.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, type_doc)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  prejson(self, prune=True)\n",
      " |  \n",
      " |  sqlite3_ddl(self) -> 'str'\n",
      " |      Return a SQLite3 column type DDL fragment for this type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl = [c for c in Feature.feature.feature_columns]\n",
    "help(cl[0].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fb6c452-cfbd-4c57-97dc-57903337a04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S524/execution-asset/Image_Annotation')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Image_Annotation\")\n",
    "asset_path_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1e15835-9f9b-4edd-935c-ed76c8d240e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fundus_Bounding_Box': PosixPath('/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S524/feature/eye-ai/Image/Annotation/asset/Fundus_Bounding_Box')}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_csv_path, bb_asset_paths = execution.feature_paths('Image', 'Annotation')\n",
    "bb_asset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ab3ca46-43b2-490e-b338-1a166b4a9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "src_dir = Path(\"/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S524/execution-asset/Image_Annotation\")\n",
    "dst_dir = Path(\"/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S524/feature/eye-ai/Image/Annotation/asset/Fundus_Bounding_Box\")\n",
    "\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in src_dir.iterdir():\n",
    "    if file.is_file():\n",
    "        shutil.move(str(file), dst_dir / file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af5530-cb5f-4105-8f8b-453cce78f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_disk_crop_predict import preprocess_and_crop\n",
    "with execution.execute() as exec:\n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/train.csv',\n",
    "      '~/working_dir/output/output_train.csv',\n",
    "      'template.jpg',\n",
    "      str(asset_path_output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )\n",
    "    \n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/test.csv',\n",
    "      '~/working_dir/output/output_test.csv',\n",
    "      'template.jpg',\n",
    "      str(asset_path_output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b020271a-3f2c-4b6c-8dce-11ed6eca6067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint test 1\n"
     ]
    }
   ],
   "source": [
    "print(\"checkpoint test 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38f97871-b6bc-48cb-b0cb-27e29ddcfcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deriva_ml.feature.ImageFeatureAnnotation"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageBoundingboxFeature = EA.feature_record_class(\"Image\", feature_name)\n",
    "ImageBoundingboxFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f3cfbf6-ccc7-4ead-a7c7-415cd236c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rids = []\n",
    "for file_name in os.listdir(asset_path_output):\n",
    "    image_rids.append(file_name.split(\"_\")[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd8af492-b43d-45ed-869c-b0bbe8e38dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = Path(\"~/working_dir/output/output_train.csv\")\n",
    "df = pd.read_csv(csv_train)\n",
    "\n",
    "# Create a mapping from Image RID to Worked Image Cropping Function\n",
    "cropping_func_map_train = dict(zip(df[\"Image RID\"], df[\"Worked Image Cropping Function\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29aa3b48-c93a-4020-9cf7-d232979b8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = Path(\"~/working_dir/output/output_test.csv\")\n",
    "df = pd.read_csv(csv_test)\n",
    "\n",
    "# Create a mapping from Image RID to Worked Image Cropping Function\n",
    "cropping_func_map_test = dict(zip(df[\"Image RID\"], df[\"Worked Image Cropping Function\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baa3804e-8a38-41d5-9de2-cefbb4fe14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list\n",
    "image_bounding_box_feature_list = []\n",
    "for image_rid in image_rids:\n",
    "    if (asset_path_output / f\"Cropped_{image_rid}.svg\").exists():\n",
    "        if image_rid in cropping_func_map_train:\n",
    "            image_bounding_box_feature_list.append(\n",
    "                ImageBoundingboxFeature(\n",
    "                    Image=image_rid,\n",
    "                    Execution=execution.execution_rid,\n",
    "                    Fundus_Bounding_Box=asset_path_output / f\"Cropped_{image_rid}.svg\",\n",
    "                    Annotation_Function=cropping_func_map_train.get(image_rid),\n",
    "                    Annotation_Type='Optic Nerve',\n",
    "                ))\n",
    "        if image_rid in cropping_func_map_test:\n",
    "            image_bounding_box_feature_list.append(\n",
    "                ImageBoundingboxFeature(\n",
    "                    Image=image_rid,\n",
    "                    Execution=execution.execution_rid,\n",
    "                    Fundus_Bounding_Box=asset_path_output / f\"Cropped_{image_rid}.svg\",\n",
    "                    Annotation_Function=cropping_func_map_test.get(image_rid),\n",
    "                    Annotation_Type='Optic Nerve',\n",
    "                ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84267f-c29d-4666-8d2d-b6c8f55c5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bounding_box_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "faab0368-0d0c-45b6-87ca-222cf650b333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageFeatureAnnotation(Execution='4-S524', Feature_Name='Annotation', Fundus_Bounding_Box=PosixPath('/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S524/execution-asset/Image_Annotation/Cropped_2-BRVR.svg'), Annotation_Function='imgResize_secondary', Annotation_Type='Optic Nerve', Image='2-BRVR')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c89d5b-e159-4627-b36b-5bbdc77e255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution.write_feature_file(image_bounding_box_feature_list)\n",
    "# execution.upload_execution_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972986a1-1fb0-4c9b-afea-7ef524de0bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
