{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bfec52-cdba-4f8d-919f-a79ef124a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-vgg19\" / \"src\" / \"vgg19\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"RETFound_MAE\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb792c6d-c5d6-4a15-915e-d901863fa5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:47:07.589228: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-30 15:47:07.589276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-30 15:47:07.590136: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-30 15:47:07.596805: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-30 15:47:08.389851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4909fad7-f14a-4276-a8c9-b2f91b29c753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7246e454-9d83-4b52-af12-1d61b471cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:47:09,449 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n"
     ]
    }
   ],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b2edfa-8a58-4a7a-b346-a0755da019c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:47:09,943 - WARNING - File /home/nguyent8/Repos/eye-ai-exec/notebooks/crop_multimodal_images.ipynb has been modified since last commit. Consider commiting before executing\n",
      "2025-03-30 15:47:10,438 - INFO - Materialize bag 4-4116... \n",
      "2025-03-30 15:47:11,433 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-30 15:47:12,354 - INFO - Loading /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116\n",
      "2025-03-30 15:47:12,886 - INFO - Creating new database for dataset: 4-4116 in /data/nguyent8/EyeAI_working/4-4116@330-B1Z0-2NHT.db\n",
      "2025-03-30 15:47:12,887 - INFO - Materialize bag 4-411G... \n",
      "2025-03-30 15:47:14,063 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-30 15:47:14,809 - INFO - Loading /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d70f7b3bfd0a0cd3931d4e2edbade797d/Dataset_4-411G\n",
      "2025-03-30 15:47:15,164 - INFO - Creating new database for dataset: 4-411G in /data/nguyent8/EyeAI_working/4-411G@330-B1Z0-GC2Y.db\n",
      "2025-03-30 15:47:15,165 - INFO - Materialize bag 2-7P5P... \n",
      "2025-03-30 15:47:16,223 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-30 15:47:17,204 - INFO - Loading /data/2-7P5P_52942baeabd3e1cee91bbbea4e58f3aca680a8f59aa72d4184823e7df474fd2a/Dataset_2-7P5P\n",
      "2025-03-30 15:47:23,735 - INFO - Creating new database for dataset: 2-7P5P in /data/nguyent8/EyeAI_working/2-7P5P@330-B1YY-G4RR.db\n",
      "2025-03-30 15:47:23,812 - INFO - Downloading assets ...\n",
      "2025-03-30 15:47:27,399 - INFO - File [/data/nguyent8/EyeAI_working/4-S51R/asset/optic_disk_crop_model.hdf5] transfer successful. 76.75 MB transferred at 25.46 MB/second. Elapsed time: 0:00:03.014719.\n",
      "2025-03-30 15:47:27,742 - INFO - Initialize status finished.\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    '4-4116', # Selected images for training\n",
    "    '4-411G', # Selected images for testing\n",
    "    '2-7P5P', # Full multimodal dataset\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.create_workflow(\n",
    "    name=\"Multimodal workflow\",\n",
    "    workflow_type=\"Multimodal workflow\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download,\n",
    "    assets = ['2-4JR6',],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of cropping multimodal images.\")\n",
    "\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d5a104-349c-48a7-8a8c-8ba1e249f901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching_dir: /data\n",
      "_working_dir: /data/nguyent8/EyeAI_working\n",
      "execution_rid: 4-S51R\n",
      "workflow_rid: 4-S51P\n",
      "asset_paths: [PosixPath('/data/nguyent8/EyeAI_working/4-S51R/asset/optic_disk_crop_model.hdf5')]\n",
      "configuration: datasets=[DatasetSpec(rid='4-4116', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0)), DatasetSpec(rid='4-411G', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0)), DatasetSpec(rid='2-7P5P', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0))] assets=['2-4JR6'] workflow=Workflow(name='Multimodal workflow', url='https://github.com/informatics-isi-edu/eye-ai-exec/blob/7199413c8e922b77a30ee9efee1f5223369c41c1--/notebooks/crop_multimodal_images.ipynb', workflow_type='Multimodal workflow', version=None, description='', rid=None, checksum='e69de29bb2d1d6434b8b29ae775ad8c2e48c5391') parameters={} description='Instance of cropping multimodal images.' argv=['/home/nguyent8/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/ipykernel_launcher.py', '-f', '/home/nguyent8/.local/share/jupyter/runtime/kernel-58a74d22-42b7-4b11-866b-8ca10afabfa0.json']\n"
     ]
    }
   ],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090db8d3-775b-4b88-9a75-beaa63f584b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds_bag = execution.datasets[0]\n",
    "testing_ds_bag = execution.datasets[1]\n",
    "multimodal_full_ds_bag = execution.datasets[2]\n",
    "\n",
    "crop_image_model = execution.asset_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea8e311b-c7ad-4f20-8b60-df91f8a369a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_bag(ds_bag: DatasetBag, multimodal_full_ds_bag: DatasetBag):\n",
    "    observation_table = ds_bag.get_table_as_dataframe('Observation')\n",
    "    image_table = ds_bag.get_table_as_dataframe('Image')\n",
    "    laterality_table = ds_bag.get_table_as_dataframe('Execution_Image_Fundus_Laterality')\n",
    "\n",
    "    image_table_filtered = image_table[['RID', 'Filename', 'Observation']].rename(columns={'RID': 'RID_Image'})\n",
    "    laterality_table_filtered = laterality_table[['Image', 'Image_Side']].rename(columns={'Image': 'RID_Image'})\n",
    "    image_laterality = pd.merge(image_table_filtered, laterality_table_filtered, left_on='RID_Image', right_on='RID_Image', how='inner')\n",
    "    observation_table_filtered = observation_table[['RID',  'Subject']].rename(columns={'RID': 'RID_Observation'})\n",
    "    image_laterality_observation = pd.merge(image_laterality, observation_table_filtered, left_on='Observation', right_on='RID_Observation', how='inner')\n",
    "\n",
    "    wide = EA.multimodal_wide(multimodal_full_ds_bag) \n",
    "    \n",
    "    image_observation_laterality_subject_wide = pd.merge(\n",
    "     wide, \n",
    "     image_laterality_observation, \n",
    "     left_on=['RID_Subject', 'Image_Side'], \n",
    "     right_on=['Subject', 'Image_Side'], \n",
    "     how='inner'\n",
    "    )\n",
    "\n",
    "    return image_observation_laterality_subject_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82a1b2bf-05e8-46e1-afbd-2cf8bbc93bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyent8/Repos/eye-ai-ml/eye_ai/eye_ai.py:425: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hvf_clean.loc[:, 'priority'] = hvf_clean['Field_Size'].map(priority)\n",
      "/home/nguyent8/Repos/eye-ai-ml/eye_ai/eye_ai.py:425: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hvf_clean.loc[:, 'priority'] = hvf_clean['Field_Size'].map(priority)\n"
     ]
    }
   ],
   "source": [
    "train_df = get_dataframe_from_bag(training_ds_bag, multimodal_full_ds_bag)\n",
    "test_df= get_dataframe_from_bag(testing_ds_bag, multimodal_full_ds_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adbaa602-7011-4c1d-842e-2c53ef86eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Ensure working_dir is a Path object\n",
    "working_dir = Path(\"~/working_dir\")\n",
    "\n",
    "# Save DataFrames as CSV files\n",
    "train_csv_path = working_dir / \"train.csv\"\n",
    "test_csv_path = working_dir / \"test.csv\"\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "test_df.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a178c2f6-33e4-4e33-a2e4-523dfad9f680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<deriva.core.ermrest_model.Column object 'eye-ai'.'Annotation'.'Annotation_Function' at 0x7f883b7a8a60>,\n",
       " <deriva.core.ermrest_model.Column object 'eye-ai'.'Annotation'.'Annotation_Type' at 0x7f883b7a8af0>,\n",
       " <deriva.core.ermrest_model.Column object 'eye-ai'.'Annotation'.'Fundus_Bounding_Box' at 0x7f883b7a89d0>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name = \"Image\"\n",
    "EA.find_features(table_name)[0].feature_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "536de7ee-527e-4cd4-b67f-48ddfff79100",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'Annotation'\n",
    "Feature = EA.feature_record_class(table_name, feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a07d7ff-19e6-4741-a523-d20efb25a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Feature Name"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Name: Fundus_Bounding_Box, Required: True',\n",
       " 'Name: Annotation_Function, Required: True',\n",
       " 'Name: Annotation_Type, Required: True']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(\n",
    "    Markdown('### Feature Name'),\n",
    "    [ f'Name: {c.name}, Required: {not c.nullok}' for c in Feature.feature.feature_columns]\n",
    ")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fb0f517-38c5-442f-bc78-7da22df44389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Type in module deriva.core.ermrest_model object:\n",
      "\n",
      "class Type(builtins.object)\n",
      " |  Type(type_doc)\n",
      " |  \n",
      " |  Named type.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, type_doc)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  prejson(self, prune=True)\n",
      " |  \n",
      " |  sqlite3_ddl(self) -> 'str'\n",
      " |      Return a SQLite3 column type DDL fragment for this type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl = [c for c in Feature.feature.feature_columns]\n",
    "help(cl[0].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fb6c452-cfbd-4c57-97dc-57903337a04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S51R/execution-asset/Image_Annotation')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Image_Annotation\")\n",
    "asset_path_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af5530-cb5f-4105-8f8b-453cce78f21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:50:02,751 - INFO - Start execution  ...\n",
      "2025-03-30 23:50:05,931 - INFO - Processing image /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116/data/asset/Image/2-660-IMAGE_0_(14).jpg : , trial 1, color channel grey, resize function imgResize_primary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:50:06,925 - INFO - Processing image /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116/data/asset/Image/2-660-IMAGE_0_(14).jpg : , trial 2, color channel green, resize function imgResize_primary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:50:07,884 - INFO - Processing image /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116/data/asset/Image/2-660-IMAGE_0_(14).jpg : , trial 3, color channel red, resize function imgResize_primary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:50:08,430 - INFO - Processing image /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116/data/asset/Image/2-660-IMAGE_0_(14).jpg : , trial 4, color channel blue, resize function imgResize_primary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:50:09,340 - INFO - Processing image /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116/data/asset/Image/2-660-IMAGE_0_(14).jpg : , trial 1, color channel grey, resize function imgResize_secondary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:50:10,333 - INFO - Processing image /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116/data/asset/Image/2-660-IMAGE_0_(14).jpg : , trial 2, color channel green, resize function imgResize_secondary\n"
     ]
    }
   ],
   "source": [
    "from vgg19_disk_crop_predict import preprocess_and_crop\n",
    "with execution.execute() as exec:\n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/train.csv',\n",
    "      '~/working_dir/output/output_train.csv',\n",
    "      'template.jpg',\n",
    "      str(asset_path_output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )\n",
    "    \n",
    "    preprocess_and_crop(\n",
    "      multimodal_full_ds_bag,\n",
    "      '~/working_dir/test.csv',\n",
    "      '~/working_dir/output/output_test.csv',\n",
    "      'template.jpg',\n",
    "      str(asset_path_output),\n",
    "      crop_image_model,\n",
    "      \"2-NK8E\",\n",
    "      \"Optic Nerve\",\n",
    "      False\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b020271a-3f2c-4b6c-8dce-11ed6eca6067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint test 1\n"
     ]
    }
   ],
   "source": [
    "print(\"checkpoint test 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38f97871-b6bc-48cb-b0cb-27e29ddcfcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deriva_ml.feature.ImageFeatureAnnotation"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageBoundingboxFeature = EA.feature_record_class(\"Image\", feature_name)\n",
    "ImageBoundingboxFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f3cfbf6-ccc7-4ead-a7c7-415cd236c9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_rids = []\n",
    "for file_name in os.listdir(asset_path_output):\n",
    "    image_rids.append(file_name.split(\"_\")[1].split('.')[0])\n",
    "image_rids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8af492-b43d-45ed-869c-b0bbe8e38dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the CSV\n",
    "csv = Path(\"~/working_dir/output/output_train.csv\")\n",
    "df = pd.read_csv(csv)\n",
    "\n",
    "# Create a mapping from Image RID to Worked Image Cropping Function\n",
    "cropping_func_map = dict(zip(df[\"Image RID\"], df[\"Worked Image Cropping Function\"]))\n",
    "cropping_func_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "baa3804e-8a38-41d5-9de2-cefbb4fe14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list\n",
    "for image_rid in image_rids:\n",
    "    print(image_rid)\n",
    "    if (asset_path_output / f\"Cropped_{image_rid}.svg\").exists() and image_rid in cropping_func_map:\n",
    "        image_bounding_box_feature_list = [\n",
    "            ImageBoundingboxFeature(\n",
    "                Image=image_rid,\n",
    "                Execution=execution.execution_rid,\n",
    "                Fundus_Bounding_Box=path / f\"Cropped_{image_rid}.svg\",\n",
    "                Annotation_Function=cropping_func_map.get(image_rid),\n",
    "                Annotation_Type='Optic Nerve',\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "faab0368-0d0c-45b6-87ca-222cf650b333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_bounding_box_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c89d5b-e159-4627-b36b-5bbdc77e255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.write_feature_file(image_bounding_box_feature_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
