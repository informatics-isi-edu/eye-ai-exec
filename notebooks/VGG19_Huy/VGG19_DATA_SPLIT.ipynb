{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fc8d04-85cc-4170-80f8-a7b7532a1414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2b2627-42fb-439f-9f82-76542f9e9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca223df5-f7d8-4844-9d08-66a788ca4b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced49616-0402-4263-a965-56c333c91bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 20:06:09,227 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n"
     ]
    }
   ],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41c627-4c58-4d42-b6ab-4621d58d62f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RID of source dataset, if any.\n",
    "source_dataset = '2-277G'\n",
    "\n",
    "# EA.add_term(vc.workflow_type, \"Create Dataset Workflow\", description=\"A workflow to test creating a new dataset in eyeAI\")\n",
    "# Workflow instance\n",
    "workflow_instance = Workflow(\n",
    "    name=\"Dataset splitter creation\",\n",
    "    url=\"https://github.com/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/VGG19_Huy/VGG19_DATA_SPLIT.ipynb\",\n",
    "    workflow_type=\"Create Dataset Workflow\"\n",
    ")\n",
    "# Configuration instance.\n",
    "\n",
    "# Set to False if you only need the metadata from the bag, and not the assets.\n",
    "download_assets = True\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    # Comment out the following line if you don't need the assets.\n",
    "    # datasets=[source_dataset] if download_assets else [],\n",
    "    datasets=[source_dataset],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Splitting the original dataset.\")\n",
    "\n",
    "# Initialize execution\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61986d93-e623-4b58-85bb-54139238be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5cb25f-bafa-4b69-b5df-c203d0bbf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag = DatasetBag(execution.dataset_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602bf69-677a-43bd-9340-2299b76c7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d2be8-107c-48fe-bac2-190482d3a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag.get_table_as_dataframe('Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888f32b-7d63-4439-bb4d-453b98c18fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_2_df =  EA.filter_angle_2(ds_bag)\n",
    "angle_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb758b-b6c4-4278-9e80-a26bd55b29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rids = angle_2_df.RID.tolist()\n",
    "print(len(image_rids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce0ab7-f210-4ca7-a950-473584f1598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, copy\n",
    "# <100 images = 10 sets\n",
    "# 100 to 999 = 5 sets\n",
    "# 1000 to 2999 = 3 sets\n",
    "# >=3000 = 1 set\n",
    "\n",
    "def range_split(images):\n",
    "    num_of_split = 0\n",
    "    if images < 100:\n",
    "        num_of_split = 10\n",
    "    elif images >= 100 and images < 1000:\n",
    "        num_of_split = 5\n",
    "    elif images >= 1000 and images < 3000:\n",
    "        num_of_split = 3\n",
    "    else:\n",
    "        num_of_split = 1\n",
    "    return num_of_split\n",
    "\n",
    "def split_dataset(image_rids):\n",
    "    num_image_split = [10, 200, 500, 1000, 2000, 3000]\n",
    "    res = {}\n",
    "    for num_images in num_image_split:\n",
    "        current_subset_sets = []\n",
    "        random.shuffle(image_rids)\n",
    "        curr_image_rids = image_rids\n",
    "        num_split = range_split(num_images)\n",
    "        for _ in range(num_split):\n",
    "            subset = curr_image_rids[:num_images]\n",
    "            current_subset_sets.append(subset)\n",
    "            curr_image_rids =  curr_image_rids[num_images:]\n",
    "        res[num_images] = current_subset_sets\n",
    "    return res \n",
    "\n",
    "sets = split_dataset(image_rids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab56158-aed4-4a20-b1c7-15a1ac67ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sets.items():\n",
    "    master_dataset = execution.create_dataset(['LAC'], description=f'The VGG19 master dataset consists of multiple sub-datasets, with each dataset containing {key} images.')\n",
    "    training_sets = []\n",
    "    for i, item in enumerate(value, start=1):\n",
    "        training_dataset = execution.create_dataset(['LAC', 'Training'], description=f'A VGG19 training dataset of {key} images, No {i}')\n",
    "        EA.add_dataset_members(dataset_rid=training_dataset, members=item)\n",
    "        training_sets.append(training_dataset)\n",
    "    EA.add_dataset_members(dataset_rid=master_dataset, members=training_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe72ef3-b448-4a75-a836-79d3743c43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
