{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36fdb206-becd-459e-8958-6b5e64506d44",
   "metadata": {},
   "source": [
    "## Initial Setup:\n",
    "This step initializes the necessary configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29948bf-af19-4328-8e4b-0216621f6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc74b1f-337b-4835-b866-2a631d274f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff9030-2b6e-4188-85fa-c17002d8423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3594e-61b1-4bb7-a895-4fbad9367934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ca6e7-b528-4fc3-83ae-7ecfb6bf658d",
   "metadata": {},
   "source": [
    "## Downloading Dataset:\n",
    "Downloading the datasets. We will work with three datasets: 2-A5T0 (train), 2-A5T2 (val), and 2-A5T4 (test). The dataset order when extracting is always set in the list provided when downloading. Additionally, this code will always download the latest version of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716415e-5986-4c3d-8aa9-c1f5960314f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RID of source dataset, if any.\n",
    "datasets = [\n",
    "            '2-A5T0',\n",
    "            '2-A5T2',\n",
    "            '2-A5T4',\n",
    "]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "EA.add_term(vc.workflow_type, \"VGG19 Model Train\", description=\"A workflow to train VGG19 model\")\n",
    "\n",
    "workflow_rid = EA.create_workflow(\n",
    "    name=\"VGG19 Model train\",\n",
    "    workflow_type=\"VGG19 Model Train\",\n",
    ")\n",
    "\n",
    "download_assets = True\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download if download_assets else [],\n",
    "    workflow=workflow_rid,\n",
    "    description=\"Instance of training VGG19 model\",\n",
    ")\n",
    "    \n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ab0e6-120d-43ee-97a8-d3e672266fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43fa59a-4089-4a54-9416-8eb3495f976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_train = execution.datasets[0]\n",
    "ds_bag_val = execution.datasets[1]\n",
    "ds_bag_test = execution.datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cfd5a-da8e-40dd-9796-8f248e1a1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = execution._working_dir / execution.execution_rid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63e606-0926-4570-9a79-4ef04aabbb81",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "Crop the images and move them to the designated folder for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7111f3-3746-4f04-996d-0985a8708abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path_cropped, csv_ds_bag_cropped = EA.create_cropped_images(ds_bag = ds_bag_train, \n",
    "                                                                              output_dir = output_dir / \"dataset\" / \"train\", \n",
    "                                                                              crop_to_eye=True)\n",
    "\n",
    "\n",
    "validation_image_path_cropped, validation_csv_cropped = EA.create_cropped_images(ds_bag = ds_bag_val,\n",
    "                                                                                 output_dir = output_dir / \"dataset\" / \"val\",\n",
    "                                                                                 crop_to_eye=True)\n",
    "\n",
    "test_image_path_cropped, test_csv_cropped = EA.create_cropped_images(ds_bag = ds_bag_test,\n",
    "                                                                     output_dir = output_dir \"dataset\" / \"test\",\n",
    "                                                                     crop_to_eye =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bdaec-20f1-4e4d-823c-fbae77d23c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%b_%d_%Y\") \n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_output_dir = execution._working_dir / execution.execution_rid / \"asset\"\n",
    "asset_output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ee89c-30a2-48ea-9028-1f23d1495db8",
   "metadata": {},
   "source": [
    "## Train and Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172870d0-e038-4029-81b6-e7308a4a1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_diagnosis_train import train_and_evaluate\n",
    "with execution.execute() as exec:\n",
    "        predictions_results, metrics_summary, model_save_path, training_history_csv = train_and_evaluate(\n",
    "            train_path=train_image_path_cropped,\n",
    "            valid_path=validation_image_path_cropped, \n",
    "            test_path=test_image_path_cropped, \n",
    "            model_path=asset_output_dir,\n",
    "            log_path=asset_output_dir,\n",
    "            eval_path=asset_output_dir,\n",
    "            model_name = f\"VGG19_Model_{ds_bag_train.dataset_rid}_{current_date}\"\n",
    "            )\n",
    "        print(\"Execution Results:\")\n",
    "        print(predictions_results, metrics_summary, model_save_path, training_history_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef30022-7fc4-4016-a778-77165e0a7c17",
   "metadata": {},
   "source": [
    "## Evaluate Only:\n",
    "If you already have a VGG19 model, provide its path here to evaluate it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f7835-ce67-4f16-aaf4-1cdb27b91b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"path/to/your/model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14202212-0609-4583-ae90-dbadcfca69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_diagnosis_train import evaluate_only\n",
    "with execution.execute() as exec:\n",
    "        predictions_results, metrics_summary = evaluate_only(\n",
    "            model_path = model_path, \n",
    "            model_name = f\"VGG19_Model_{ds_bag_train.dataset_rid}_{current_date}\", \n",
    "            test_path = test_image_path_cropped, \n",
    "            output_dir = asset_output_dir,\n",
    "        )\n",
    "        print(\"Execution Results:\")\n",
    "        print(predictions_results, metrics_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c3e7d-9e27-4cc3-8a7d-4afead42cb28",
   "metadata": {},
   "source": [
    "## Upload results:\n",
    "We now need to set up the paths to upload the files to the catalog. Please note that this process uploads a copy of the files, even when clean_folder=True. The original files will remain on your system in case you wish to revisit them later. However, you should consider deleting them afterward to conserve storage.\n",
    "\n",
    "Alternatively, you can move the files directly to the corresponding path created by execution.asset_file_path(). This ensures that you are uploading the original files instead of creating a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e593b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loop creates copies.\n",
    "for filename in os.listdir(asset_output_dir):\n",
    "    file_path = os.path.join(asset_output_dir, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        asset_type = \"\"\n",
    "        if filename.endswith(('csv', 'jpg', 'txt')):\n",
    "            asset_type = \"Model_Prediction\"\n",
    "        elif filename.endswith('pth'):\n",
    "            asset_type = \"Diagnosis_Model\"\n",
    "        if asset_type != \"\":\n",
    "            path = execution.asset_file_path(\n",
    "                asset_name=\"Execution_Asset\",\n",
    "                file_name=file_path,\n",
    "                asset_types=asset_type\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a3c1e-6ab2-4a64-ae71-dd6b1ec4eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
