{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36fdb206-becd-459e-8958-6b5e64506d44",
   "metadata": {},
   "source": [
    "## Initial Setup:\n",
    "This step initializes the necessary configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29948bf-af19-4328-8e4b-0216621f6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc74b1f-337b-4835-b866-2a631d274f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff9030-2b6e-4188-85fa-c17002d8423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3594e-61b1-4bb7-a895-4fbad9367934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ca6e7-b528-4fc3-83ae-7ecfb6bf658d",
   "metadata": {},
   "source": [
    "## Downloading Dataset:\n",
    "Downloading the datasets. We will work with three datasets: 2-A5T0 (train), 2-A5T2 (val), and 2-A5T4 (test). The dataset order when extracting is always set in the list provided when downloading. Additionally, this code will always download the latest version of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716415e-5986-4c3d-8aa9-c1f5960314f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RID of source dataset, if any.\n",
    "datasets = [\n",
    "            '2-A5T0',\n",
    "            '2-A5T2',\n",
    "            '2-A5T4',\n",
    "]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "EA.add_term(vc.workflow_type, \"VGG19 Model Train\", description=\"A workflow to train VGG19 model\")\n",
    "\n",
    "workflow_rid = EA.create_workflow(\n",
    "    name=\"VGG19 Model train\",\n",
    "    workflow_type=\"VGG19 Model Train\",\n",
    ")\n",
    "\n",
    "download_assets = True\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download if download_assets else [],\n",
    "    workflow=workflow_rid,\n",
    "    description=\"Instance of training VGG19 model\",\n",
    ")\n",
    "    \n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ab0e6-120d-43ee-97a8-d3e672266fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43fa59a-4089-4a54-9416-8eb3495f976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag_train = execution.datasets[0]\n",
    "ds_bag_val = execution.datasets[1]\n",
    "ds_bag_test = execution.datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cfd5a-da8e-40dd-9796-8f248e1a1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = execution._working_dir / execution.execution_rid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63e606-0926-4570-9a79-4ef04aabbb81",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "Crop the images and move them to the designated folder for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7111f3-3746-4f04-996d-0985a8708abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path_cropped, csv_ds_bag_cropped = EA.create_cropped_images(ds_bag = ds_bag_train, \n",
    "                                                                              output_dir = output_dir / \"train\", \n",
    "                                                                              crop_to_eye=True)\n",
    "\n",
    "\n",
    "validation_image_path_cropped, validation_csv_cropped = EA.create_cropped_images(ds_bag = ds_bag_val,\n",
    "                                                                                 output_dir = output_dir / \"val\",\n",
    "                                                                                 crop_to_eye=True)\n",
    "\n",
    "test_image_path_cropped, test_csv_cropped = EA.create_cropped_images(ds_bag = ds_bag_test,\n",
    "                                                                     output_dir = output_dir / \"test\",\n",
    "                                                                     crop_to_eye =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28035b-ad2e-4857-9903-7f026ac53260",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Model_Prediction\")\n",
    "asset_path_logs = execution.execution_asset_path(\"Training_Log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bdaec-20f1-4e4d-823c-fbae77d23c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%b_%d_%Y\") \n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ee89c-30a2-48ea-9028-1f23d1495db8",
   "metadata": {},
   "source": [
    "## Train and Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172870d0-e038-4029-81b6-e7308a4a1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_diagnosis_train import train_and_evaluate\n",
    "with execution.execute() as exec:\n",
    "        predictions_results, metrics_summary, model_save_path, training_history_csv = train_and_evaluate(\n",
    "            train_path=train_image_path_cropped,\n",
    "            valid_path=validation_image_path_cropped, \n",
    "            test_path=test_image_path_cropped, \n",
    "            model_path=asset_path_models,\n",
    "            log_path=asset_path_logs,\n",
    "            eval_path=asset_path_output,\n",
    "            model_name = f\"VGG19_Model_{ds_bag_train.dataset_rid}_{current_date}\"\n",
    "            )\n",
    "        print(\"Execution Results:\")\n",
    "        print(predictions_results, metrics_summary, model_save_path, training_history_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef30022-7fc4-4016-a778-77165e0a7c17",
   "metadata": {},
   "source": [
    "## Evaluate Only:\n",
    "If you already have a VGG19 model, provide its path here to evaluate it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f7835-ce67-4f16-aaf4-1cdb27b91b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"path/to/your/model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14202212-0609-4583-ae90-dbadcfca69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_diagnosis_train import evaluate_only\n",
    "with execution.execute() as exec:\n",
    "        predictions_results, metrics_summary = evaluate_only(\n",
    "            model_path = model_path, \n",
    "            model_name = f\"VGG19_Model_{ds_bag_train.dataset_rid}_{current_date}\", \n",
    "            test_path = test_image_path_cropped, \n",
    "            output_dir = asset_path_output,\n",
    "        )\n",
    "        print(\"Execution Results:\")\n",
    "        print(predictions_results, metrics_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c3e7d-9e27-4cc3-8a7d-4afead42cb28",
   "metadata": {},
   "source": [
    "## Upload results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a3c1e-6ab2-4a64-ae71-dd6b1ec4eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
