{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/VGG19_Diagnosis_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVq_jMdfx7Ni"
   },
   "source": [
    "# Multimodal Initial analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     !pip install deriva\n",
    "#     !pip install bdbag\n",
    "#     !pip install --upgrade --force pydantic\n",
    "#     !pip install git+https://github.com/informatics-isi-edu/deriva-ml git+https://github.com/informatics-isi-edu/eye-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "#%load_ext autoreload # autoreloads updates to local packages\n",
    "#%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\"))\n",
    "\n",
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "from models.severe.severity_analysis import Severity\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deriva_ml import DatasetSpec, ExecutionConfiguration, DerivaML, Workflow\n",
    "from deriva_ml import MLVocab as vc\n",
    "from deriva_ml.deriva_definitions import ColumnDefinition, BuiltinTypes\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "\n",
    "\n",
    "# Login\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "host = 'www.eye-ai.org'\n",
    "catalog_id = \"eye-ai\"\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n",
    "\n",
    "cache_dir = Path.home() / '/data'\n",
    "working_dir = Path.home() / '/data'\n",
    "EA = Severity(cache_dir= cache_dir, working_dir=working_dir)\n",
    "#EA = Severity(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir) # was giving an error for some reason 1/29/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.min_rows', 20)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####IF I DON'T WANNA RE-RUN BELOW, I HAVE MODELS SAVED AS BELOW. ----> SKIP TO \"ADD AGE TO TABLE\" CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save and access future things for easier access without having to rerun an execution which takes a long time\n",
    "asset_path = '/data/yukim3003/EyeAI_working/Execution_Assets/Multimodal_Analysis/'\n",
    "\n",
    "#loaded_train_path = asset_path + \"wide_train_raw.csv\"\n",
    "#loaded_test_path = asset_path + \"wide_test_raw.csv\" # last updated Dec 6 2024\n",
    "#wide_train_raw = pd.read_csv(loaded_train_path, index_col=0)\n",
    "#wide_test_raw = pd.read_csv(loaded_test_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = '2-C9PP'\n",
    "new_v_train = EA.dataset_version(train_dataset)\n",
    "\n",
    "# RID of source dataset, if any.\n",
    "test_dataset = '2-C9PR'\t\n",
    "new_v_test = EA.dataset_version(test_dataset)\n",
    "\n",
    "# Set to False if you only need the metadata from the bag, and not the assets.\n",
    "config = ExecutionConfiguration(\n",
    "    # Comment out the following line if you don't need the assets.\n",
    "    datasets=[DatasetSpec(rid=train_dataset, version=new_v_train, materialize=False), DatasetSpec(rid=test_dataset, version=new_v_test, materialize=False)],\n",
    "    assets=[],\n",
    "    workflow='2-A51W', \n",
    "    description=\"Multimodal GS v glaucoma workflow\")\n",
    "\n",
    "# Initialize execution\n",
    "execution = EA.create_execution(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to download configuration record that didn't work\n",
    "# configuration_record = EA.download_execution_configuration(configuration_rid='4-3RTJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imD3DJ4lx7Nm"
   },
   "source": [
    "Connect to Eye-AI catalog.  Configure to store data local cache and working directories.  Initialize Eye-AI for pending execution based on the provided configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old, before redoing EA : configuration_rid= \"2-CCD4\" # rid I created with my config containing minid for both train and test sets\n",
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag = execution.datasets[0]\n",
    "test_bag = execution.datasets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate multimodal wide table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_train_raw = EA.severity_analysis(train_bag)\n",
    "wide_test_raw = EA.severity_analysis(test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wide_train_raw))\n",
    "print(len(wide_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine wide_train_raw and wide_test_raw but label as train vs raw\n",
    "wide_full_raw = pd.concat([wide_train_raw, wide_test_raw], keys=['train', 'test']).reset_index(level=0).rename(columns={'level_0': 'source'})\n",
    "wide_full_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 01-29-2025: Alt method using saved wide_multimodal_full.csv from Aug 2024 to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide_full = pd.read_csv(asset_path + \"wide_multimodal_full.csv\")\n",
    "#wide_full = wide_full.rename(columns={'Side': 'Image_Side', 'Gender': 'Subject_Gender', 'Ethnicity': 'Subject_Ethnicity', 'Label': 'Condition_Label'})\n",
    "print(len(wide_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt using saved wide_train_raw and wide_test_raw from 12-26-2024 execution\n",
    "#wide_train_raw = pd.read_csv(\"/home/yukim3003/KY-Scratch/wide_train_raw-4-3R4P-122624.csv\", index_col=0)\n",
    "#wide_test_raw = pd.read_csv(\"/home/yukim3003/KY-Scratch/wide_test_raw-4-3R4R-122624.csv\", index_col=0)\n",
    "#len(wide_train_raw) + len(wide_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add age to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add age\n",
    "age_path = \"/data/yukim3003/EyeAI_working/Execution_Assets/Multimodal_Analysis/multimodal_subject_age.csv\"\n",
    "age_df = pd.read_csv(age_path)\n",
    "age_df.rename(columns={'RID': 'RID_Subject'}, inplace=True)\n",
    "#wide_train_raw = wide_train_raw.merge(age_df, on='RID_Subject', how='left')\n",
    "#wide_test_raw = wide_test_raw.merge(age_df, on='RID_Subject', how='left')\n",
    "wide_full_raw = wide_full_raw.merge(age_df, on='RID_Subject', how='left') # only if using the alt method with the original wide_multimodal_full.csv above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wide_full_raw)\n",
    "len(wide_full_raw['RID_Subject'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "demographic_fx = ['Subject_Gender', 'Subject_Ethnicity', 'Age']\n",
    "clinic_fx = ['LogMAR_VA', 'IOP'] # 'Gonioscopy' - mostly NaN, not standardized annotation # CCT - mostly NaN\n",
    "CDR_fx = ['CDR']\n",
    "RNFL_fx = ['Average_RNFL_Thickness(μm)'] # Average_C/D_Ratio - for RNFL-derived CDR\n",
    "RNFL_clockhr_fx = ['Clock_Hours_1', 'Clock_Hours_2', 'Clock_Hours_3', 'Clock_Hours_4', 'Clock_Hours_5', 'Clock_Hours_6', 'Clock_Hours_7', 'Clock_Hours_8', 'Clock_Hours_9', 'Clock_Hours_10', 'Clock_Hours_11', 'Clock_Hours_12'] # if I want to use each clock hour\n",
    "RNFL_quad_fx = ['Quadrants_S', 'Quadrants_N', 'Quadrants_T', 'Quadrants_I']\n",
    "RNFL_IS_fx = ['Quadrants_S', 'Quadrants_I']\n",
    "HVF_fx = ['MD', 'VFI'] # 'PSD' - mostly NaN. I think PSD and PSD.1 columns should be merged to use this column if desired\n",
    "GHT = ['GHT']\n",
    "\n",
    "# redefined for AGS 02-19-2025\n",
    "exam_fx = clinic_fx + CDR_fx\n",
    "RNFL_fx = RNFL_fx + RNFL_IS_fx # Average_C/D_Ratio - for RNFL-derived CDR\n",
    "HVF_fx = HVF_fx + GHT\n",
    "\n",
    "# All Project Fx\n",
    "all_fx_cols = demographic_fx + exam_fx + RNFL_fx + HVF_fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only keep rows that are not missing in ANY of all_fx_cols -- if not doing imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep rows that are not nan in ANY fx in all_fx_cols\n",
    "\n",
    "wide_full_raw= wide_full_raw.dropna(subset=all_fx_cols)\n",
    "print(len(wide_full_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process chart labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_chart_labels=True # if false, uses ICD10 labels instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_chart_labels:\n",
    "    chart_path = \"/home/yukim3003/chart_diagnosis_output-05-28-2025.csv\"\n",
    "    chart_df = pd.read_csv(chart_path)[['RID_Subject', 'Side', 'ICD-10 Label', 'chart_label']]\n",
    "    chart_df.rename(columns={'Side': 'Image_Side'}, inplace=True)\n",
    "    wide_full_raw = wide_full_raw.merge(chart_df, on=['RID_Subject', 'Image_Side'], how='left')\n",
    "    #wide_train_raw = wide_train_raw.merge(chart_df, on=['RID_Subject', 'Image_Side'], how='inner')\n",
    "    #wide_test_raw = wide_test_raw.merge(chart_df, on=['RID_Subject', 'Image_Side'], how='inner')\n",
    "\n",
    "    # drop rows with undesired chart labels\n",
    "    wide_full_raw = wide_full_raw[wide_full_raw['chart_label'].isin(['GS', 'POAG', 'PACG'])]\n",
    "\n",
    "    # set Condition_Label as chart label, and create different ICD 10 label column\n",
    "    wide_full_raw['ICD10_label_full'] = wide_full_raw['Condition_Label']\n",
    "    wide_full_raw['Condition_Label'] = wide_full_raw['chart_label']\n",
    "    \n",
    "    ####DON'T DO THE FOLLOWING WHICH REPLACED \"MISSING\" CHART LABELS (REALLY JUST THOSE LABELED WITH OTHER/NORMAL/NO DIAGNOSIS) WITH ICD10 LABEL\n",
    "    ## set Condition_Label to chart_label if not NAN, else just use original condition label\n",
    "    #wide_full_raw['Condition_Label'] = wide_full_raw['chart_label'].fillna(wide_full_raw['Condition_Label'])\n",
    "# else: by default Condition_Label is already ICD10 labels\n",
    "\n",
    "# drop rows missing labels for analysis\n",
    "wide_full_raw= wide_full_raw.dropna(subset='Condition_Label')\n",
    "\n",
    "# drop duplicate rows (there are a few patients, eg 2-7P38, that are for some reason duplicated): 1267 rows -> 1263 rows\n",
    "wide_full_raw = wide_full_raw.drop_duplicates(subset=['RID_Subject', 'Image_Side'], keep='first', inplace=False)\n",
    "print(len(wide_full_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate file to obtain rows missing chart label\n",
    "\"\"\"\n",
    "# obtain rows missing chart label\n",
    "num_missing_chart_label = wide_full_raw['chart_label'].isna().sum()\n",
    "print(\"Number missing chart label: \" + str(num_missing_chart_label))\n",
    "\n",
    "# add MRN to table\n",
    "mrn_path = \"/data/yukim3003/EyeAI_working/Execution_Assets/Multimodal_Analysis/multimodal_subject_age_MRN.csv\"\n",
    "mrn_df = pd.read_csv(mrn_path, dtype={'MRN': str})\n",
    "mrn_df.rename(columns={'RID': 'RID_Subject'}, inplace=True)\n",
    "wide_full_raw_mrns = wide_full_raw.merge(mrn_df, on='RID_Subject', how='left')\n",
    "\n",
    "missing_labels = wide_full_raw_mrns[wide_full_raw_mrns['chart_label'].isna()]\n",
    "selected_cols = ['RID_Subject', 'MRN', 'date_of_encounter_Clinic', 'date_of_encounter_Fundus', 'Provider', 'Image_Side', 'Condition_Label']\n",
    "excel=missing_labels[selected_cols]\n",
    "excel_path = '/home/yukim3003/chart_diagnosis_input_04-12-2025.csv'\n",
    "excel.to_csv(excel_path, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wide_full_raw['RID_Subject'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both eyes\n",
    "#wide_test = wide_full_raw[wide_full_raw['source'] == 'test'].drop(columns='source').reset_index(drop=True)\n",
    "#wide_test.to_csv('/home/yukim3003/wide_test_botheyes_04-18-2025.csv', index=False)\n",
    "#len(wide_test['RID_Subject'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new table with only more severe eye for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_ai.py:     def pick_severe_eye(self, df, rnfl_threshold, md_threshold):\n",
    "# (if only one eye has a label, that's automatically the more severe eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnfl_thresh = 0\n",
    "md_thresh = 0\n",
    "wide_full_severe = EA.pick_severe_eye(wide_full_raw, rnfl_thresh, md_thresh)\n",
    "#wide_train = EA.pick_severe_eye(wide_train_raw, rnfl_thresh, md_thresh)\n",
    "#wide_test = EA.pick_severe_eye(wide_test_raw, rnfl_thresh, md_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if choose to use better eye instead\n",
    "df_diff = wide_full_raw.merge(wide_full_severe, on=wide_full_raw.columns.tolist(), how='left', indicator=True)\n",
    "wide_full_better = df_diff[df_diff['_merge'] == 'left_only'].drop(columns=['_merge']) # less severe eye -- though technically the subjects that only have one eye included should also be included in the better eye analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_full = wide_full_severe\n",
    "len(wide_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for saving only -- generate a version of wide_full with severe eye only, before splitting into train/test\n",
    "#wide_full = EA.pick_severe_eye(wide_full_raw, 0, 0)\n",
    "#wide_full.to_csv(asset_path + 'wide_full082024_severeeye.csv')\n",
    "\n",
    "# save more severe eye raw data\n",
    "#wide_train.to_csv(asset_path + 'wide_train_fromfull082024_severeeye.csv') \n",
    "#wide_test.to_csv(asset_path + 'wide_test_fromfull082024_severeeye.csv')\n",
    "\n",
    "#wide_train_nothresh = EA.pick_severe_eye(wide_train_raw, 0, 0)\n",
    "#wide_test_nothresh = EA.pick_severe_eye(wide_test_raw, 0, 0)\n",
    "\n",
    "# Show which subjects changed eyes by adding thresholds\n",
    "#diff_values = wide_train.compare(wide_train_nothresh, align_axis=0, keep_shape=True, keep_equal=True) #keep_equal=False --> values that are equal are represented as NaN\n",
    "#diff_values = diff_values.drop_duplicates(keep=False) # drop rows that have a duplicate\n",
    "#print(\"# subjects where eye choice changed: %i\" % (len(diff_values)/2))\n",
    "#diff_values[['RID_Subject', 'Image_Side', 'Label', 'Average_RNFL_Thickness(μm)', 'MD', 'CDR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split - after removing all NAs to get final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: create my own 80-20 split from wide_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DON'T DO THIS-- SHOULD BE SPLITTING BY SUBJECT, WHEREAS THIS SPLITS BY EYE\n",
    "#wide_train, wide_test = train_test_split(wide_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# split using orig wide_train vs wide_test sets -- jk this would miss a bunch of patients though\n",
    "\n",
    "# split by subject:\n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "splitter = GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 42)\n",
    "split = splitter.split(wide_full, groups=wide_full['RID_Subject'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "wide_train = wide_full.iloc[train_inds]\n",
    "wide_test = wide_full.iloc[test_inds]\n",
    "\n",
    "print(len(wide_train))\n",
    "print(len(wide_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these so I can repeat my results in future\n",
    "#wide_train.to_csv(asset_path + 'wide_train_botheyes_02-18-2025.csv')\n",
    "#wide_test.to_csv(asset_path + 'wide_test_botheyes_02-18-2025.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Use labeled train vs test from EyeAI split in wide_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_train = wide_full[wide_full['source'] == 'train'].drop(columns='source').reset_index(drop=True)\n",
    "wide_test = wide_full[wide_full['source'] == 'test'].drop(columns='source').reset_index(drop=True)\n",
    "print(len(wide_train))\n",
    "print(len(wide_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide_test.to_csv('/home/yukim3003/wide_test_bettereye_04-18-2025.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### START HERE to use already generated data subsets ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate table of less severe eye only\n",
    "wide_train_severe = pd.read_csv(asset_path + 'wide_train_severeeye_02-09-2025.csv', index_col=0) # more severe eye\n",
    "wide_test_severe = pd.read_csv(asset_path + 'wide_test_severeeye_02-09-2025.csv', index_col=0)\n",
    "wide_train_both = pd.read_csv(asset_path + 'wide_train_botheyes_02-18-2025.csv', index_col=0) # both eyes\n",
    "wide_test_both = pd.read_csv(asset_path + 'wide_test_botheyes_02-18-2025.csv', index_col=0)\n",
    "\n",
    "df_diff = wide_train_both.merge(wide_train_severe, on=wide_train_both.columns.tolist(), how='left', indicator=True)\n",
    "wide_train_better = df_diff[df_diff['_merge'] == 'left_only'].drop(columns=['_merge']) # less severe eye\n",
    "df_diff = wide_test_both.merge(wide_test_severe, on=wide_test_both.columns.tolist(), how='left', indicator=True)\n",
    "wide_test_better = df_diff[df_diff['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which dataset to use\n",
    "wide_train = wide_train_severe\n",
    "wide_test = wide_test_severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_train['ICD10_label_full'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GS vs Glaucoma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjust fx_cols depending on what variables I want to include in model\n",
    "#fx_cols = demographic_fx\n",
    "#fx_cols = exam_fx\n",
    "#fx_cols = RNFL_fx\n",
    "#fx_cols = HVF_fx\n",
    "#fx_cols = RNFL_fx + HVF_fx\n",
    "\n",
    "# for univariate or all 4 domains or ML\n",
    "#fx_cols = all_fx_cols\n",
    "\n",
    "# ICD-10\n",
    "#fx_cols = [\"ICD10_label_full\"]\n",
    "\n",
    "# OLD: Domain knowledge fx\n",
    "#fx_cols = ['Age', 'Subject_Gender', 'LogMAR_VA', 'CDR'] + RNFL_fx + ['MD', 'GHT']  # Age, Subject_Gender, VA, CDR, avg RNFL, MD, GHT outside normal limits.\n",
    "ymethod=\"all_glaucoma\"\n",
    "\n",
    "# ALL is a required key if desiring to run univariate analyses, ridge, and elastic net\n",
    "list_of_fx_cols_to_run = {\n",
    "    'Demographics': demographic_fx,\n",
    "    'Exam': exam_fx, \n",
    "    'OCT': RNFL_fx,\n",
    "    'VF': HVF_fx,\n",
    "    'OCT+VF': RNFL_fx + HVF_fx,\n",
    "    'All Four Domains': all_fx_cols,\n",
    "    'ALL': all_fx_cols,\n",
    "    'ICD10': [\"ICD10_label_full\"],\n",
    "}\n",
    "\n",
    "models_glaucoma, X_train_overall, X_test_overall, y_train_overall, y_test_overall = EA.run_whole_analysis(list_of_fx_cols_to_run, wide_train, wide_test, ymethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_glaucoma.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Counts / data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X train size: \" + str(len(X_train_overall)))\n",
    "print(\"X test size: \" + str(len(X_test_overall)))\n",
    "totaln = len(X_train_overall) + len(X_test_overall)\n",
    "totaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(y_train_overall, return_counts=True)\n",
    "print(\"Train: \" + str(counts[0]) + \": \" + str(counts[1])) # #GS vs #Glaucoma\n",
    "print(\"Percent GS vs Glaucoma in TRAIN:\", counts[1] / sum(counts[1])) # percent\n",
    "\n",
    "counts = np.unique(y_test_overall, return_counts=True)\n",
    "print(\"Test: \" + str(counts[0]) + \": \" + str(counts[1])) # #GS vs #Glaucoma\n",
    "print(\"Percent GS vs Glaucoma in TEST:\", counts[1] / sum(counts[1])) # percent\n",
    "\n",
    "print(\"Percent Glaucoma in TOTAL:\", (sum(y_train_overall) + sum(y_test_overall)) / totaln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_overall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_fornumeric(col, dat1=X_train_overall, dat2=X_test_overall):\n",
    "    totaln = len(dat1) + len(dat2)\n",
    "    sumcol = np.sum(dat1[col]) + np.sum(dat2[col])\n",
    "    print(\"Mean \" + col + \": \" + str(round(sumcol/totaln, 4)))\n",
    "\n",
    "numeric_cols = [\"Age\", \"LogMAR_VA\", \"IOP\", \"CDR\", \"MD\", \"VFI\", \"Average_RNFL_Thickness(μm)\", \"Quadrants_S\", \"Quadrants_I\"]\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sd_fornumeric(col, dat1=X_train_overall, dat2=X_test_overall):\n",
    "    all_v = dat1[col].tolist() + dat2[col].tolist()\n",
    "    sd = np.std(all_v)\n",
    "    print(\"Std \" + col + \": \" + str(round(sd, 4)))\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print_sd_fornumeric(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_n_forcatvar(col, dat1=X_train_overall, dat2=X_test_overall):\n",
    "    totaln = len(dat1) + len(dat2)\n",
    "    n = sum(dat1[col]) + sum(dat2[col])\n",
    "    print(col + \": \" + str(n) + \" (\" + str(round(n/totaln*100, 2)) + \"%)\")\n",
    "\n",
    "cat_cols = ['Subject_Gender_F', 'Subject_Gender_M', 'Subject_Ethnicity_African Descent', 'Subject_Ethnicity_Asian',\n",
    "       'Subject_Ethnicity_Caucasian', 'Subject_Ethnicity_Latin American',\n",
    "       'Subject_Ethnicity_Other', 'GHT_Borderline',\n",
    "       'GHT_Outside Normal Limits', 'GHT_Within Normal Limits']\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat above but filter by glaucoma vs suspect\n",
    "train_mask = pd.Series(y_train_overall).astype(bool)\n",
    "X_train_glaucoma = X_train_overall[train_mask]\n",
    "X_train_GS = X_train_overall[~train_mask]\n",
    "\n",
    "test_mask = pd.Series(y_test_overall).astype(bool)\n",
    "X_test_glaucoma = X_test_overall[test_mask]\n",
    "X_test_GS = X_test_overall[~test_mask]\n",
    "\n",
    "print(\"GLAUCOMA\")\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col, dat1=X_train_glaucoma, dat2=X_test_glaucoma)\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col, dat1=X_train_glaucoma, dat2=X_test_glaucoma)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"SUSPECT\")\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col, dat1=X_train_GS, dat2=X_test_GS)\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col, dat1=X_train_GS, dat2=X_test_GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NAN\n",
    "### the number of rows with nan in any column will increase if I choose more features\n",
    "\n",
    "# count number / percent of rows with nan value\n",
    "num_rows_with_nan = X_train_overall.isnull().any(axis=1).sum()\n",
    "print (\"Number of train rows with any nan: %i\" % num_rows_with_nan)\n",
    "\n",
    "# Calculate the percentage of rows with NaN values\n",
    "print (\"Percent of train rows with any nan: %f\" % ((num_rows_with_nan / len(X_train_overall)) * 100))\n",
    "\n",
    "# count number / percent of rows with nan value\n",
    "num_rows_with_nan = X_test_overall.isnull().any(axis=1).sum()\n",
    "print (\"Number of test rows with any nan: %i\" % num_rows_with_nan)\n",
    "\n",
    "# Calculate the percentage of rows with NaN values\n",
    "print (\"Percent of test rows with any nan: %f\" % ((num_rows_with_nan / len(X_test_overall)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urgent glaucoma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moderate-to-severe glaucoma = MD<= -6 AND chart label of Glaucoma\n",
    "\n",
    "mild/GS = MD > -6 OR chart label of GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymethod = \"urgent_glaucoma\"\n",
    "\n",
    "# Redefine to not include HVF\n",
    "all_nonVF_fx_cols = demographic_fx + exam_fx + RNFL_fx\n",
    "\n",
    "# ALL is a required key if desiring to run univariate analyses, ridge, and elastic net\n",
    "list_of_fx_cols_to_run = {\n",
    "    'Demographics': demographic_fx,\n",
    "    'Exam': exam_fx, \n",
    "    'OCT': RNFL_fx,\n",
    "    'Exam+OCT': exam_fx + RNFL_fx,\n",
    "    'All Three Domains': all_nonVF_fx_cols,\n",
    "    'ALL': all_nonVF_fx_cols,\n",
    "    'for_counts_only': all_fx_cols, # included purely for counts/data info calcs below, so I can still calculate counts/stats for HVF measures # if this key isn't provided, uses ALL dataframes for counts\n",
    "}\n",
    "\n",
    "models_urgent, X_train_overall, X_test_overall, y_train_overall, y_test_overall = EA.run_whole_analysis(list_of_fx_cols_to_run, wide_train, wide_test, ymethod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Counts / data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### note I interchangeably-ish used X_train/test_overall and wide_train/test, because they should be the same rows given I preemptively dropped all NAs, but they're formatted differently\n",
    "\n",
    "print(\"X train size: \" + str(len(X_train_overall)))\n",
    "print(\"X test size: \" + str(len(X_test_overall)))\n",
    "totaln = len(X_train_overall) + len(X_test_overall)\n",
    "totaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(y_train_overall, return_counts=True)\n",
    "print(\"Train: \" + str(counts[0]) + \": \" + str(counts[1])) # #GS vs #Glaucoma\n",
    "print(\"Percent mild-GS vs mod-severe in TRAIN:\", counts[1] / sum(counts[1])) # percent\n",
    "\n",
    "counts = np.unique(y_test_overall, return_counts=True)\n",
    "print(\"Test: \" + str(counts[0]) + \": \" + str(counts[1])) # #GS vs #Glaucoma\n",
    "print(\"Percent mild-GS vs mod-severe in TEST:\", counts[1] / sum(counts[1])) # percent\n",
    "\n",
    "print(\"Percent mod-severe in TOTAL:\", (sum(y_train_overall) + sum(y_test_overall)) / totaln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_overall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_fornumeric(col, dat1=X_train_overall, dat2=X_test_overall):\n",
    "    totaln = len(dat1) + len(dat2)\n",
    "    sumcol = np.sum(dat1[col]) + np.sum(dat2[col])\n",
    "    print(\"Mean \" + col + \": \" + str(round(sumcol/totaln, 4)))\n",
    "\n",
    "numeric_cols = [\"Age\", \"LogMAR_VA\", \"IOP\", \"CDR\", \"MD\", \"VFI\", \"Average_RNFL_Thickness(μm)\", \"Quadrants_S\", \"Quadrants_I\"]\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col)\n",
    "\n",
    "def print_sd_fornumeric(col, dat1=X_train_overall, dat2=X_test_overall):\n",
    "    all_v = dat1[col].tolist() + dat2[col].tolist()\n",
    "    sd = np.std(all_v)\n",
    "    print(\"Std \" + col + \": \" + str(round(sd, 4)))\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print_sd_fornumeric(col)\n",
    "\n",
    "def print_n_forcatvar(col, dat1=X_train_overall, dat2=X_test_overall):\n",
    "    totaln = len(dat1) + len(dat2)\n",
    "    n = sum(dat1[col]) + sum(dat2[col])\n",
    "    print(col + \": \" + str(n) + \" (\" + str(round(n/totaln*100, 2)) + \"%)\")\n",
    "\n",
    "cat_cols = ['Subject_Gender_F', 'Subject_Gender_M', 'Subject_Ethnicity_African Descent', 'Subject_Ethnicity_Asian',\n",
    "       'Subject_Ethnicity_Caucasian', 'Subject_Ethnicity_Latin American',\n",
    "       'Subject_Ethnicity_Other', 'GHT_Borderline','GHT_Outside Normal Limits', 'GHT_Within Normal Limits']\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat above but filter by mod-severe vs mild-GS\n",
    "train_mask = pd.Series(y_train_overall).astype(bool)\n",
    "X_train_1 = X_train_overall[train_mask]\n",
    "X_train_0 = X_train_overall[~train_mask]\n",
    "\n",
    "test_mask = pd.Series(y_test_overall).astype(bool)\n",
    "X_test_1 = X_test_overall[test_mask]\n",
    "X_test_0 = X_test_overall[~test_mask]\n",
    "\n",
    "print(\"MOD-SEVERE\")\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col, dat1=X_train_1, dat2=X_test_1)\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col, dat1=X_train_1, dat2=X_test_1)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"MILD-GS\")\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col, dat1=X_train_0, dat2=X_test_0)\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col, dat1=X_train_0, dat2=X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (wide_train.Condition_Label=='GS') & (wide_train.MD<=-6)\n",
    "test_mask = (wide_test.Condition_Label=='GS') & (wide_test.MD<=-6)\n",
    "\n",
    "# since i removed all NAs, wide_train and X_train overall should match up\n",
    "X_train_1 = X_train_overall[train_mask]\n",
    "X_train_0 = X_train_overall[~train_mask]\n",
    "X_test_1 = X_test_overall[test_mask]\n",
    "X_test_0 = X_test_overall[~test_mask]\n",
    "\n",
    "print(\"GS yet MD<=-6\")\n",
    "print(\"Number: %s\" % str(len(X_train_1) + len(X_test_1)))\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col, dat1=X_train_1, dat2=X_test_1)\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col, dat1=X_train_1, dat2=X_test_1)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"NOT [GS yet MD<=-6] - not really useful info but i printed it anyways\")\n",
    "print(\"Number: %s\" % str(len(X_train_0) + len(X_test_0)))\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col, dat1=X_train_0, dat2=X_test_0)\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col, dat1=X_train_0, dat2=X_test_0)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "train_mask = (wide_train.Condition_Label=='GS') & (wide_train.MD>-6)\n",
    "test_mask = (wide_test.Condition_Label=='GS') & (wide_test.MD>-6)\n",
    "\n",
    "# since i removed all NAs, wide_train and X_train overall should match up\n",
    "X_train_1 = X_train_overall[train_mask]\n",
    "X_train_0 = X_train_overall[~train_mask]\n",
    "X_test_1 = X_test_overall[test_mask]\n",
    "X_test_0 = X_test_overall[~test_mask]\n",
    "\n",
    "print(\"GS with MD> -6\")\n",
    "print(\"Number: %s\" % str(len(X_train_1) + len(X_test_1)))\n",
    "for col in numeric_cols:\n",
    "    print_mean_fornumeric(col, dat1=X_train_1, dat2=X_test_1)\n",
    "for col in cat_cols:\n",
    "    print_n_forcatvar(col, dat1=X_train_1, dat2=X_test_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT multiple ROC curves\n",
    "- current version of this code requires running above multiple times for each roc curve I want to plot, then saving them manually and adding to global dictionary before plotting combined ROC curve\n",
    "- X_test and y_test have different #s for drop_NA bc drop_NA may drop diff # rows depending on which variables are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = {} # model label name: (model, associated X_test, associated y_test)\n",
    "# start with univarate models dict\n",
    "#models ={**models, **models_univariate} ## don't overwrite models just in case already contains stuff\n",
    "\n",
    "### No longer needed because variables are all named correctly now, and no longer renaming univariate labels\n",
    "\"\"\"\n",
    "# map model names\n",
    "key_mapping = {\n",
    "    #'Average_RNFL_Thickness(μm)': 'OCT',\n",
    "    #'MD': 'VF',\n",
    "    'ML Feature Selection (Elastic Net)': 'ML Elastic Net',\n",
    "    'HVF': 'VF',\n",
    "    'OCT+HVF': 'OCT+VF',\n",
    "    'CDR+OCT+HVF': 'CDR+OCT+VF'\n",
    "}\n",
    "# Function to rename keys in a dictionary\n",
    "def rename_keys(d, key_map):\n",
    "    return {key_map.get(k, k): v for k, v in d.items()}\n",
    "# Apply the renaming function to the dictionary\n",
    "models = rename_keys(models, key_mapping)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to combine 2 dictionaries\n",
    "#all_models = {**models_univariate, **selected_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which models to plot\n",
    "analysis = \"urgent_glaucoma\" # \"urgent_glaucoma\"\n",
    "\n",
    "#all_keys = ['Clinic Data', 'Demographics', CDR', 'OCT', 'HVF', 'OCT+HVF', 'CDR+OCT+HVF', 'All Four Domains', 'Domain Knowledge', 'All Features (Ridge)', 'ML Elastic Net'] # The keys you want\n",
    "\n",
    "if analysis==\"all_glaucoma\":\n",
    "    models= models_glaucoma\n",
    "    wanted_keys = ['Demographics', 'Exam', 'OCT', 'VF', 'OCT+VF', 'All Four Domains', 'ML Elastic Net'] # for models_glaucoma\n",
    "if analysis==\"urgent_glaucoma\":\n",
    "    models= models_urgent\n",
    "    wanted_keys = ['Demographics', 'Exam', 'OCT', 'Exam+OCT', 'All Three Domains', 'ML Elastic Net'] # for models_urgent\n",
    "selected_models = dict((k, models[k]) for k in wanted_keys if k in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figname = \"Figure_1_chartlabel-04-21-2025-using_EyeAI_splits-urgentglaucoma-severeeye-nomild.png\"\n",
    "\n",
    "plt.figure(figsize=(9, 8))\n",
    "for name, (m, xt, yt) in selected_models.items():\n",
    "    print (name)\n",
    "    fpr, tpr, auc, optimal_idx, optimal_threshold = EA.compute_performance_youden(m, xt, yt, plot=False)\n",
    "    #plt.plot(fpr, tpr, label=\"%s (AUC=%.3f, Youden's=%.3f)\" % (name, auc, (tpr[optimal_idx] - fpr[optimal_idx])))\n",
    "    plt.plot(fpr, tpr, label=\"%s (AUC=%.2f)\" % (name, auc))\n",
    "    #plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='red')\n",
    "    print (\"\")\n",
    "\n",
    "####NOT sure why I had this duplicated code...was I having issues before?###\n",
    "#name = \"All Four Domains\"\n",
    "#m, xt, yt = models[name]\n",
    "#print (name)\n",
    "#fpr, tpr, auc, optimal_idx, optimal_threshold = EA.compute_performance_youden(m, xt, yt, plot=False)\n",
    "##plt.plot(fpr, tpr, label=\"%s (AUC=%.3f, Youden's=%.3f)\" % (name, auc, (tpr[optimal_idx] - fpr[optimal_idx])))\n",
    "#plt.plot(fpr, tpr, label=\"%s (AUC=%.2f)\" % (name, auc))\n",
    "##plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='red')\n",
    "#print (\"\")\n",
    "\n",
    "#name = \"ML Elastic Net\"\n",
    "#m, xt, yt = models[name]\n",
    "#print (name)\n",
    "#fpr, tpr, auc, optimal_idx, optimal_threshold = EA.compute_performance_youden(m, xt, yt, plot=False)\n",
    "##plt.plot(fpr, tpr, label=\"%s (AUC=%.3f, Youden's=%.3f)\" % (name, auc, (tpr[optimal_idx] - fpr[optimal_idx])))\n",
    "#plt.plot(fpr, tpr, label=\"%s (AUC=%.2f)\" % (name, auc))\n",
    "##plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='red')\n",
    "#print (\"\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.savefig(\"/home/yukim3003/\" + figname, format=\"png\", dpi=300)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Save a high quality plot - nvm this has to be in same cell as original plot creation to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(configuration_records.working_dir/'Execution_Assets/Multimodal_Figures/')\n",
    "fig_path = configuration_records.working_dir/'Execution_Assets/Multimodal_Figures/Figure_1.png'\n",
    "\n",
    "# Save the plot with higher DPI\n",
    "plt.savefig(fig_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workaround\n",
    "plt.savefig(\"/home/yukim3003/Figure_1.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cache_path = asset_path + 'models_glaucoma_cache_04-21-2025.pkl'\n",
    "\n",
    "# Cache the models dictionary to a file\n",
    "with open(cache_path, 'wb') as f:\n",
    "    pickle.dump(models_glaucoma, f)\n",
    "\n",
    "cache_path = asset_path + 'models_urgent_cache_04-21-2025.pkl'\n",
    "\n",
    "# Cache the models dictionary to a file\n",
    "with open(cache_path, 'wb') as f:\n",
    "    pickle.dump(models_urgent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = asset_path + 'models_cache_04-12-2025.pkl'\n",
    "\n",
    "# To load the cached models dictionary later\n",
    "with open(cache_path, 'rb') as f:\n",
    "    cached_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access a specific saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a specific model that is saved\n",
    "name = \"ML Elastic Net\"\n",
    "m, xt, yt = cached_models[name]\n",
    "EA.compute_performance(m, xt, yt)\n",
    "EA.compute_performance_youden(m, xt, yt, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE NOT UPTODATE WITH CHANGES FOR ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIP A-B-C BELOW -- I REMOVED ALL NAS EARLIER IN CODE NOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Simple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = 'mean'\n",
    "# NOTE: the following code imputes X_test based on the imputer fitted to X_train\n",
    "\n",
    "\"\"\"\n",
    "STRATEGIES\n",
    "If “mean”, then replace missing values using the mean along each column. Can only be used with numeric data.\n",
    "\n",
    "If “median”, then replace missing values using the median along each column. Can only be used with numeric data.\n",
    "\n",
    "If “most_frequent”, then replace missing using the most frequent value along each column. Can be used with strings or numeric data. If there is more than one such value, only the smallest is returned.\n",
    "\n",
    "If “constant”, then replace missing values with fill_value. Can be used with strings or numeric data.\n",
    "\"\"\"\n",
    "\n",
    "# simple imputation fitted to X_train, but also applied to X_test\n",
    "# eye_ai.py: def simple_impute(self, X_train_keep_missing, X_test_keep_missing, strat = \"mean\"):\n",
    "X_train, X_test = EA.simple_impute(X_train_keep_missing, X_test_keep_missing)\n",
    "\n",
    "y_train = y_train_keep_missing\n",
    "y_test = y_test_keep_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## B) Multiple imputations (10 imputations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good article on MCAR vs MAR vs MNAR and how to appropriately handle missing values in each case: https://datascience.stackexchange.com/questions/116622/what-should-you-do-with-nan-values\n",
    "\n",
    "# return list of pandas dataframes, each containing 1 of 10 imputations\n",
    "# eye_ai.py:     def mult_impute_missing(self, X, train_data=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputedsets = EA.mult_impute_missing(X_train_keep_missing) # list of 10 imputed X_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputedsets = EA.mult_impute_missing(X_test_keep_missing, train_data=X_test_keep_missing) # Impute test data using model fit with training data, not with test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_keep_missing\n",
    "y_test = y_test_keep_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Drop NA\n",
    "### DON'T use this with the univariate loop -- incorrectly drops rows (dropNA in univariate loop instead to drop only for the univariate variable in question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with nan\n",
    "X_train = X_train_keep_missing.dropna()\n",
    "X_test = X_test_keep_missing.dropna()\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "\n",
    "y_train = y_train_keep_missing[y_train_keep_missing.index.isin(X_train.index)]\n",
    "y_test = y_test_keep_missing[y_test_keep_missing.index.isin(X_test.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferred to eye_ai.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    def model_summary(self, model, X_train):\n",
    "    def calc_stats(self, y_pred, y_test):\n",
    "    def compute_performance(self, model, X_test, y_test):\n",
    "    def compute_performance_youden(self, model, X_test, y_test, plot=True):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Multivariate Logistic Regression DROPNA or SIMPLEIMPUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferred to severity_analysis.py as methods univariate_analysis, multivariate_logreg, multivariate_ridge_elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Multivariate Logistic Regression MULTIPLE IMPUTATIONS\n",
    "### To check if what I did is best method: used mode of y_pred, and averaged prediction probabilities of each imputed model to determine AUC, and averaged p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_ai.py: \n",
    "#     def compute_performance_mice(self, logreg_models, Xtest_finals, y_test):\n",
    "#     def model_summary_mice(self, logreg_models, Xtrain_finals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to do prediction after multiple imputation:\n",
    "# https://github.com/amices/mice/issues/82\n",
    "# https://stackoverflow.com/questions/68460923/how-to-do-the-prediction-after-multiple-imputation-with-mice-package\n",
    "logreg_models = []\n",
    "Xtrain_finals = []\n",
    "Xtest_finals = []\n",
    "\n",
    "# MUST DROP REFERENCE COLUMN FOR ONE-HOT-ENCODED VARIABLES\n",
    "#chosen_ref_labels = ['GHT_Within Normal Limits', 'Subject_Gender_M', 'Subject_Ethnicity_Other']\n",
    "chosen_ref_labels = ['GHT_Within Normal Limits','GHT_Borderline', 'Subject_Gender_M', 'Subject_Ethnicity_Other']\n",
    "penalty=None#'l1', 'l2', 'elasticnet', or None\n",
    "solver='saga' # 'lbfgs', 'saga' (only saga supports l1 and elasticnet)\n",
    "\n",
    "for X_train, X_test in zip(X_train_imputedsets, X_test_imputedsets):\n",
    "    # NORMAL LOGISTIC REGRESSION\n",
    "    drop_cols = [x for x in X_train.columns if x in chosen_ref_labels]\n",
    "    X_train_dropped = X_train.drop(columns=drop_cols)\n",
    "    X_test_dropped = X_test.drop(columns=drop_cols)\n",
    "\n",
    "    logreg = LogisticRegression(random_state=16, solver=solver, max_iter=1000, penalty=penalty)\n",
    "    logreg.fit(X_train_dropped, y_train)\n",
    "    logreg_models.append(logreg)\n",
    "\n",
    "    Xtrain_finals.append(X_train_dropped)\n",
    "    Xtest_finals.append(X_test_dropped)\n",
    "\n",
    "EA.model_summary_mice(logreg_models, Xtrain_finals)\n",
    "EA.compute_performance_mice(logreg_models, Xtest_finals, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Alternative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't have to onehotencode, but xgboost performs better if does\n",
    "# keep dummy variables, don't drop ref label for decision trees\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "drop_NA=True\n",
    "if drop_NA:\n",
    "    # Drop NA if desired\n",
    "    x = X_train_keep_missing.dropna()\n",
    "    x_t = X_test_keep_missing.dropna()\n",
    "\n",
    "    y = y_train[y_train.index.isin(x.index)]\n",
    "    y_t = y_test[y_test.index.isin(x_t.index)]\n",
    "\n",
    "print(x.columns)\n",
    "\n",
    "#model = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=0) # bagged SVC\n",
    "#model=BaggingClassifier() # bagged decision trees (bc DecisionTree is default)\n",
    "model=SVC(probability=True) # probability=True to enable predict_proba function (slow)\n",
    "clf = model.fit(x,y)\n",
    "\n",
    "# define cross-validation evaluation procedure\n",
    "k = 10\n",
    "cv = RepeatedStratifiedKFold(n_splits=k, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x, y, scoring='roc_auc', cv=cv)\n",
    "# summarize performance\n",
    "print('Mean AUC using %i-fold cross-validation: %.3f' % (k, mean(scores)))# AUC from 10-fold cv on TRAINING set, as opposed to AUC on test set computed in compute_performance -- if this better than AUC for test set, then model probably overfit\n",
    "print(\"\")\n",
    "\n",
    "# test performance\n",
    "EA.compute_performance(clf, x_t, y_t)\n",
    "EA.compute_performance_youden(clf, x_t, y_t)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
