{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c3f6e9b-57c2-4dd5-82bc-5834f32b1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     !pip install deriva\n",
    "#     !pip install bdbag\n",
    "#     !pip install --upgrade --force pydantic\n",
    "#     !pip install git+https://github.com/informatics-isi-edu/deriva-ml git+https://github.com/informatics-isi-edu/eye-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d235d595-c68f-4146-a0b7-fb2c754c9cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16c603cb-e1e1-4c90-8a91-a3e44451cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "# import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "633c4d60-a01f-4b16-816f-228dc849ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 07:02:36,888 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 07:02:36,889 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c1b7779-06d0-4678-adbe-a411da14ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "\n",
    "cache_dir = '/data'        # Directory in which to cache materialized BDBags for datasets\n",
    "working_dir = '/data'    # Directory in which to place output files for later upload.\n",
    "\n",
    "configuration_rid = \"2-C8RG\" # rid\n",
    "# Change the confi_file with bag_url=[\"minid: train\", \"minid: Valid\", \"minid: test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8ee651c-3c59-4f75-8f8b-2f8f41d79f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 07:02:43,456 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 07:02:43,457 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    }
   ],
   "source": [
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7c50050-65da-4130-b56a-1d3fde5959b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 07:02:45,456 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json] transfer successful. 0.97 KB transferred. Elapsed time: 0:00:00.000060.\n",
      "2024-06-28 07:02:45,457 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json]\n",
      "2024-06-28 07:02:45,495 - INFO - Configuration validation successful!\n",
      "2024-06-28 07:02:53,169 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json] transfer successful. 0.69 KB transferred. Elapsed time: 0:00:00.000098.\n",
      "2024-06-28 07:02:53,169 - INFO - Verifying SHA256 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json]\n",
      "2024-06-28 07:02:53,369 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv] transfer successful. 0.34 KB transferred. Elapsed time: 0:00:00.000062.\n",
      "2024-06-28 07:02:53,369 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv]\n",
      "2024-06-28 07:02:53,583 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv] transfer successful. 0.15 KB transferred. Elapsed time: 0:00:00.000057.\n",
      "2024-06-28 07:02:53,583 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'caching_dir': PosixPath('/data'),\n",
       " 'working_dir': PosixPath('/data/sreenidhi/EyeAI_working'),\n",
       " 'vocabs': {'Workflow_Type': [{'name': 'VGG19_Catalog_Model_LACDHS_laterality_training',\n",
       "    'rid': '2-C8RM'}],\n",
       "  'Execution_Asset_Type': [{'name': 'VGG19_Catalog_Model_LACDHS_laterality_training',\n",
       "    'rid': '2-C8RP'}]},\n",
       " 'execution_rid': '2-C8RJ',\n",
       " 'workflow_rid': '2-C8RR',\n",
       " 'bag_paths': [PosixPath('/data/2-277G_6aa1a6861eee5a79bce4bf071065355f95a066c2a1ff326089d43048a7e0f185/Dataset_2-277G'),\n",
       "  PosixPath('/data/2-277J_81c873a311aa6a67cf2eef44bd9056cb19181b299a6e44327ea3553616f18725/Dataset_2-277J'),\n",
       "  PosixPath('/data/2-277M_8c4b855c2752e098580a5bb0d1b63a8cedde4462805fe74cddc912a72fb39963/Dataset_2-277M')],\n",
       " 'assets_paths': [PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'),\n",
       "  PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv'),\n",
       "  PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv')],\n",
       " 'configuration_path': PosixPath('/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json')}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Initiate an Execution\n",
    "configuration_records = EA.execution_init(configuration_rid=configuration_rid)\n",
    "configuration_records.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d005a2a-2edc-4d35-b508-969f2f2be5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigurationRecord(caching_dir=PosixPath('/data'), working_dir=PosixPath('/data/sreenidhi/EyeAI_working'), vocabs={'Workflow_Type': [Term(name='VGG19_Catalog_Model_LACDHS_laterality_training', rid='2-C8RM')], 'Execution_Asset_Type': [Term(name='VGG19_Catalog_Model_LACDHS_laterality_training', rid='2-C8RP')]}, execution_rid='2-C8RJ', workflow_rid='2-C8RR', bag_paths=[PosixPath('/data/2-277G_6aa1a6861eee5a79bce4bf071065355f95a066c2a1ff326089d43048a7e0f185/Dataset_2-277G'), PosixPath('/data/2-277J_81c873a311aa6a67cf2eef44bd9056cb19181b299a6e44327ea3553616f18725/Dataset_2-277J'), PosixPath('/data/2-277M_8c4b855c2752e098580a5bb0d1b63a8cedde4462805fe74cddc912a72fb39963/Dataset_2-277M')], assets_paths=[PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'), PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv'), PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv')], configuration_path=PosixPath('/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aff0eff0-f063-412c-b382-01d0a82ab33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_train = pd.read_csv(configuration_records.assets_paths[1])['ID'].to_list()\n",
    "exclude_valid = pd.read_csv(configuration_records.assets_paths[2])['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99f6175f-2fc7-48b5-b2a7-6bc537e7857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def create_LACDHS_laterality_dataset(train_dir: str, validation_dir: str, test_dir: str, output_dir: str, exclude_train: list = [], exclude_valid: list = []) -> tuple:\n",
    "    \"\"\"\n",
    "    Creates a dataset for LACDHS laterality classification by organizing images into train, valid, and test folders\n",
    "    based on their Image_Laterality.\n",
    "\n",
    "    Parameters:\n",
    "    - train_dir (str): Path to the raw train dataset bag.\n",
    "    - validation_dir (str): Path to the raw validation dataset bag.\n",
    "    - test_dir (str): Path to the raw test dataset bag.\n",
    "    - output_dir (str): Path to the output directory where the organized dataset will be created.\n",
    "    - exclude_train (list): List of image RIDs to exclude from the train set.\n",
    "    - exclude_valid (list): List of image RIDs to exclude from the validation set.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the paths to the train, validation, and test directories.\n",
    "    \"\"\"\n",
    "    def process_dataset(bag_path: str, output_subdir: str, exclude_list: list = []):\n",
    "        image_csv_path = os.path.join(bag_path, 'data', 'Image.csv')\n",
    "        image_df = pd.read_csv(image_csv_path)\n",
    "        image_root_path = os.path.join(bag_path, 'data', 'assets', 'Image')\n",
    "\n",
    "        for _, row in image_df.iterrows():\n",
    "            if row['RID'] not in exclude_list:\n",
    "                laterality = row['Image_Side_Vocab']\n",
    "                filename = row['Filename']\n",
    "                src_path = os.path.join(image_root_path, filename)\n",
    "                dst_dir = os.path.join(output_dir, output_subdir, laterality)\n",
    "                os.makedirs(dst_dir, exist_ok=True)\n",
    "                dst_path = os.path.join(dst_dir, filename)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    # Process train dataset\n",
    "    process_dataset(train_dir, 'train', exclude_train)\n",
    "\n",
    "    # Process validation dataset\n",
    "    process_dataset(validation_dir, 'valid', exclude_valid)\n",
    "\n",
    "    # Process test dataset\n",
    "    process_dataset(test_dir, 'test')\n",
    "\n",
    "    train_path = os.path.join(output_dir, 'train')\n",
    "    valid_path = os.path.join(output_dir, 'valid')\n",
    "    test_path = os.path.join(output_dir, 'test')\n",
    "\n",
    "    return train_path, valid_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "334ed1a5-4a9c-4478-a110-6555a5066622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/sreenidhi/EyeAI_working')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_records.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1076c83-5acc-4668-bcef-bd00998ace6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset path: /data/sreenidhi/EyeAI_working/train\n",
      "Validation dataset path: /data/sreenidhi/EyeAI_working/valid\n",
      "Test dataset path: /data/sreenidhi/EyeAI_working/test\n"
     ]
    }
   ],
   "source": [
    "# @title Data Preprocessing (Filtering Image.csv for just Field_2 Images)\n",
    "train_dir = configuration_records.bag_paths[0] # path to the raw train dataset\n",
    "validation_dir = configuration_records.bag_paths[1]\n",
    "test_dir = configuration_records.bag_paths[2]\n",
    "\n",
    "exclude_train = pd.read_csv(configuration_records.assets_paths[1])['ID'].to_list()\n",
    "exclude_valid = pd.read_csv(configuration_records.assets_paths[2])['ID'].to_list()\n",
    "\n",
    "# Call the create_LACDHS_angle_dataset function\n",
    "train_path, valid_path, test_path = create_LACDHS_laterality_dataset(\n",
    "    train_dir=str(train_dir),\n",
    "    validation_dir=str(validation_dir),\n",
    "    test_dir=str(test_dir),\n",
    "    output_dir=str(configuration_records.working_dir),\n",
    "    exclude_train=exclude_train,\n",
    "    exclude_valid=exclude_valid\n",
    ")\n",
    "\n",
    "# Print the paths to verify\n",
    "print(\"Train dataset path:\", train_path)\n",
    "print(\"Validation dataset path:\", valid_path)\n",
    "print(\"Test dataset path:\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45475801-2b48-4930-9fe2-befc1a79423d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b600173-42b1-49d1-8602-2dac5ad97f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing train folder:\n",
      "  2SK0: 13574 images\n",
      "  2SK2: 13593 images\n",
      "Total images in train: 27167\n",
      "\n",
      "Analyzing valid folder:\n",
      "  2SK2: 4530 images\n",
      "  2SK0: 4534 images\n",
      "Total images in valid: 9064\n",
      "\n",
      "Analyzing test folder:\n",
      "  2SK0: 1640 images\n",
      "  2SK2: 1648 images\n",
      "Total images in test: 3288\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "def analyze_lacdhs_angle_dataset(base_path):\n",
    "    main_folders = ['train', 'valid', 'test']\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nAnalyzing {main_folder} folder:\")\n",
    "        \n",
    "        total_files = 0\n",
    "        for angle_folder in os.listdir(main_folder_path):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            if os.path.isdir(angle_folder_path):\n",
    "                file_count = count_files(angle_folder_path)\n",
    "                print(f\"  {angle_folder}: {file_count} images\")\n",
    "                total_files += file_count\n",
    "        \n",
    "        print(f\"Total images in {main_folder}: {total_files}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "analyze_lacdhs_angle_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f149a-dbf7-44e3-8d15-0daa2f3158cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_lacdhs_angle_dataset(base_path, samples_per_angle=6):\n",
    "    main_folders = ['train', 'valid', 'test']\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nVisualizing samples from {main_folder} folder:\")\n",
    "        \n",
    "        angle_folders = [f for f in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, f))]\n",
    "        \n",
    "        # Calculate grid size\n",
    "        n_angles = len(angle_folders)\n",
    "        n_cols = samples_per_angle\n",
    "        n_rows = n_angles\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3.5))\n",
    "        fig.suptitle(f'Sample Images from {main_folder.capitalize()} Set', fontsize=16)\n",
    "        \n",
    "        for i, angle_folder in enumerate(angle_folders):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            image_files = [f for f in os.listdir(angle_folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            if len(image_files) < samples_per_angle:\n",
    "                print(f\"Warning: Not enough images in {angle_folder}. Using all available images.\")\n",
    "                selected_files = image_files\n",
    "            else:\n",
    "                selected_files = random.sample(image_files, samples_per_angle)\n",
    "            \n",
    "            for j, image_file in enumerate(selected_files):\n",
    "                img_path = os.path.join(angle_folder_path, image_file)\n",
    "                img = Image.open(img_path)\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "                # Add image filename as title for each subplot\n",
    "                axes[i, j].set_title(image_file, fontsize=8)\n",
    "                \n",
    "                if j == 0:\n",
    "                    axes[i, j].set_ylabel(angle_folder, rotation=0, labelpad=40, va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95, bottom=0.05, left=0.2, right=0.98)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print confirmation of angles\n",
    "        print(f\"Angles in {main_folder} set:\")\n",
    "        for angle in angle_folders:\n",
    "            print(f\"  - {angle}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "# visualize_lacdhs_angle_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e6312b8-9faa-4ea5-9f2e-4de7380ffb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = str(EA.working_dir) + \"/Execution_Assets/\" + configuration_records.vocabs['Execution_Asset_Type'][0].name\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49177652-13f5-4464-99fe-bc5a240e2557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a799f240-96f7-473a-b9b4-3feb8cf6e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path = str(configuration_records.assets_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f93ec10b-be38-404c-9a96-4df4f0e3ca1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper_parameters_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42b57610-80ee-43a1-9d43-c27f4acf3896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"rotation_range\": -6,\n",
      "    \"width_shift_range\": 0.049283662164352315,\n",
      "    \"height_shift_range\": 0.062129040368351915,\n",
      "    \"horizontal_flip\": true,\n",
      "    \"vertical_flip\": true,\n",
      "    \"zoom_range\": -0.03493437617512693,\n",
      "    \"brightness_range\": 0.016808387649284325,\n",
      "    \"use_class_weights\": true,\n",
      "    \"pooling\": \"global_average\",\n",
      "    \"dense_layers\": 2,\n",
      "    \"units_layer_0\": 512,\n",
      "    \"activation_func_0\": \"sigmoid\",\n",
      "    \"batch_norm_0\": true,\n",
      "    \"dropout_0\": 0.10646478371824658,\n",
      "    \"units_layer_1\": 64,\n",
      "    \"activation_func_1\": \"relu\",\n",
      "    \"batch_norm_1\": false,\n",
      "    \"dropout_1\": 0.2830490167548361,\n",
      "    \"fine_tune_at\": 0,\n",
      "    \"fine_tuning_learning_rate_adam\": 1.1688327470992886e-05,\n",
      "    \"batch_size\": 32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(best_hyper_parameters_json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aeccf0bb-c5b7-4d04-a84c-32e98e9870b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27167 images belonging to 2 classes.\n",
      "Found 9064 images belonging to 2 classes.\n",
      "Found 3288 images belonging to 2 classes.\n",
      "train_generator.class_indices :  {'2SK0': 0, '2SK2': 1}\n",
      "validation_generator.class_indices :  {'2SK0': 0, '2SK2': 1}\n",
      "test_generator.class_indices :  {'2SK0': 0, '2SK2': 1}\n",
      "Epoch 1/100\n",
      "849/849 [==============================] - 634s 735ms/step - loss: 0.0984 - roc_auc_score: 0.9931 - f1_score_normal: 0.9657 - accuracy_score: 0.9665 - val_loss: 0.0422 - val_roc_auc_score: 0.9966 - val_f1_score_normal: 0.9895 - val_accuracy_score: 0.9897\n",
      "Epoch 2/100\n",
      "849/849 [==============================] - 622s 729ms/step - loss: 0.0424 - roc_auc_score: 0.9971 - f1_score_normal: 0.9887 - accuracy_score: 0.9891 - val_loss: 0.0390 - val_roc_auc_score: 0.9972 - val_f1_score_normal: 0.9894 - val_accuracy_score: 0.9897\n",
      "Epoch 3/100\n",
      "849/849 [==============================] - 630s 738ms/step - loss: 0.0373 - roc_auc_score: 0.9974 - f1_score_normal: 0.9904 - accuracy_score: 0.9909 - val_loss: 0.0451 - val_roc_auc_score: 0.9966 - val_f1_score_normal: 0.9891 - val_accuracy_score: 0.9894\n",
      "Epoch 4/100\n",
      "849/849 [==============================] - 632s 743ms/step - loss: 0.0322 - roc_auc_score: 0.9978 - f1_score_normal: 0.9925 - accuracy_score: 0.9927 - val_loss: 0.0375 - val_roc_auc_score: 0.9969 - val_f1_score_normal: 0.9907 - val_accuracy_score: 0.9908\n",
      "Epoch 5/100\n",
      "849/849 [==============================] - 630s 740ms/step - loss: 0.0287 - roc_auc_score: 0.9982 - f1_score_normal: 0.9931 - accuracy_score: 0.9932 - val_loss: 0.0616 - val_roc_auc_score: 0.9969 - val_f1_score_normal: 0.9817 - val_accuracy_score: 0.9821\n",
      "Epoch 6/100\n",
      "849/849 [==============================] - 617s 725ms/step - loss: 0.0266 - roc_auc_score: 0.9985 - f1_score_normal: 0.9932 - accuracy_score: 0.9937 - val_loss: 0.0379 - val_roc_auc_score: 0.9970 - val_f1_score_normal: 0.9920 - val_accuracy_score: 0.9919\n",
      "Epoch 7/100\n",
      "849/849 [==============================] - 629s 738ms/step - loss: 0.0224 - roc_auc_score: 0.9987 - f1_score_normal: 0.9943 - accuracy_score: 0.9945 - val_loss: 0.0399 - val_roc_auc_score: 0.9967 - val_f1_score_normal: 0.9923 - val_accuracy_score: 0.9923\n",
      "Epoch 8/100\n",
      "849/849 [==============================] - 627s 736ms/step - loss: 0.0201 - roc_auc_score: 0.9989 - f1_score_normal: 0.9946 - accuracy_score: 0.9948 - val_loss: 0.0434 - val_roc_auc_score: 0.9966 - val_f1_score_normal: 0.9905 - val_accuracy_score: 0.9908\n",
      "Epoch 9/100\n",
      "849/849 [==============================] - 629s 739ms/step - loss: 0.0168 - roc_auc_score: 0.9993 - f1_score_normal: 0.9952 - accuracy_score: 0.9956 - val_loss: 0.0471 - val_roc_auc_score: 0.9959 - val_f1_score_normal: 0.9911 - val_accuracy_score: 0.9912\n",
      "Epoch 10/100\n",
      "849/849 [==============================] - ETA: 0s - loss: 0.0148 - roc_auc_score: 0.9996 - f1_score_normal: 0.9958 - accuracy_score: 0.9957Restoring model weights from the end of the best epoch: 2.\n",
      "849/849 [==============================] - 630s 740ms/step - loss: 0.0148 - roc_auc_score: 0.9996 - f1_score_normal: 0.9958 - accuracy_score: 0.9957 - val_loss: 0.0518 - val_roc_auc_score: 0.9958 - val_f1_score_normal: 0.9903 - val_accuracy_score: 0.9907\n",
      "Epoch 10: early stopping\n",
      "103/103 [==============================] - 131s 1s/step - loss: 0.0548 - roc_auc_score: 0.9956 - f1_score_normal: 0.9845 - accuracy_score: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 09:11:02,641 - INFO - Test results - [0.054773248732089996, 0.9955582022666931, 0.9845349192619324, 0.9857056140899658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Eval results: [0.054773248732089996, 0.9955582022666931, 0.9845349192619324, 0.9857056140899658]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sreenidhi/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-06-28 09:11:02,934 - INFO - VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024 Model trained, Model and training history are saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# @title Execute Training algorithm\n",
    "\n",
    "from eye_ai.models.vgg19_lacdhs_laterality_train import main\n",
    "\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "  main(train_path=train_path,\n",
    "       valid_path=valid_path, \n",
    "       test_path=test_path, \n",
    "       output_path=output_path,\n",
    "       best_hyperparameters_json_path=best_hyper_parameters_json_path,\n",
    "       model_name=\"VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024\"\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "916dc9b5-12d3-4b2f-81c3-25e01c2310e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "341b95cb-0c7a-4e6b-aaa8-b5be262412bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3288 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 09:23:18,804 - INFO - Data saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# @title Execute Evaluation algorithm\n",
    "from eye_ai.models.vgg19_lacdhs_laterality_predict import prediction\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "    prediction(\n",
    "        model_path=output_path + '/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5',\n",
    "        cropped_image_path=test_path,\n",
    "        output_dir=Path(output_path),\n",
    "        best_hyperparameters_json_path=best_hyper_parameters_json_path\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "933ec6fc-517b-4e4c-a62a-ec66c36b3bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3288 images belonging to 2 classes.\n",
      "True labels:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Predictions:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Data saved to predictions.csv\n",
      "Accuracy: 0.985705596107056\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      1640\n",
      "         1.0       0.99      0.98      0.99      1648\n",
      "\n",
      "    accuracy                           0.99      3288\n",
      "   macro avg       0.99      0.99      0.99      3288\n",
      "weighted avg       0.99      0.99      0.99      3288\n",
      "\n",
      "AUC Score: 0.9963329534690979\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def f1_score_normal(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "model = tf.keras.models.load_model(output_path + '/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5',\n",
    "                                       custom_objects={'f1_score_normal': f1_score_normal})\n",
    "def preprocess_input_vgg19(x):\n",
    "    return tf.keras.applications.vgg19.preprocess_input(x)\n",
    "\n",
    "graded_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg19)\n",
    "\n",
    "classes = {'2SK0': 0, '2SK2': 1}\n",
    "\n",
    "graded_test_generator = graded_test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=data['batch_size'],\n",
    "    class_mode='binary',\n",
    "    classes=classes,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "# Make sure to reset the generator before starting the predictions\n",
    "# graded_test_generator.reset()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Initialize lists to store file names, true labels, and predicted labels\n",
    "filenames = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "scores = []\n",
    "\n",
    "# Iterate over all batches in the graded_test_generator\n",
    "\n",
    "for i in range(len(graded_test_generator)):\n",
    "    # Get a batch of data\n",
    "    batch_data = graded_test_generator[i]\n",
    "    image_batch, label_batch = batch_data[0], batch_data[1]\n",
    "    batch_filenames = graded_test_generator.filenames[i * graded_test_generator.batch_size : (i + 1) * graded_test_generator.batch_size]\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "    # append bacth data to lists\n",
    "    scores.extend(predictions)\n",
    "\n",
    "    # Binarize the predictions\n",
    "    predictions = tf.where(predictions < 0.5, 0, 1).numpy()\n",
    "\n",
    "    # Append batch data to lists\n",
    "    filenames.extend(batch_filenames)\n",
    "    y_true.extend(label_batch)\n",
    "    y_pred.extend(predictions)\n",
    "\n",
    "    # For debugging, print the first batch's results\n",
    "    if i == 0:\n",
    "        # print(\"Image batch:\")\n",
    "        # print(image_batch)\n",
    "        print(\"True labels:\")\n",
    "        print(label_batch)\n",
    "        print(\"Predictions:\")\n",
    "        print(predictions)\n",
    "\n",
    "# Write to CSV file\n",
    "# with open('predictions_with_correct_predictions_and_probability_score_SG_1_NG_0.csv', 'w', newline='') as file: #s\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Filename', 'True Label', 'Prediction', 'Probability Score'])\n",
    "\n",
    "#     for i in range(len(filenames)):\n",
    "#         writer.writerow([filenames[i], y_true[i], y_pred[i], scores[i]])\n",
    "\n",
    "print(\"Data saved to predictions.csv\")\n",
    "\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = np.mean(np.array(y_pred) == np.array(y_true))\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Generate a classification report and AUC score\n",
    "print('Classification Report:\\n', classification_report(y_true, y_pred))\n",
    "print('AUC Score:', roc_auc_score(y_true, scores))\n",
    "\n",
    "# Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57e9502f-634a-4c50-96a2-43e89d096f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scikit-learn Metrics:\n",
      "ROC AUC: 0.9963329534690979\n",
      "F1 Score: 0.9857055630515777\n",
      "F1 Score Normal: 0.9857273003340419\n",
      "Precision: 0.9866261398176291\n",
      "Recall: 0.9848300970873787\n",
      "Accuracy: 0.985705596107056\n",
      "Balanced Accuracy: 0.9857077314705186\n",
      "Matthews correlation coefficient: 0.9714127672916003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "# Calculate metrics using scikit-learn\n",
    "sklearn_roc_auc = roc_auc_score(y_true, scores)\n",
    "sklearn_f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "sklearn_f1_score_normal = f1_score(y_true, y_pred)\n",
    "sklearn_precision = precision_score(y_true, y_pred)\n",
    "sklearn_recall = recall_score(y_true, y_pred)\n",
    "sklearn_accuracy = accuracy_score(y_true, y_pred)\n",
    "sklearn_balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "sklearn_matthews_corrcoef = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "print(f'\\nScikit-learn Metrics:')\n",
    "print(f'ROC AUC: {sklearn_roc_auc}')\n",
    "print(f'F1 Score: {sklearn_f1_score}')\n",
    "print(f'F1 Score Normal: {sklearn_f1_score_normal}') #t\n",
    "print(f'Precision: {sklearn_precision}')\n",
    "print(f'Recall: {sklearn_recall}')\n",
    "print(f'Accuracy: {sklearn_accuracy}')\n",
    "print(f'Balanced Accuracy: {sklearn_balanced_accuracy}')\n",
    "print(f'Matthews correlation coefficient: {sklearn_matthews_corrcoef}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17a367dd-445a-41f9-bc97-354e6def6100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 09:54:32,765 - INFO - Initializing uploader: GenericUploader v1.7.1 [Python 3.10.13, Linux-5.10.210-201.852.amzn2.x86_64-x86_64-with-glibc2.26]\n",
      "2024-06-28 09:54:32,767 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 09:54:32,768 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n",
      "2024-06-28 09:54:32,818 - INFO - Checking for updated configuration...\n",
      "2024-06-28 09:54:32,959 - INFO - Updated configuration found.\n",
      "2024-06-28 09:54:32,962 - INFO - Scanning files in directory [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training]...\n",
      "2024-06-28 09:54:32,963 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5].\n",
      "2024-06-28 09:54:32,963 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/training_history_VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.csv].\n",
      "2024-06-28 09:54:32,964 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/predictions_results.csv].\n",
      "2024-06-28 09:54:32,964 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5]\n",
      "2024-06-28 09:54:32,965 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5].\n",
      "2024-06-28 09:54:32,966 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5]. Please wait...\n",
      "2024-06-28 09:54:33,527 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 09:54:38,117 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.h5] upload successful. 232.71 MB transferred at 53.27 MB/second. Elapsed time: 0:00:04.368521.\n",
      "2024-06-28 09:54:38,291 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/training_history_VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.csv]\n",
      "2024-06-28 09:54:38,292 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/training_history_VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.csv].\n",
      "2024-06-28 09:54:38,292 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/training_history_VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.csv]. Please wait...\n",
      "2024-06-28 09:54:38,304 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/training_history_VGG19_Catalog_LAC_DHS_Laterality_Trained_model_June_27_2024.csv] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 09:54:38,413 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/predictions_results.csv]\n",
      "2024-06-28 09:54:38,414 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/predictions_results.csv].\n",
      "2024-06-28 09:54:38,414 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/predictions_results.csv]. Please wait...\n",
      "2024-06-28 09:54:38,426 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_laterality_training/predictions_results.csv] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 09:54:38,607 - INFO - File upload processing completed: 3 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n",
      "2024-06-28 09:54:38,715 - INFO - Initializing uploader: GenericUploader v1.7.1 [Python 3.10.13, Linux-5.10.210-201.852.amzn2.x86_64-x86_64-with-glibc2.26]\n",
      "2024-06-28 09:54:38,716 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-28 09:54:38,717 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n",
      "2024-06-28 09:54:38,752 - INFO - Checking for updated configuration...\n",
      "2024-06-28 09:54:38,861 - INFO - Updated configuration found.\n",
      "2024-06-28 09:54:38,863 - INFO - Scanning files in directory [/data/sreenidhi/EyeAI_working/Execution_Metadata]...\n",
      "2024-06-28 09:54:38,864 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json].\n",
      "2024-06-28 09:54:38,865 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt].\n",
      "2024-06-28 09:54:38,865 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-multimodal_df_join.json].\n",
      "2024-06-28 09:54:38,865 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json]\n",
      "2024-06-28 09:54:38,866 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json].\n",
      "2024-06-28 09:54:38,867 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json]. Please wait...\n",
      "2024-06-28 09:54:38,878 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 09:54:38,973 - INFO - Updating catalog for file [Execution_Config-vgg19_catalog_model_training_LACDHS_laterality_sreenidhi_june_27_2024.json]\n",
      "2024-06-28 09:54:39,462 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt]\n",
      "2024-06-28 09:54:39,463 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt].\n",
      "2024-06-28 09:54:39,464 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt]. Please wait...\n",
      "2024-06-28 09:54:39,475 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 09:54:39,492 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-multimodal_df_join.json]\n",
      "2024-06-28 09:54:39,493 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-multimodal_df_join.json].\n",
      "2024-06-28 09:54:39,493 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-multimodal_df_join.json]. Please wait...\n",
      "2024-06-28 09:54:39,503 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-multimodal_df_join.json] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-28 09:54:39,519 - INFO - File upload processing completed: 3 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n"
     ]
    }
   ],
   "source": [
    "# # @title Save Execution Assets (model) and Metadata\n",
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bb207-df9b-4ddc-933c-045eb08388fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
