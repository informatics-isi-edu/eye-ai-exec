{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/VGG19_Diagnosis_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVq_jMdfx7Ni"
   },
   "source": [
    "# VGG19 Training --- Fine tuning on Van's Labels\n",
    "\n",
    "This notebook is used to train VGG19 model for glacoma diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0B5DczZgx7Nl"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     !pip install deriva\n",
    "#     !pip install bdbag\n",
    "#     !pip install --upgrade --force pydantic\n",
    "#     !pip install git+https://github.com/informatics-isi-edu/deriva-ml git+https://github.com/informatics-isi-edu/eye-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgmzhX4Fx7Nm"
   },
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "# import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw-bW4bORlqQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imD3DJ4lx7Nm"
   },
   "source": [
    "Connect to Eye-AI catalog.  Configure to store data local cache and working directories.  Initialize Eye-AI for pending execution based on the provided configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m5U3w6SPx7Nn"
   },
   "outputs": [],
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "\n",
    "cache_dir = '/data'        # Directory in which to cache materialized BDBags for datasets\n",
    "working_dir = '/data'    # Directory in which to place output files for later upload.\n",
    "\n",
    "configuration_rid = \"2-C94P\" # rid\n",
    "# Change the confi_file with bag_url=[\"minid: train\", \"minid: Valid\", \"minid: test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkHsSCJXx7Nn"
   },
   "outputs": [],
   "source": [
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kCIfOvbUXTGB"
   },
   "outputs": [],
   "source": [
    "# @title Initiate an Execution\n",
    "configuration_records = EA.execution_init(configuration_rid=configuration_rid)\n",
    "configuration_records.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_train = pd.read_csv(configuration_records.assets_paths[1])['ID'].to_list()\n",
    "exclude_valid = pd.read_csv(configuration_records.assets_paths[2])['ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUuTRgyg7Ys1"
   },
   "outputs": [],
   "source": [
    "# @title Data Preprocessing (Filtering Image.csv for just Field_2 Images)\n",
    "train_dir = configuration_records.bag_paths[2] # path to the raw train dataset\n",
    "validation_dir = configuration_records.bag_paths[3]\n",
    "test_dir = configuration_records.bag_paths[4]\n",
    "\n",
    "train_cropped_image_path, train_cropped_csv = EA.create_cropped_images(str(train_dir),\n",
    "                                                                       output_dir = str(EA.working_dir) +'/train',\n",
    "                                                                       crop_to_eye=True,\n",
    "                                                                       exclude_list=exclude_train)\n",
    "validation_cropped_image_path, validation_cropped_csv = EA.create_cropped_images(str(validation_dir),\n",
    "                                                                                 output_dir = str(EA.working_dir) +'/valid',\n",
    "                                                                                 crop_to_eye=True,\n",
    "                                                                                 exclude_list=exclude_valid)\n",
    "test_cropped_image_path, test_cropped_csv = EA.create_cropped_images(str(test_dir),\n",
    "                                                                     output_dir = str(EA.working_dir) +'/test',\n",
    "                                                                     crop_to_eye=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # without no optic disc images\n",
    "\n",
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "def analyze_directory(base_path):\n",
    "    main_folders = ['train', 'test', 'valid']\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nAnalyzing {main_folder} folder:\")\n",
    "        \n",
    "        image_cropped_path = os.path.join(main_folder_path, 'Image_cropped')\n",
    "        if not os.path.exists(image_cropped_path):\n",
    "            print(\"Image_cropped folder not found\")\n",
    "            continue\n",
    "        \n",
    "        total_files = 0\n",
    "        for subfolder in os.listdir(image_cropped_path):\n",
    "            subfolder_path = os.path.join(image_cropped_path, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                file_count = count_files(subfolder_path)\n",
    "                print(f\"  {subfolder}: {file_count} files\")\n",
    "                total_files += file_count\n",
    "        \n",
    "        print(f\"Total files in {main_folder}: {total_files}\")\n",
    "\n",
    "# Assuming you're running this script from the directory containing train, test, and valid folders\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\" #os.getcwd()\n",
    "analyze_directory(base_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = str(EA.working_dir) + \"/Execution_Assets/\" + configuration_records.vocabs['Execution_Asset_Type'][0].name\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path = str(configuration_records.assets_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Execute Training algorithm\n",
    "from eye_ai.models.vgg19_diagnosis_fine_tune_train import main\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "  main(train_path=train_cropped_image_path,\n",
    "       valid_path=validation_cropped_image_path, \n",
    "       test_path=test_cropped_image_path, \n",
    "       output_path = output_path,\n",
    "       best_hyperparameters_json_path = best_hyper_parameters_json_path,\n",
    "       model_name = \"VGG19_Catalog_LAC_DHS_Cropped_Data_exlcuding_no_Optic_disc_fundus_Trained_model_June_24_2024_Van_Fine_Tuned\",\n",
    "       original_model_path = str(configuration_records.assets_paths[3])\n",
    "       )\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHqtgNpxrISs"
   },
   "outputs": [],
   "source": [
    "# @title Save Execution Assets (model) and Metadata\n",
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
