{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3f6e9b-57c2-4dd5-82bc-5834f32b1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     !pip install deriva\n",
    "#     !pip install bdbag\n",
    "#     !pip install --upgrade --force pydantic\n",
    "#     !pip install git+https://github.com/informatics-isi-edu/deriva-ml git+https://github.com/informatics-isi-edu/eye-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d235d595-c68f-4146-a0b7-fb2c754c9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c603cb-e1e1-4c90-8a91-a3e44451cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "# import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633c4d60-a01f-4b16-816f-228dc849ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 12:32:29,050 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-30 12:32:29,051 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1b7779-06d0-4678-adbe-a411da14ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "\n",
    "cache_dir = '/data'        # Directory in which to cache materialized BDBags for datasets\n",
    "working_dir = '/data'    # Directory in which to place output files for later upload.\n",
    "\n",
    "configuration_rid = \"2-C8ZG\" # rid\n",
    "# Change the confi_file with bag_url=[\"minid: train\", \"minid: Valid\", \"minid: test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ee651c-3c59-4f75-8f8b-2f8f41d79f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 12:32:29,094 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-30 12:32:29,095 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    }
   ],
   "source": [
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c50050-65da-4130-b56a-1d3fde5959b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 12:32:30,879 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json] transfer successful. 0.99 KB transferred. Elapsed time: 0:00:00.000115.\n",
      "2024-06-30 12:32:30,880 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json]\n",
      "2024-06-30 12:32:30,917 - INFO - Configuration validation successful!\n",
      "2024-06-30 12:32:48,169 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json] transfer successful. 0.69 KB transferred. Elapsed time: 0:00:00.000051.\n",
      "2024-06-30 12:32:48,169 - INFO - Verifying SHA256 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json]\n",
      "2024-06-30 12:32:48,416 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv] transfer successful. 0.34 KB transferred. Elapsed time: 0:00:00.000069.\n",
      "2024-06-30 12:32:48,417 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv]\n",
      "2024-06-30 12:32:48,666 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv] transfer successful. 0.15 KB transferred. Elapsed time: 0:00:00.000051.\n",
      "2024-06-30 12:32:48,667 - INFO - Verifying MD5 checksum for downloaded file [/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'caching_dir': PosixPath('/data'),\n",
       " 'working_dir': PosixPath('/data/sreenidhi/EyeAI_working'),\n",
       " 'vocabs': {'Workflow_Type': [{'name': 'VGG19_Catalog_Model_LACDHS_quality_training',\n",
       "    'rid': '2-C8WA'}],\n",
       "  'Execution_Asset_Type': [{'name': 'VGG19_Catalog_Model_LACDHS_quality_training',\n",
       "    'rid': '2-C8WC'}]},\n",
       " 'execution_rid': '2-C91T',\n",
       " 'workflow_rid': '2-C8ZM',\n",
       " 'bag_paths': [PosixPath('/data/2-36BW_772f62deab4b12b67bf6fa0cd347a095ec28f75aa11c9c9f068e22ee390aec36/Dataset_2-36BW'),\n",
       "  PosixPath('/data/2-39FY_1d2a0510049e238d0206d75476122ce12750ea9a5da642328afc62d52bd34813/Dataset_2-39FY'),\n",
       "  PosixPath('/data/2-277M_8c4b855c2752e098580a5bb0d1b63a8cedde4462805fe74cddc912a72fb39963/Dataset_2-277M')],\n",
       " 'assets_paths': [PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'),\n",
       "  PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv'),\n",
       "  PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv')],\n",
       " 'configuration_path': PosixPath('/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Initiate an Execution\n",
    "configuration_records = EA.execution_init(configuration_rid=configuration_rid)\n",
    "configuration_records.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d005a2a-2edc-4d35-b508-969f2f2be5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigurationRecord(caching_dir=PosixPath('/data'), working_dir=PosixPath('/data/sreenidhi/EyeAI_working'), vocabs={'Workflow_Type': [Term(name='VGG19_Catalog_Model_LACDHS_quality_training', rid='2-C8WA')], 'Execution_Asset_Type': [Term(name='VGG19_Catalog_Model_LACDHS_quality_training', rid='2-C8WC')]}, execution_rid='2-C91T', workflow_rid='2-C8ZM', bag_paths=[PosixPath('/data/2-36BW_772f62deab4b12b67bf6fa0cd347a095ec28f75aa11c9c9f068e22ee390aec36/Dataset_2-36BW'), PosixPath('/data/2-39FY_1d2a0510049e238d0206d75476122ce12750ea9a5da642328afc62d52bd34813/Dataset_2-39FY'), PosixPath('/data/2-277M_8c4b855c2752e098580a5bb0d1b63a8cedde4462805fe74cddc912a72fb39963/Dataset_2-277M')], assets_paths=[PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'), PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/train_no_optic_disc_image_ids.csv'), PosixPath('/data/sreenidhi/EyeAI_working/Execution_Assets/valid_no_optic_disc_image_ids.csv')], configuration_path=PosixPath('/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27ebba9-43da-48e3-848d-f60636ba0e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/2-39FY_1d2a0510049e238d0206d75476122ce12750ea9a5da642328afc62d52bd34813/Dataset_2-39FY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['690J', '692J', nan, '2-4DQP'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir=str(configuration_records.bag_paths[1]) \n",
    "\n",
    "print(train_dir)\n",
    "\n",
    "subject_csv_path = os.path.join(train_dir, 'data', 'Diagnosis.csv')\n",
    "\n",
    "subject_df = pd.read_csv(subject_csv_path)\n",
    "subject_df\n",
    "\n",
    "subject_df.Image_Quality_Vocab.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4504515e-0656-41a4-8398-2b127723ef73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_Quality_Vocab\n",
       "690J      1537\n",
       "692J       131\n",
       "2-4DQP       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_df.Image_Quality_Vocab.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d839acf-fb9a-482f-acc5-4f25ad9e974d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>RCT</th>\n",
       "      <th>RMT</th>\n",
       "      <th>RCB</th>\n",
       "      <th>RMB</th>\n",
       "      <th>Cup/Disk_Ratio</th>\n",
       "      <th>Image</th>\n",
       "      <th>Process</th>\n",
       "      <th>Diagnosis_Vocab</th>\n",
       "      <th>Diagnosis_Tag</th>\n",
       "      <th>Diagnosis_Status</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Image_Quality_Vocab</th>\n",
       "      <th>Execution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-35PW</td>\n",
       "      <td>2023-09-18 23:36:22.840003+00</td>\n",
       "      <td>2023-11-30 01:00:36.043948+00</td>\n",
       "      <td>https://auth.globus.org/fb1b3a7f-f953-418d-83e...</td>\n",
       "      <td>https://auth.globus.org/3769492a-b197-4063-952...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>A5K8</td>\n",
       "      <td>C1NC</td>\n",
       "      <td>2SKC</td>\n",
       "      <td>2-4F76</td>\n",
       "      <td>C1SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-35PY</td>\n",
       "      <td>2023-09-18 23:36:27.324847+00</td>\n",
       "      <td>2023-11-30 01:00:36.043948+00</td>\n",
       "      <td>https://auth.globus.org/fb1b3a7f-f953-418d-83e...</td>\n",
       "      <td>https://auth.globus.org/3769492a-b197-4063-952...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7RHY</td>\n",
       "      <td>C1NC</td>\n",
       "      <td>2SKC</td>\n",
       "      <td>2-4F76</td>\n",
       "      <td>C1SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-35Q0</td>\n",
       "      <td>2023-09-18 23:36:43.443651+00</td>\n",
       "      <td>2023-11-30 01:00:36.043948+00</td>\n",
       "      <td>https://auth.globus.org/fb1b3a7f-f953-418d-83e...</td>\n",
       "      <td>https://auth.globus.org/3769492a-b197-4063-952...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9ECE</td>\n",
       "      <td>C1NC</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>2-4F76</td>\n",
       "      <td>C1SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-35Q2</td>\n",
       "      <td>2023-09-18 23:47:04.965927+00</td>\n",
       "      <td>2023-11-30 01:00:36.043948+00</td>\n",
       "      <td>https://auth.globus.org/fb1b3a7f-f953-418d-83e...</td>\n",
       "      <td>https://auth.globus.org/3769492a-b197-4063-952...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9KZ4</td>\n",
       "      <td>C1NC</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>2-4F76</td>\n",
       "      <td>C1SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-35Q4</td>\n",
       "      <td>2023-09-18 23:47:13.305401+00</td>\n",
       "      <td>2023-11-30 01:00:36.043948+00</td>\n",
       "      <td>https://auth.globus.org/fb1b3a7f-f953-418d-83e...</td>\n",
       "      <td>https://auth.globus.org/3769492a-b197-4063-952...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9HH4</td>\n",
       "      <td>C1NC</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>2-4F76</td>\n",
       "      <td>C1SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>M6X2</td>\n",
       "      <td>2023-05-30 19:13:06.072952+00</td>\n",
       "      <td>2023-11-16 19:18:52.975075+00</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AHDY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>C1T4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>M6X4</td>\n",
       "      <td>2023-05-30 19:13:06.072952+00</td>\n",
       "      <td>2023-06-01 21:15:27.953924+00</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>https://auth.globus.org/b2541312-d274-11e5-913...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AHE0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>C1T4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>M6X6</td>\n",
       "      <td>2023-05-30 19:13:06.072952+00</td>\n",
       "      <td>2023-06-01 21:15:27.953924+00</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>https://auth.globus.org/b2541312-d274-11e5-913...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AHE2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>C1T4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>M6Z8</td>\n",
       "      <td>2023-05-30 19:13:06.072952+00</td>\n",
       "      <td>2023-11-16 19:18:52.975075+00</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>C1T4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>M6ZA</td>\n",
       "      <td>2023-05-30 19:13:06.072952+00</td>\n",
       "      <td>2023-11-16 19:18:52.975075+00</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>https://auth.globus.org/2a32b19e-2728-4708-827...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2SKA</td>\n",
       "      <td>C1T4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690J</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3419 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RID                            RCT                            RMT  \\\n",
       "0     2-35PW  2023-09-18 23:36:22.840003+00  2023-11-30 01:00:36.043948+00   \n",
       "1     2-35PY  2023-09-18 23:36:27.324847+00  2023-11-30 01:00:36.043948+00   \n",
       "2     2-35Q0  2023-09-18 23:36:43.443651+00  2023-11-30 01:00:36.043948+00   \n",
       "3     2-35Q2  2023-09-18 23:47:04.965927+00  2023-11-30 01:00:36.043948+00   \n",
       "4     2-35Q4  2023-09-18 23:47:13.305401+00  2023-11-30 01:00:36.043948+00   \n",
       "...      ...                            ...                            ...   \n",
       "3414    M6X2  2023-05-30 19:13:06.072952+00  2023-11-16 19:18:52.975075+00   \n",
       "3415    M6X4  2023-05-30 19:13:06.072952+00  2023-06-01 21:15:27.953924+00   \n",
       "3416    M6X6  2023-05-30 19:13:06.072952+00  2023-06-01 21:15:27.953924+00   \n",
       "3417    M6Z8  2023-05-30 19:13:06.072952+00  2023-11-16 19:18:52.975075+00   \n",
       "3418    M6ZA  2023-05-30 19:13:06.072952+00  2023-11-16 19:18:52.975075+00   \n",
       "\n",
       "                                                    RCB  \\\n",
       "0     https://auth.globus.org/fb1b3a7f-f953-418d-83e...   \n",
       "1     https://auth.globus.org/fb1b3a7f-f953-418d-83e...   \n",
       "2     https://auth.globus.org/fb1b3a7f-f953-418d-83e...   \n",
       "3     https://auth.globus.org/fb1b3a7f-f953-418d-83e...   \n",
       "4     https://auth.globus.org/fb1b3a7f-f953-418d-83e...   \n",
       "...                                                 ...   \n",
       "3414  https://auth.globus.org/2a32b19e-2728-4708-827...   \n",
       "3415  https://auth.globus.org/2a32b19e-2728-4708-827...   \n",
       "3416  https://auth.globus.org/2a32b19e-2728-4708-827...   \n",
       "3417  https://auth.globus.org/2a32b19e-2728-4708-827...   \n",
       "3418  https://auth.globus.org/2a32b19e-2728-4708-827...   \n",
       "\n",
       "                                                    RMB  Cup/Disk_Ratio Image  \\\n",
       "0     https://auth.globus.org/3769492a-b197-4063-952...             0.3  A5K8   \n",
       "1     https://auth.globus.org/3769492a-b197-4063-952...             0.2  7RHY   \n",
       "2     https://auth.globus.org/3769492a-b197-4063-952...             0.8  9ECE   \n",
       "3     https://auth.globus.org/3769492a-b197-4063-952...             0.6  9KZ4   \n",
       "4     https://auth.globus.org/3769492a-b197-4063-952...             0.7  9HH4   \n",
       "...                                                 ...             ...   ...   \n",
       "3414  https://auth.globus.org/2a32b19e-2728-4708-827...             NaN  AHDY   \n",
       "3415  https://auth.globus.org/b2541312-d274-11e5-913...             NaN  AHE0   \n",
       "3416  https://auth.globus.org/b2541312-d274-11e5-913...             NaN  AHE2   \n",
       "3417  https://auth.globus.org/2a32b19e-2728-4708-827...             NaN  AGET   \n",
       "3418  https://auth.globus.org/2a32b19e-2728-4708-827...             NaN  AGEW   \n",
       "\n",
       "     Process Diagnosis_Vocab Diagnosis_Tag Diagnosis_Status Comments  \\\n",
       "0       C1NC            2SKC        2-4F76             C1SW      NaN   \n",
       "1       C1NC            2SKC        2-4F76             C1SW      NaN   \n",
       "2       C1NC            2SKA        2-4F76             C1SW      NaN   \n",
       "3       C1NC            2SKA        2-4F76             C1SW      NaN   \n",
       "4       C1NC            2SKA        2-4F76             C1SW      NaN   \n",
       "...      ...             ...           ...              ...      ...   \n",
       "3414     NaN            2SKA          C1T4              NaN      NaN   \n",
       "3415     NaN            2SKA          C1T4              NaN      NaN   \n",
       "3416     NaN            2SKA          C1T4              NaN      NaN   \n",
       "3417     NaN            2SKA          C1T4              NaN      NaN   \n",
       "3418     NaN            2SKA          C1T4              NaN      NaN   \n",
       "\n",
       "     Image_Quality_Vocab  Execution  \n",
       "0                   690J        NaN  \n",
       "1                   690J        NaN  \n",
       "2                   690J        NaN  \n",
       "3                   690J        NaN  \n",
       "4                   690J        NaN  \n",
       "...                  ...        ...  \n",
       "3414                690J        NaN  \n",
       "3415                 NaN        NaN  \n",
       "3416                 NaN        NaN  \n",
       "3417                690J        NaN  \n",
       "3418                690J        NaN  \n",
       "\n",
       "[3419 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f5aae05-5d14-46ee-acd2-119c5a321b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_Quality_Vocab\n",
       "690J    704\n",
       "692J     96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subject_df[subject_df['Diagnosis_Tag'] == \"2-4F76\"].Image_Quality_Vocab.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6768aa-627f-4713-b988-d1d1ab4bbd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec9f7d22-869d-48c5-b088-783345d66e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path, PurePath\n",
    "from tqdm import tqdm\n",
    "\n",
    "def crop_to_eye(im):\n",
    "    mask = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    cropped_im = im[y:y + h, x:x + w]\n",
    "    return cropped_im\n",
    "\n",
    "def create_LACDHS_quality_dataset_van_graded(train_dir: str, validation_dir: str, test_dir: str, output_dir: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Creates a dataset for LACDHS image quality classification by organizing images into train, valid, and test folders\n",
    "    based on their Image_Quality_Vocab from the Diagnosis table, filtered for Field 2 images and cropped to the eye.\n",
    "    Additional filters are applied for specific Diagnosis_Tag values in train and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - train_dir (str): Path to the raw train dataset bag.\n",
    "    - validation_dir (str): Path to the raw validation dataset bag.\n",
    "    - test_dir (str): Path to the raw test dataset bag.\n",
    "    - output_dir (str): Path to the output directory where the organized dataset will be created.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the paths to the train and validation directories.\n",
    "    \"\"\"\n",
    "    def filter_field_2(image_df):\n",
    "        return image_df[image_df['Image_Angle_Vocab'] == \"2SK6\"]\n",
    "\n",
    "    def process_dataset(bag_path: str, output_subdir: str, diagnosis_tag: str = None):\n",
    "        image_csv_path = os.path.join(bag_path, 'data', 'Image.csv')\n",
    "        diagnosis_csv_path = os.path.join(bag_path, 'data', 'Diagnosis.csv')\n",
    "        \n",
    "        image_df = pd.read_csv(image_csv_path)\n",
    "        diagnosis_df = pd.read_csv(diagnosis_csv_path)\n",
    "        \n",
    "        # Filter for Field 2 images\n",
    "        image_df = filter_field_2(image_df)\n",
    "        \n",
    "        # Merge dataframes\n",
    "        merged_df = image_df.merge(diagnosis_df, left_on='RID', right_on='Image')\n",
    "        \n",
    "        # Filter out rows with NaN Image_Quality_Vocab\n",
    "        merged_df = merged_df.dropna(subset=['Image_Quality_Vocab'])\n",
    "        \n",
    "        # Apply Diagnosis_Tag filter if specified\n",
    "        if diagnosis_tag:\n",
    "            merged_df = merged_df[merged_df['Diagnosis_Tag'] == diagnosis_tag]\n",
    "        \n",
    "        image_root_path = os.path.join(bag_path, 'data', 'assets', 'Image')\n",
    "        \n",
    "        # Add tqdm progress bar\n",
    "        for _, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=f\"Processing {output_subdir}\"):\n",
    "            quality = row['Image_Quality_Vocab']\n",
    "            filename = row['Filename']\n",
    "            src_path = os.path.join(image_root_path, filename)\n",
    "            \n",
    "            # Read the image\n",
    "            img = cv2.imread(src_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {src_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Crop the image to the eye\n",
    "            cropped_img = crop_to_eye(img)\n",
    "            \n",
    "            dst_dir = os.path.join(output_dir, output_subdir, quality)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            dst_path = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            # Save the cropped image\n",
    "            cv2.imwrite(dst_path, cropped_img)\n",
    "        \n",
    "        # Print the count of images in each category\n",
    "        print(f\"\\nImage count for {output_subdir}:\")\n",
    "        print(merged_df['Image_Quality_Vocab'].value_counts())\n",
    "\n",
    "    print(\"Processing train dataset...\")\n",
    "    process_dataset(train_dir, 'train', diagnosis_tag=\"2-4F74\")\n",
    "\n",
    "    print(\"\\nProcessing validation dataset...\")\n",
    "    process_dataset(validation_dir, 'valid', diagnosis_tag=\"2-4F76\")\n",
    "\n",
    "    # Process test dataset (no Diagnosis_Tag filter)\n",
    "    # print(\"\\nProcessing test dataset...\")\n",
    "    # process_dataset(test_dir, 'test')\n",
    "\n",
    "    train_path = os.path.join(output_dir, 'train')\n",
    "    valid_path = os.path.join(output_dir, 'valid')\n",
    "    # test_path = os.path.join(output_dir, 'test')\n",
    "\n",
    "    return train_path, valid_path  # , test_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb2fa7a6-3fa2-4218-b526-5f142a328096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/sreenidhi/EyeAI_working')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_records.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd8dc53-3b7f-45b9-94c7-04cdabf12a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 3200/3200 [14:15<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image count for train:\n",
      "Image_Quality_Vocab\n",
      "690J    2757\n",
      "692J     443\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing validation dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 100%|██████████| 800/800 [03:34<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image count for valid:\n",
      "Image_Quality_Vocab\n",
      "690J    704\n",
      "692J     96\n",
      "Name: count, dtype: int64\n",
      "Train dataset path: /data/sreenidhi/EyeAI_working/train\n",
      "Validation dataset path: /data/sreenidhi/EyeAI_working/valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Data Preprocessing (Filtering Image.csv for just Field_2 Images)\n",
    "train_dir = configuration_records.bag_paths[0] # path to the raw train dataset\n",
    "validation_dir = configuration_records.bag_paths[1]\n",
    "test_dir = configuration_records.bag_paths[2]\n",
    "\n",
    "# Call the create_LACDHS_quality_dataset function\n",
    "train_path, valid_path = create_LACDHS_quality_dataset_van_graded(\n",
    "    train_dir=str(configuration_records.bag_paths[0]),\n",
    "    validation_dir=str(configuration_records.bag_paths[1]),\n",
    "    test_dir=str(configuration_records.bag_paths[2]),\n",
    "    output_dir=str(configuration_records.working_dir),\n",
    ") #, test_path\n",
    "\n",
    "# Print the paths to verify\n",
    "print(\"Train dataset path:\", train_path)\n",
    "print(\"Validation dataset path:\", valid_path)\n",
    "# print(\"Test dataset path:\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d4788d5-e8af-4883-9099-e35325b4c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing train folder:\n",
      "  690J: 2757 images\n",
      "  692J: 443 images\n",
      "Total images in train: 3200\n",
      "\n",
      "Analyzing valid folder:\n",
      "  690J: 704 images\n",
      "  692J: 96 images\n",
      "Total images in valid: 800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "def analyze_lacdhs_angle_dataset(base_path):\n",
    "    main_folders = ['train', 'valid'] #, 'test'\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nAnalyzing {main_folder} folder:\")\n",
    "        \n",
    "        total_files = 0\n",
    "        for angle_folder in os.listdir(main_folder_path):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            if os.path.isdir(angle_folder_path):\n",
    "                file_count = count_files(angle_folder_path)\n",
    "                print(f\"  {angle_folder}: {file_count} images\")\n",
    "                total_files += file_count\n",
    "        \n",
    "        print(f\"Total images in {main_folder}: {total_files}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "analyze_lacdhs_angle_dataset(base_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f839e9a3-3752-44b0-aed5-3e818b47f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_lacdhs_quality_dataset(base_path, samples_per_angle=6):\n",
    "    main_folders = ['train', 'valid'] #, 'test'\n",
    "    \n",
    "    for main_folder in main_folders:\n",
    "        main_folder_path = os.path.join(base_path, main_folder)\n",
    "        if not os.path.exists(main_folder_path):\n",
    "            print(f\"{main_folder} folder not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nVisualizing samples from {main_folder} folder:\")\n",
    "        \n",
    "        angle_folders = [f for f in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, f))]\n",
    "        \n",
    "        # Calculate grid size\n",
    "        n_angles = len(angle_folders)\n",
    "        n_cols = samples_per_angle\n",
    "        n_rows = n_angles\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3.5))\n",
    "        fig.suptitle(f'Sample Images from {main_folder.capitalize()} Set', fontsize=16)\n",
    "        \n",
    "        for i, angle_folder in enumerate(angle_folders):\n",
    "            angle_folder_path = os.path.join(main_folder_path, angle_folder)\n",
    "            image_files = [f for f in os.listdir(angle_folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            if len(image_files) < samples_per_angle:\n",
    "                print(f\"Warning: Not enough images in {angle_folder}. Using all available images.\")\n",
    "                selected_files = image_files\n",
    "            else:\n",
    "                selected_files = random.sample(image_files, samples_per_angle)\n",
    "            \n",
    "            for j, image_file in enumerate(selected_files):\n",
    "                img_path = os.path.join(angle_folder_path, image_file)\n",
    "                img = Image.open(img_path)\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "                # Add image filename as title for each subplot\n",
    "                axes[i, j].set_title(image_file, fontsize=8)\n",
    "                \n",
    "                if j == 0:\n",
    "                    axes[i, j].set_ylabel(angle_folder, rotation=0, labelpad=40, va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95, bottom=0.05, left=0.2, right=0.98)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print confirmation of angles\n",
    "        print(f\"Angles in {main_folder} set:\")\n",
    "        for angle in angle_folders:\n",
    "            print(f\"  - {angle}\")\n",
    "\n",
    "# Usage\n",
    "base_path = \"/data/sreenidhi/EyeAI_working/\"\n",
    "# visualize_lacdhs_quality_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab84cbc-bac9-4909-9923-3a2bf27f8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = str(EA.working_dir) + \"/Execution_Assets/\" + configuration_records.vocabs['Execution_Asset_Type'][0].name\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b49509-32d4-47b7-88d3-f224a00b01a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cbbfb90-53ce-4730-9721-b35d11458ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters_json_path = str(configuration_records.assets_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f135924-3e0f-4b71-beb5-173a7a9533e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/sreenidhi/EyeAI_working/Execution_Assets/best_hyperparameters_exluding_no_optic_disc_images_june_24_2024.json'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper_parameters_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb39d015-c811-48e4-92f6-4b1db0f4d379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"rotation_range\": -6,\n",
      "    \"width_shift_range\": 0.049283662164352315,\n",
      "    \"height_shift_range\": 0.062129040368351915,\n",
      "    \"horizontal_flip\": true,\n",
      "    \"vertical_flip\": true,\n",
      "    \"zoom_range\": -0.03493437617512693,\n",
      "    \"brightness_range\": 0.016808387649284325,\n",
      "    \"use_class_weights\": true,\n",
      "    \"pooling\": \"global_average\",\n",
      "    \"dense_layers\": 2,\n",
      "    \"units_layer_0\": 512,\n",
      "    \"activation_func_0\": \"sigmoid\",\n",
      "    \"batch_norm_0\": true,\n",
      "    \"dropout_0\": 0.10646478371824658,\n",
      "    \"units_layer_1\": 64,\n",
      "    \"activation_func_1\": \"relu\",\n",
      "    \"batch_norm_1\": false,\n",
      "    \"dropout_1\": 0.2830490167548361,\n",
      "    \"fine_tune_at\": 0,\n",
      "    \"fine_tuning_learning_rate_adam\": 1.1688327470992886e-05,\n",
      "    \"batch_size\": 32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(best_hyper_parameters_json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01e46e2f-4401-41a3-a75b-1437f8735477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 14:41:17.786696: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-30 14:41:17.786759: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-30 14:41:17.932383: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-30 14:41:18.244242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-30 14:41:19.775765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "train_generator.class_indices :  {'692J': 0, '690J': 1}\n",
      "validation_generator.class_indices :  {'692J': 0, '690J': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 14:41:22.658975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.067209: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.070900: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.075019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.078591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.082057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.224330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.225806: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.227188: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-30 14:41:23.228506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 14:41:29.930775: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-06-30 14:41:37.277899: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f9af1c79330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-30 14:41:37.277967: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-06-30 14:41:37.305814: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719783697.466924   15514 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 90s 689ms/step - loss: 0.5253 - roc_auc_score: 0.8372 - f1_score_normal: 0.7844 - accuracy_score: 0.6888 - val_loss: 0.3399 - val_roc_auc_score: 0.9303 - val_f1_score_normal: 0.9563 - val_accuracy_score: 0.9212\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 75s 734ms/step - loss: 0.3954 - roc_auc_score: 0.9123 - f1_score_normal: 0.8673 - accuracy_score: 0.7953 - val_loss: 0.2967 - val_roc_auc_score: 0.9546 - val_f1_score_normal: 0.9505 - val_accuracy_score: 0.9162\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 75s 730ms/step - loss: 0.3697 - roc_auc_score: 0.9194 - f1_score_normal: 0.8816 - accuracy_score: 0.8156 - val_loss: 0.3026 - val_roc_auc_score: 0.9385 - val_f1_score_normal: 0.9483 - val_accuracy_score: 0.9112\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 74s 724ms/step - loss: 0.3389 - roc_auc_score: 0.9340 - f1_score_normal: 0.8962 - accuracy_score: 0.8353 - val_loss: 0.2143 - val_roc_auc_score: 0.9436 - val_f1_score_normal: 0.9516 - val_accuracy_score: 0.9162\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 75s 736ms/step - loss: 0.3077 - roc_auc_score: 0.9444 - f1_score_normal: 0.9089 - accuracy_score: 0.8553 - val_loss: 0.1745 - val_roc_auc_score: 0.9576 - val_f1_score_normal: 0.9563 - val_accuracy_score: 0.9250\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 76s 742ms/step - loss: 0.2932 - roc_auc_score: 0.9482 - f1_score_normal: 0.9161 - accuracy_score: 0.8656 - val_loss: 0.3979 - val_roc_auc_score: 0.9591 - val_f1_score_normal: 0.9089 - val_accuracy_score: 0.8525\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 75s 737ms/step - loss: 0.3035 - roc_auc_score: 0.9460 - f1_score_normal: 0.9108 - accuracy_score: 0.8572 - val_loss: 0.2087 - val_roc_auc_score: 0.9533 - val_f1_score_normal: 0.9579 - val_accuracy_score: 0.9275\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 75s 734ms/step - loss: 0.2844 - roc_auc_score: 0.9533 - f1_score_normal: 0.9158 - accuracy_score: 0.8647 - val_loss: 0.2021 - val_roc_auc_score: 0.9365 - val_f1_score_normal: 0.9633 - val_accuracy_score: 0.9337\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 75s 731ms/step - loss: 0.2765 - roc_auc_score: 0.9546 - f1_score_normal: 0.9152 - accuracy_score: 0.8637 - val_loss: 0.1967 - val_roc_auc_score: 0.9481 - val_f1_score_normal: 0.9551 - val_accuracy_score: 0.9225\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 75s 734ms/step - loss: 0.2614 - roc_auc_score: 0.9590 - f1_score_normal: 0.9241 - accuracy_score: 0.8769 - val_loss: 0.2061 - val_roc_auc_score: 0.9337 - val_f1_score_normal: 0.9649 - val_accuracy_score: 0.9388\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 74s 727ms/step - loss: 0.2649 - roc_auc_score: 0.9594 - f1_score_normal: 0.9253 - accuracy_score: 0.8791 - val_loss: 0.2123 - val_roc_auc_score: 0.9469 - val_f1_score_normal: 0.9515 - val_accuracy_score: 0.9162\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 77s 750ms/step - loss: 0.2599 - roc_auc_score: 0.9601 - f1_score_normal: 0.9232 - accuracy_score: 0.8759 - val_loss: 0.1629 - val_roc_auc_score: 0.9591 - val_f1_score_normal: 0.9625 - val_accuracy_score: 0.9350\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 75s 734ms/step - loss: 0.2335 - roc_auc_score: 0.9677 - f1_score_normal: 0.9298 - accuracy_score: 0.8863 - val_loss: 0.1654 - val_roc_auc_score: 0.9610 - val_f1_score_normal: 0.9590 - val_accuracy_score: 0.9300\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 75s 739ms/step - loss: 0.2584 - roc_auc_score: 0.9609 - f1_score_normal: 0.9203 - accuracy_score: 0.8731 - val_loss: 0.1758 - val_roc_auc_score: 0.9552 - val_f1_score_normal: 0.9618 - val_accuracy_score: 0.9337\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 76s 740ms/step - loss: 0.2190 - roc_auc_score: 0.9721 - f1_score_normal: 0.9305 - accuracy_score: 0.8872 - val_loss: 0.2136 - val_roc_auc_score: 0.9600 - val_f1_score_normal: 0.9502 - val_accuracy_score: 0.9162\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 75s 740ms/step - loss: 0.2265 - roc_auc_score: 0.9691 - f1_score_normal: 0.9293 - accuracy_score: 0.8863 - val_loss: 0.1969 - val_roc_auc_score: 0.9605 - val_f1_score_normal: 0.9522 - val_accuracy_score: 0.9187\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 72s 705ms/step - loss: 0.2053 - roc_auc_score: 0.9755 - f1_score_normal: 0.9333 - accuracy_score: 0.8919 - val_loss: 0.2744 - val_roc_auc_score: 0.8991 - val_f1_score_normal: 0.9647 - val_accuracy_score: 0.9375\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 78s 743ms/step - loss: 0.2137 - roc_auc_score: 0.9724 - f1_score_normal: 0.9383 - accuracy_score: 0.8994 - val_loss: 0.1870 - val_roc_auc_score: 0.9522 - val_f1_score_normal: 0.9595 - val_accuracy_score: 0.9300\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 75s 736ms/step - loss: 0.1987 - roc_auc_score: 0.9763 - f1_score_normal: 0.9465 - accuracy_score: 0.9116 - val_loss: 0.2688 - val_roc_auc_score: 0.9502 - val_f1_score_normal: 0.9400 - val_accuracy_score: 0.9000\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 75s 735ms/step - loss: 0.1875 - roc_auc_score: 0.9792 - f1_score_normal: 0.9457 - accuracy_score: 0.9103 - val_loss: 0.3016 - val_roc_auc_score: 0.8857 - val_f1_score_normal: 0.9616 - val_accuracy_score: 0.9312\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1947 - roc_auc_score: 0.9771 - f1_score_normal: 0.9464 - accuracy_score: 0.9116Restoring model weights from the end of the best epoch: 13.\n",
      "100/100 [==============================] - 75s 739ms/step - loss: 0.1947 - roc_auc_score: 0.9771 - f1_score_normal: 0.9464 - accuracy_score: 0.9116 - val_loss: 0.1991 - val_roc_auc_score: 0.9465 - val_f1_score_normal: 0.9619 - val_accuracy_score: 0.9337\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sreenidhi/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2024-06-30 15:08:04,815 - INFO - VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024 Model trained, Model and training history are saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# @title Execute Training algorithm\n",
    "\n",
    "from eye_ai.models.vgg19_lacdhs_quality_van_graded_train import main\n",
    "\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "  main(train_path=train_path,\n",
    "       valid_path=valid_path, \n",
    "       # test_path=test_path, \n",
    "       output_path=output_path,\n",
    "       best_hyperparameters_json_path=best_hyper_parameters_json_path,\n",
    "       model_name=\"VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024\"\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a3f3d-d49d-4899-af5a-c1565de9a28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17a367dd-445a-41f9-bc97-354e6def6100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 15:20:44,164 - INFO - Initializing uploader: GenericUploader v1.7.1 [Python 3.10.13, Linux-5.10.210-201.852.amzn2.x86_64-x86_64-with-glibc2.26]\n",
      "2024-06-30 15:20:44,165 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-30 15:20:44,165 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n",
      "2024-06-30 15:20:44,167 - INFO - Setting up RefreshTokenAuthorizer with auth_client=[instance:140308152190096]\n",
      "2024-06-30 15:20:44,168 - INFO - Setting up a RenewingAuthorizer. It will use an auth type of Bearer and can handle 401s.\n",
      "2024-06-30 15:20:44,168 - INFO - RenewingAuthorizer will start by using access_token with hash \"0633007d6ca07b655e17c93e96c38c5be99f9d460bb5b378d050df84d8f47214\"\n",
      "2024-06-30 15:20:44,169 - INFO - Executing token refresh without client credentials\n",
      "2024-06-30 15:20:44,169 - INFO - Fetching new token from Globus Auth\n",
      "2024-06-30 15:20:44,568 - INFO - request done (success)\n",
      "2024-06-30 15:20:44,569 - INFO - RenewingAuthorizer.access_token updated to token with hash \"7dc6983de781ae133b94af0cf3e2a49ad30be409da754fced94cae394a796e18\"\n",
      "2024-06-30 15:20:45,976 - INFO - Checking for updated configuration...\n",
      "2024-06-30 15:20:46,114 - INFO - Updated configuration found.\n",
      "2024-06-30 15:20:46,115 - INFO - Scanning files in directory [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training]...\n",
      "2024-06-30 15:20:46,119 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.h5].\n",
      "2024-06-30 15:20:46,119 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/training_history_VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.csv].\n",
      "2024-06-30 15:20:46,120 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.h5]\n",
      "2024-06-30 15:20:46,121 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.h5].\n",
      "2024-06-30 15:20:46,122 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.h5]. Please wait...\n",
      "2024-06-30 15:20:46,684 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.h5] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-30 15:20:52,279 - INFO - File [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.h5] upload successful. 232.71 MB transferred at 43.45 MB/second. Elapsed time: 0:00:05.355620.\n",
      "2024-06-30 15:20:52,577 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/training_history_VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.csv]\n",
      "2024-06-30 15:20:52,577 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/training_history_VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.csv].\n",
      "2024-06-30 15:20:52,578 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/training_history_VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.csv]. Please wait...\n",
      "2024-06-30 15:20:52,591 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Assets/VGG19_Catalog_Model_LACDHS_quality_training/training_history_VGG19_Catalog_LAC_DHS_Quality_Van_Graded_Trained_model_June_30_2024.csv] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-30 15:20:52,734 - INFO - File upload processing completed: 2 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n",
      "2024-06-30 15:20:52,852 - INFO - Initializing uploader: GenericUploader v1.7.1 [Python 3.10.13, Linux-5.10.210-201.852.amzn2.x86_64-x86_64-with-glibc2.26]\n",
      "2024-06-30 15:20:52,854 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-06-30 15:20:52,854 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n",
      "2024-06-30 15:20:52,890 - INFO - Checking for updated configuration...\n",
      "2024-06-30 15:20:53,058 - INFO - Updated configuration found.\n",
      "2024-06-30 15:20:53,060 - INFO - Scanning files in directory [/data/sreenidhi/EyeAI_working/Execution_Metadata]...\n",
      "2024-06-30 15:20:53,061 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json].\n",
      "2024-06-30 15:20:53,062 - INFO - Including file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt].\n",
      "2024-06-30 15:20:53,062 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json]\n",
      "2024-06-30 15:20:53,063 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json].\n",
      "2024-06-30 15:20:53,063 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json]. Please wait...\n",
      "2024-06-30 15:20:53,082 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-30 15:20:53,182 - INFO - Updating catalog for file [Execution_Config-vgg19_catalog_model_training_LACDHS_quality_van_graded_labels_sreenidhi_june_27_2024.json]\n",
      "2024-06-30 15:20:53,231 - INFO - Processing: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt]\n",
      "2024-06-30 15:20:53,231 - INFO - Computed metadata for: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt].\n",
      "2024-06-30 15:20:53,232 - INFO - Computing checksums for file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt]. Please wait...\n",
      "2024-06-30 15:20:53,242 - INFO - Uploading file: [/data/sreenidhi/EyeAI_working/Execution_Metadata/Runtime_Env-python_environment_snapshot.txt] to host https://www.eye-ai.org. Please wait...\n",
      "2024-06-30 15:20:53,259 - INFO - File upload processing completed: 2 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n"
     ]
    }
   ],
   "source": [
    "# # @title Save Execution Assets (model) and Metadata\n",
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bb207-df9b-4ddc-933c-045eb08388fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7460350-738f-4ab0-aaef-a7a65ed2b303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
