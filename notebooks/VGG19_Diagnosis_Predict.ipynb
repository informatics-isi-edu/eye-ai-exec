{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href=\"https://colab.research.google.com/github/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/VGG19_Diagnosis_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# VGG19 Model Application\n",
    "\n",
    "This notebook applied a pre-trained model to a dataset specified in the configuration file and uploads the labels to the catalog.  The ROC curve is also calculated and uploaded."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prerequisites to configure colab \n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install deriva\n",
    "    !pip install bdbag\n",
    "    !pip install --upgrade --force pydantic\n",
    "    !pip install git+https://github.com/informatics-isi-edu/deriva-ml git+https://github.com/informatics-isi-edu/eye-ai-ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "id": "iCtEohU8lV-W"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw-bW4bORlqQ"
   },
   "outputs": [],
   "source": [
    "# @title login to DERIVA via Globus Auth\n",
    "\n",
    "DEBUG_MODE = False #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "DEFAULT_SERVER = 'dev.eye-ai.org' if DEBUG_MODE else 'www.eye-ai.org'\n",
    "\n",
    "!deriva-globus-auth-utils login --no-browser --host {DEFAULT_SERVER}\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Connect to Eye-AI catalog.  Configure to store data local cache and working directories.  Initialize Eye-AI for pending execution based on the provided configuration file."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "\n",
    "cache_dir = 'cache'        # Directory in which to cache materialized BDBags for datasets\n",
    "working_dir = 'working'    # Directory in which to place output files for later upload.\n",
    "\n",
    "configuration_rid=\"2-A5KC\"      # Configuration file for this run.  Needs to be changed for each execution."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EA = EyeAI(hostname = DEFAULT_SERVER, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCIfOvbUXTGB"
   },
   "outputs": [],
   "source": [
    "# @title Initiate an Execution\n",
    "configuration_records = EA.execution_init(configuration_rid=configuration_rid)\n",
    "input_dataset = configuration_records.assets_paths[0] # Assumes that the configuration file only specifies one dataset.\n",
    "configuration_records.model_dump()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Algorithm was trained on cropped images, so take the raw images and bounding boxes and apply, storing the results in the working directory. "
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title Get Cropped Images\n",
    "cropped_image_path, cropped_csv = EA.create_cropped_images(str(configuration_records.bag_paths[0]),\n",
    "                                                           output_dir = working_dir,\n",
    "                                                           crop_to_eye=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the actual model code and then run against the input dataset specified in the configuration file.  "
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title Execute Proecss algorithm (Test model)\n",
    "from eye_ai.models.vgg19_diagnosis_predict import prediction\n",
    "with EA.execution(execution_rid=configuration_records.execution_rid) as exec:\n",
    "  output_path = EA.execution_assets_path/Path(\"Model_Prediction\")\n",
    "  pred_csv_path = prediction(input_dataset, cropped_image_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hra5M6G8-dh9"
   },
   "outputs": [],
   "source": [
    "# @title Plot ROC.\n",
    "roc_value_path = EA.plot_roc(pred_csv_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add the new lables to the catalog using the provided diagnosis tage for this execution.  Also upload any additional assets that were produced by this execution.."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title Save Diagnosis\n",
    "import re\n",
    "pred_df = pd.read_csv(pred_csv_path)\n",
    "pred_df['Image'] = pred_df['Filename'].apply(lambda x: re.search(r'Cropped_(.*?)\\.', x).group(1))\n",
    "# The input dataframe need two columns: Image (containing image rid) and Prediction (containing 0/1)\n",
    "EA.insert_new_diagnosis(pred_df,\n",
    "                        configuration_records.vocabs['Diagnosis_Tag'][0].rid,\n",
    "                        configuration_records.execution_rid)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title Save Execution Assets (model) and Metadata\n",
    "uploaded_assets = EA.execution_upload(configuration_records.execution_rid, False)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
