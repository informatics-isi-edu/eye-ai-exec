{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Define the base repository directory\n",
    "repo_dir = Path.home() / \"Desktop\" / \"eye_ai\" / \"Github\"  # Update to your GitHub repo location\n",
    "\n",
    "# Update the load path so Python can find modules for the model\n",
    "sys.path.insert(0, str(repo_dir / \"deriva-ml\"))\n",
    "sys.path.insert(0, str(repo_dir / \"eye-ai-ml\"))\n",
    "\n",
    "# Reload extensions if needed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:38.874254Z",
     "start_time": "2024-11-21T19:50:38.858917Z"
    }
   },
   "id": "ebbe774c69abe790",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml.deriva_ml_base import MLVocab as vc, Status\n",
    "from deriva_ml.execution_configuration import ExecutionConfiguration, Workflow, Execution\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:43.157667Z",
     "start_time": "2024-11-21T19:50:39.863277Z"
    }
   },
   "id": "7a4c63f1992a2f4b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:50:47,971 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-11-21 11:50:47,973 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "# host = 'dev.eye-ai.org'\n",
    "# catalog_id = \"428\"\n",
    "\n",
    "host = 'www.eye-ai.org'\n",
    "catalog_id = \"21\"\n",
    "# catalog_id = \"eye-ai\"\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:47.988059Z",
     "start_time": "2024-11-21T19:50:47.930094Z"
    }
   },
   "id": "5854dd2af49b17c6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:50:50,783 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-11-21 11:50:50,784 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n",
      "2024-11-21 11:50:52,629 - INFO - Loading dirty model.  Consider commiting and tagging: 1.1.0.post76+git.403fdd90.dirty\n"
     ]
    }
   ],
   "source": [
    "# Variables to configure the rest of the notebook.\n",
    "cache_dir = Path.home() / 'Desktop/test_cache'\n",
    "working_dir = Path.home() / 'Desktop/test_cache'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:52.776137Z",
     "start_time": "2024-11-21T19:50:50.762356Z"
    }
   },
   "id": "ca73daf6aef44b55",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44e0d26997766f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Add Workflow Vocab terms\n",
    "EA.add_term(vc.workflow_type, \"Data_Model_Changes\", description=\"Workflows to support data model changes\")\n",
    "# Workflow instance\n",
    "new_workflow = Workflow(\n",
    "    name=\"Fill diag exec_rid\",\n",
    "    url=\"https://github.com/informatics-isi-edu/eye-ai-exec/blob/Data_Model_Update/notebooks/schema_changes/fill_diag_exec_rid.ipynb\",\n",
    "    workflow_type=\"Data_Model_Changes\"\n",
    ")\n",
    "# Configuration instance\n",
    "config = ExecutionConfiguration(\n",
    "    bdbags=[],\n",
    "    models = [],\n",
    "    execution=Execution(description=\"fill execution rid for UI annotation on dev\"),\n",
    "    workflow=new_workflow)\n",
    "# Initialize execution\n",
    "# configuration_record = EA.initialize_execution(config)\n",
    "# execution_rid = configuration_record.execution_rid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:53.057432Z",
     "start_time": "2024-11-21T19:50:52.777398Z"
    }
   },
   "id": "7438a3b956e576e5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_dup(dataset_rid: str):\n",
    "    results = subject_dataset.path\\\n",
    "        .filter(subject_dataset.Dataset == dataset_rid) \\\n",
    "        .link(subject, on=subject_dataset.Subject == subject.RID) \\\n",
    "        .link(observation, on=subject.RID == observation.Subject) \\\n",
    "        .link(image, on=observation.RID == image.Observation) \\\n",
    "        .link(diagnosis, on=image.RID == diagnosis.Image)\n",
    "\n",
    "    diag_records = pd.DataFrame(results.entities().fetch())\n",
    "    diag_records = pd.merge(diag_records, pd.DataFrame(EA.user_list()), how=\"left\", left_on='RCB', right_on='ID')\n",
    "    diag_records = diag_records[diag_records['Diagnosis_Tag'] != 'CNN_Prediction']\n",
    "    return diag_records[diag_records.duplicated(subset=[\"Image\", \"Diagnosis_Tag\",\"Full_Name\"], keep=\"first\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:55.420041Z",
     "start_time": "2024-11-21T19:50:55.379498Z"
    }
   },
   "id": "5458615a2faab3c9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subject_dataset = EA.domain_schema_instance.Subject_Dataset\n",
    "subject = EA.domain_schema_instance.Subject\n",
    "image = EA.domain_schema_instance.Image\n",
    "observation = EA.domain_schema_instance.Observation\n",
    "diagnosis = EA.domain_schema_instance.Diagnosis\n",
    "\n",
    "lac = '2-1S12'\n",
    "new_lac = '2-N93J'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:34.514035Z",
     "start_time": "2024-11-21T19:51:34.433161Z"
    }
   },
   "id": "20e2deefa60316bc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lac_dup = check_dup(lac)\n",
    "new_lac_dup = check_dup(new_lac)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:39.972395Z",
     "start_time": "2024-11-21T19:51:35.640352Z"
    }
   },
   "id": "514b51f43b92b058",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [RID, RCT, RMT, RCB, RMB, Execution, Image, Feature_Name, Diagnosis_Image, Image_Quality, Diagnosis_Tag, Diagnosis_Status, Cup/Disk_Ratio, Comments, Process, ID, Full_Name]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RID</th>\n      <th>RCT</th>\n      <th>RMT</th>\n      <th>RCB</th>\n      <th>RMB</th>\n      <th>Execution</th>\n      <th>Image</th>\n      <th>Feature_Name</th>\n      <th>Diagnosis_Image</th>\n      <th>Image_Quality</th>\n      <th>Diagnosis_Tag</th>\n      <th>Diagnosis_Status</th>\n      <th>Cup/Disk_Ratio</th>\n      <th>Comments</th>\n      <th>Process</th>\n      <th>ID</th>\n      <th>Full_Name</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lac_dup"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:50.785093Z",
     "start_time": "2024-11-21T19:51:50.727808Z"
    }
   },
   "id": "360d656426b0e313",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def batchUpdate(table, entities, update_cols):\n",
    "    n = len(entities)\n",
    "    batch_num = min(2000, n)\n",
    "    for i in range(n//batch_num):\n",
    "        table.update(entities[i*batch_num: (i+1)*batch_num], [table.RID], update_cols)\n",
    "        logging.info(\"Processed batch: %d to %d\", i * batch_num, (i + 1) * batch_num)\n",
    "    if (i+1)*batch_num < n:\n",
    "        table.update(entities[(i+1)*batch_num: n], [table.RID], update_cols)\n",
    "        logging.info(\"Processed batch: %d to %d\", (i + 1) * batch_num, n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:53.265135Z",
     "start_time": "2024-11-21T19:51:53.228818Z"
    }
   },
   "id": "25acd0db2481540d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def update_exec_rid(dataset_rid: str):\n",
    "    results = subject_dataset.path\\\n",
    "        .filter(subject_dataset.Dataset == dataset_rid) \\\n",
    "        .link(subject, on=subject_dataset.Subject == subject.RID) \\\n",
    "        .link(observation, on=subject.RID == observation.Subject) \\\n",
    "        .link(image, on=observation.RID == image.Observation) \\\n",
    "        .link(diagnosis, on=image.RID == diagnosis.Image)\n",
    "\n",
    "    diag_records = pd.DataFrame(results.entities().fetch())\n",
    "    diag_records = pd.merge(diag_records, pd.DataFrame(EA.user_list()), how=\"left\", left_on='RCB', right_on='ID')\n",
    "    tags = diag_records['Diagnosis_Tag'].unique()\n",
    "    graders = diag_records['Full_Name'].unique()\n",
    "    for tag in tags:\n",
    "        if tag == 'CNN_Prediction':\n",
    "            continue\n",
    "        elif tag == 'Initial Diagnosis':\n",
    "            update_rec = diag_records[diag_records['Diagnosis_Tag'] == tag][['RID', 'Execution']]\n",
    "            configuration_record = EA.initialize_execution(config)\n",
    "            execution_rid = configuration_record.execution_rid\n",
    "            update_rec['Execution'] = execution_rid\n",
    "            update_entities = update_rec.to_dict(orient='records')\n",
    "            batchUpdate(diagnosis, update_entities, [diagnosis.Execution])\n",
    "            EA.update_status(Status.completed, \"update execution rid to diagnosis\", execution_rid)\n",
    "        else:\n",
    "            for grader in graders:\n",
    "                update_rec = diag_records[(diag_records['Diagnosis_Tag'] == tag) & (diag_records['Full_Name'] == grader)][['RID', 'Execution']]\n",
    "                if len(update_rec) == 0:\n",
    "                    print(\"The DataFrame is empty.\")\n",
    "                else:\n",
    "                    configuration_record = EA.initialize_execution(config)\n",
    "                    execution_rid = configuration_record.execution_rid\n",
    "                    update_rec['Execution'] = execution_rid\n",
    "                    update_entities = update_rec.to_dict(orient='records')\n",
    "                    batchUpdate(diagnosis, update_entities, [diagnosis.Execution])\n",
    "                    EA.update_status(Status.completed, \"update execution rid to diagnosis\", execution_rid)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:55.125004Z",
     "start_time": "2024-11-21T19:51:55.100428Z"
    }
   },
   "id": "25b042ed2597fd48",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:52:05,430 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:52:09,410 - INFO - Processed batch: 0 to 2000\n",
      "2024-11-21 11:52:10,316 - INFO - Processed batch: 2000 to 4000\n",
      "2024-11-21 11:52:11,154 - INFO - Processed batch: 4000 to 6000\n",
      "2024-11-21 11:52:12,178 - INFO - Processed batch: 6000 to 8000\n",
      "2024-11-21 11:52:13,286 - INFO - Processed batch: 8000 to 10000\n",
      "2024-11-21 11:52:14,281 - INFO - Processed batch: 10000 to 12000\n",
      "2024-11-21 11:52:15,162 - INFO - Processed batch: 12000 to 14000\n",
      "2024-11-21 11:52:16,145 - INFO - Processed batch: 14000 to 16000\n",
      "2024-11-21 11:52:17,222 - INFO - Processed batch: 16000 to 18000\n",
      "2024-11-21 11:52:18,215 - INFO - Processed batch: 18000 to 20000\n",
      "2024-11-21 11:52:19,252 - INFO - Processed batch: 20000 to 22000\n",
      "2024-11-21 11:52:20,129 - INFO - Processed batch: 22000 to 24000\n",
      "2024-11-21 11:52:21,197 - INFO - Processed batch: 24000 to 26000\n",
      "2024-11-21 11:52:22,560 - INFO - Processed batch: 26000 to 28000\n",
      "2024-11-21 11:52:23,598 - INFO - Processed batch: 28000 to 30000\n",
      "2024-11-21 11:52:24,567 - INFO - Processed batch: 30000 to 32000\n",
      "2024-11-21 11:52:25,572 - INFO - Processed batch: 32000 to 34000\n",
      "2024-11-21 11:52:26,454 - INFO - Processed batch: 34000 to 36000\n",
      "2024-11-21 11:52:27,506 - INFO - Processed batch: 36000 to 38000\n",
      "2024-11-21 11:52:28,685 - INFO - Processed batch: 38000 to 40000\n",
      "2024-11-21 11:52:29,634 - INFO - Processed batch: 40000 to 42000\n",
      "2024-11-21 11:52:30,594 - INFO - Processed batch: 42000 to 44000\n",
      "2024-11-21 11:52:31,851 - INFO - Processed batch: 44000 to 46000\n",
      "2024-11-21 11:52:32,955 - INFO - Processed batch: 46000 to 48000\n",
      "2024-11-21 11:52:34,033 - INFO - Processed batch: 48000 to 50000\n",
      "2024-11-21 11:52:35,321 - INFO - Processed batch: 50000 to 52000\n",
      "2024-11-21 11:52:36,435 - INFO - Processed batch: 52000 to 54000\n",
      "2024-11-21 11:52:37,548 - INFO - Processed batch: 54000 to 56000\n",
      "2024-11-21 11:52:39,000 - INFO - Processed batch: 56000 to 58000\n",
      "2024-11-21 11:52:40,402 - INFO - Processed batch: 58000 to 60000\n",
      "2024-11-21 11:52:41,462 - INFO - Processed batch: 60000 to 62000\n",
      "2024-11-21 11:52:42,527 - INFO - Processed batch: 62000 to 64000\n",
      "2024-11-21 11:52:43,522 - INFO - Processed batch: 64000 to 66000\n",
      "2024-11-21 11:52:44,705 - INFO - Processed batch: 66000 to 68000\n",
      "2024-11-21 11:52:45,886 - INFO - Processed batch: 68000 to 70000\n",
      "2024-11-21 11:52:47,060 - INFO - Processed batch: 70000 to 72000\n",
      "2024-11-21 11:52:47,967 - INFO - Processed batch: 72000 to 74000\n",
      "2024-11-21 11:52:48,914 - INFO - Processed batch: 74000 to 76000\n",
      "2024-11-21 11:52:50,169 - INFO - Processed batch: 76000 to 78000\n",
      "2024-11-21 11:52:51,099 - INFO - Processed batch: 78000 to 80000\n",
      "2024-11-21 11:52:52,123 - INFO - Processed batch: 80000 to 82000\n",
      "2024-11-21 11:52:53,074 - INFO - Processed batch: 82000 to 84000\n",
      "2024-11-21 11:52:54,026 - INFO - Processed batch: 84000 to 86000\n",
      "2024-11-21 11:52:54,983 - INFO - Processed batch: 86000 to 88000\n",
      "2024-11-21 11:52:56,053 - INFO - Processed batch: 88000 to 90000\n",
      "2024-11-21 11:52:57,044 - INFO - Processed batch: 90000 to 92000\n",
      "2024-11-21 11:52:57,974 - INFO - Processed batch: 92000 to 94000\n",
      "2024-11-21 11:52:58,917 - INFO - Processed batch: 94000 to 96000\n",
      "2024-11-21 11:53:00,133 - INFO - Processed batch: 96000 to 98000\n",
      "2024-11-21 11:53:01,043 - INFO - Processed batch: 98000 to 100000\n",
      "2024-11-21 11:53:01,784 - INFO - Processed batch: 100000 to 101442\n"
     ]
    }
   ],
   "source": [
    "rotterdam = '1-EATE'\n",
    "result = update_exec_rid(rotterdam)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:53:02.071181Z",
     "start_time": "2024-11-21T19:52:01.098188Z"
    }
   },
   "id": "2d64dc39986c247f",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:56:46,207 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:56:48,667 - INFO - Processed batch: 0 to 2000\n",
      "2024-11-21 11:56:49,197 - INFO - Processed batch: 2000 to 3200\n",
      "2024-11-21 11:56:49,424 - INFO - Configuration validation successful!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:56:50,667 - INFO - Processed batch: 0 to 13\n",
      "2024-11-21 11:56:50,779 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:56:52,078 - INFO - Processed batch: 0 to 30\n",
      "2024-11-21 11:56:52,301 - INFO - Configuration validation successful!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:56:53,854 - INFO - Processed batch: 0 to 800\n",
      "2024-11-21 11:56:54,158 - INFO - Configuration validation successful!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:56:56,142 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:56:56,262 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:56:57,866 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:56:57,979 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:56:59,820 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:56:59,935 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:01,683 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:01,804 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:03,427 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:03,620 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:05,443 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:05,555 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:07,277 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:07,390 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:09,014 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:09,124 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:10,786 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:10,902 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:12,495 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:12,613 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:14,521 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:14,635 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:16,344 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:16,458 - INFO - Configuration validation successful!\n",
      "2024-11-21 11:57:18,105 - INFO - Processed batch: 0 to 1000\n",
      "2024-11-21 11:57:18,267 - INFO - Configuration validation successful!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n",
      "The DataFrame is empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 11:57:20,405 - INFO - Processed batch: 0 to 2000\n",
      "2024-11-21 11:57:21,280 - INFO - Processed batch: 2000 to 4000\n",
      "2024-11-21 11:57:22,301 - INFO - Processed batch: 4000 to 6000\n",
      "2024-11-21 11:57:23,224 - INFO - Processed batch: 6000 to 8000\n",
      "2024-11-21 11:57:24,145 - INFO - Processed batch: 8000 to 10000\n",
      "2024-11-21 11:57:25,148 - INFO - Processed batch: 10000 to 12000\n",
      "2024-11-21 11:57:26,354 - INFO - Processed batch: 12000 to 14000\n",
      "2024-11-21 11:57:27,308 - INFO - Processed batch: 14000 to 16000\n",
      "2024-11-21 11:57:28,241 - INFO - Processed batch: 16000 to 18000\n",
      "2024-11-21 11:57:29,214 - INFO - Processed batch: 18000 to 20000\n",
      "2024-11-21 11:57:30,068 - INFO - Processed batch: 20000 to 22000\n",
      "2024-11-21 11:57:31,350 - INFO - Processed batch: 22000 to 24000\n",
      "2024-11-21 11:57:32,649 - INFO - Processed batch: 24000 to 26000\n",
      "2024-11-21 11:57:33,558 - INFO - Processed batch: 26000 to 28000\n",
      "2024-11-21 11:57:34,486 - INFO - Processed batch: 28000 to 30000\n",
      "2024-11-21 11:57:35,389 - INFO - Processed batch: 30000 to 32000\n",
      "2024-11-21 11:57:36,317 - INFO - Processed batch: 32000 to 34000\n",
      "2024-11-21 11:57:37,389 - INFO - Processed batch: 34000 to 36000\n",
      "2024-11-21 11:57:38,495 - INFO - Processed batch: 36000 to 38000\n",
      "2024-11-21 11:57:39,481 - INFO - Processed batch: 38000 to 40000\n",
      "2024-11-21 11:57:40,564 - INFO - Processed batch: 40000 to 42000\n",
      "2024-11-21 11:57:41,525 - INFO - Processed batch: 42000 to 44000\n",
      "2024-11-21 11:57:42,481 - INFO - Processed batch: 44000 to 46000\n",
      "2024-11-21 11:57:43,366 - INFO - Processed batch: 46000 to 47517\n"
     ]
    }
   ],
   "source": [
    "lac = '2-1S12'\n",
    "new_lac = '2-N93J'\n",
    "result = update_exec_rid(lac)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:57:43.537372Z",
     "start_time": "2024-11-21T19:56:34.503567Z"
    }
   },
   "id": "58d7c9180f169a9a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3008407e-fc8b-4c1e-953a-7ca563b03399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T07:15:57.107549Z",
     "start_time": "2024-11-21T07:15:48.378878Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 23:15:48,841 - INFO - Configuration validation successful!\n",
      "2024-11-20 23:15:52,275 - INFO - Processed batch: 0 to 2000\n",
      "2024-11-20 23:15:53,737 - INFO - Processed batch: 2000 to 4000\n",
      "2024-11-20 23:15:54,703 - INFO - Processed batch: 4000 to 6000\n",
      "2024-11-20 23:15:55,828 - INFO - Processed batch: 6000 to 8000\n",
      "2024-11-20 23:15:56,732 - INFO - Processed batch: 8000 to 10000\n"
     ]
    },
    {
     "ename": "DataPathException",
     "evalue": "DETAIL:  Key (\"Execution\", \"Image\", \"Feature_Name\")=(5-R6C2, 2-D2GY, Diagnosis) already exists.\n\n409 Client Error: CONFLICT for url: [https://dev.eye-ai.org/ermrest/catalog/428/attributegroup/eye-ai:Diagnosis/RID;Execution] Details: b'Request conflicts with state of server. Detail: Input data violates model. ERROR:  duplicate key value violates unique constraint \"Execution_Image_Image_Diagnosis_assoc_key\"\\nDETAIL:  Key (\"Execution\", \"Image\", \"Feature_Name\")=(5-R6C2, 2-D2GY, Diagnosis) already exists.\\n\\n'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/datapath.py:778\u001B[0m, in \u001B[0;36m_request_with_retry\u001B[0;34m(request_func, retry_codes, backoff_factor, max_attempts)\u001B[0m\n\u001B[1;32m    777\u001B[0m     attempt \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 778\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/datapath.py:1110\u001B[0m, in \u001B[0;36m_TableWrapper.update.<locals>.<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1109\u001B[0m     resp \u001B[38;5;241m=\u001B[39m _request_with_retry(\n\u001B[0;32m-> 1110\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[43mrequest_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1111\u001B[0m         retry_codes\u001B[38;5;241m=\u001B[39mretry_codes,\n\u001B[1;32m   1112\u001B[0m         backoff_factor\u001B[38;5;241m=\u001B[39mbackoff_factor,\n\u001B[1;32m   1113\u001B[0m         max_attempts\u001B[38;5;241m=\u001B[39mmax_attempts\n\u001B[1;32m   1114\u001B[0m     )\n\u001B[1;32m   1115\u001B[0m     results\u001B[38;5;241m.\u001B[39mextend(resp\u001B[38;5;241m.\u001B[39mjson())\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/datapath.py:1099\u001B[0m, in \u001B[0;36m_TableWrapper.update.<locals>.request_func\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest_func\u001B[39m(batch):\n\u001B[0;32m-> 1099\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_schema\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_catalog\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wrapped_catalog\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mContent-Type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mapplication/json\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/deriva_binding.py:330\u001B[0m, in \u001B[0;36mDerivaBinding.put\u001B[0;34m(self, path, data, json, headers, guard_response)\u001B[0m\n\u001B[1;32m    329\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session\u001B[38;5;241m.\u001B[39mput(url, data\u001B[38;5;241m=\u001B[39mdata, json\u001B[38;5;241m=\u001B[39mjson, headers\u001B[38;5;241m=\u001B[39mheaders)\n\u001B[0;32m--> 330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_for_status_412\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/deriva_binding.py:213\u001B[0m, in \u001B[0;36mDerivaBinding._raise_for_status_412\u001B[0;34m(r)\u001B[0m\n\u001B[1;32m    212\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConcurrentUpdate(r)\n\u001B[0;32m--> 213\u001B[0m \u001B[43m_response_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28msetattr\u001B[39m(r, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise_for_status\u001B[39m\u001B[38;5;124m'\u001B[39m, _response_raise_for_status\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(r))\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/deriva_binding.py:97\u001B[0m, in \u001B[0;36m_response_raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     96\u001B[0m details \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Details: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 97\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mHTTPError(\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m Error: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m for url: [\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (\n\u001B[1;32m     99\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus_code,\n\u001B[1;32m    100\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClient\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m500\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mServer\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    101\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreason,\n\u001B[1;32m    102\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl,\n\u001B[1;32m    103\u001B[0m         details \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontent \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontent \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    104\u001B[0m     ),\n\u001B[1;32m    105\u001B[0m     response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\n\u001B[1;32m    106\u001B[0m )\n",
      "\u001B[0;31mHTTPError\u001B[0m: 409 Client Error: CONFLICT for url: [https://dev.eye-ai.org/ermrest/catalog/428/attributegroup/eye-ai:Diagnosis/RID;Execution] Details: b'Request conflicts with state of server. Detail: Input data violates model. ERROR:  duplicate key value violates unique constraint \"Execution_Image_Image_Diagnosis_assoc_key\"\\nDETAIL:  Key (\"Execution\", \"Image\", \"Feature_Name\")=(5-R6C2, 2-D2GY, Diagnosis) already exists.\\n\\n'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mDataPathException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[108], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mupdate_exec_rid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_lac\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[106], line 28\u001B[0m, in \u001B[0;36mupdate_exec_rid\u001B[0;34m(dataset_rid)\u001B[0m\n\u001B[1;32m     26\u001B[0m     update_rec[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExecution\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m execution_rid\n\u001B[1;32m     27\u001B[0m     update_entities \u001B[38;5;241m=\u001B[39m update_rec\u001B[38;5;241m.\u001B[39mto_dict(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m     \u001B[43mbatchUpdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdiagnosis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_entities\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mdiagnosis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExecution\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     EA\u001B[38;5;241m.\u001B[39mupdate_status(Status\u001B[38;5;241m.\u001B[39mcompleted, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdate execution rid to diagnosis\u001B[39m\u001B[38;5;124m\"\u001B[39m, execution_rid)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn[47], line 5\u001B[0m, in \u001B[0;36mbatchUpdate\u001B[0;34m(table, entities, update_cols)\u001B[0m\n\u001B[1;32m      3\u001B[0m batch_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m2000\u001B[39m, n)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39mbatch_num):\n\u001B[0;32m----> 5\u001B[0m     \u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mentities\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatch_num\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatch_num\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRID\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_cols\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessed batch: \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, i \u001B[38;5;241m*\u001B[39m batch_num, (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m batch_num)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m*\u001B[39mbatch_num \u001B[38;5;241m<\u001B[39m n:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/datapath.py:1109\u001B[0m, in \u001B[0;36m_TableWrapper.update\u001B[0;34m(self, entities, correlation, targets, retry_codes, backoff_factor, max_attempts, max_batch_rows, max_batch_bytes)\u001B[0m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m _generate_batches(\n\u001B[1;32m   1104\u001B[0m     entities,\n\u001B[1;32m   1105\u001B[0m     max_batch_rows\u001B[38;5;241m=\u001B[39mmax_batch_rows,\n\u001B[1;32m   1106\u001B[0m     max_batch_bytes\u001B[38;5;241m=\u001B[39mmax_batch_bytes\n\u001B[1;32m   1107\u001B[0m ):\n\u001B[1;32m   1108\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1109\u001B[0m         resp \u001B[38;5;241m=\u001B[39m \u001B[43m_request_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1110\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretry_codes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_codes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1112\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbackoff_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackoff_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_attempts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_attempts\u001B[49m\n\u001B[1;32m   1114\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1115\u001B[0m         results\u001B[38;5;241m.\u001B[39mextend(resp\u001B[38;5;241m.\u001B[39mjson())\n\u001B[1;32m   1116\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Eye_ai/lib/python3.10/site-packages/deriva/core/datapath.py:785\u001B[0m, in \u001B[0;36m_request_with_retry\u001B[0;34m(request_func, retry_codes, backoff_factor, max_attempts)\u001B[0m\n\u001B[1;32m    783\u001B[0m         last_ex \u001B[38;5;241m=\u001B[39m DataPathException(_http_error_message(e), e)\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mint\u001B[39m(e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mstatus_code) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m retry_codes:\n\u001B[0;32m--> 785\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m last_ex\n\u001B[1;32m    786\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    787\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mtext)\n",
      "\u001B[0;31mDataPathException\u001B[0m: DETAIL:  Key (\"Execution\", \"Image\", \"Feature_Name\")=(5-R6C2, 2-D2GY, Diagnosis) already exists.\n\n409 Client Error: CONFLICT for url: [https://dev.eye-ai.org/ermrest/catalog/428/attributegroup/eye-ai:Diagnosis/RID;Execution] Details: b'Request conflicts with state of server. Detail: Input data violates model. ERROR:  duplicate key value violates unique constraint \"Execution_Image_Image_Diagnosis_assoc_key\"\\nDETAIL:  Key (\"Execution\", \"Image\", \"Feature_Name\")=(5-R6C2, 2-D2GY, Diagnosis) already exists.\\n\\n'"
     ]
    }
   ],
   "source": [
    "update_exec_rid(new_lac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
