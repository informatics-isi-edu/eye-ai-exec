{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2006ce9-6ca1-402d-b9ad-8853b85509cf",
   "metadata": {},
   "source": [
    "# Connect Eye-AI and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003248d9-3365-4aaa-874a-858234cb2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# # Update the load path so python can find modules for the model\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "# sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "# sys.path.insert(0, str(Path.home() / repo_dir / \"deriva-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499060d-4de0-4ab1-bf23-8f766d24dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "#from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration\n",
    "from deriva_ml import DerivaML, Workflow, ExecutionConfiguration, VersionPart\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f254b11-9f01-4185-95a0-cd7f80995c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "host = 'www.eye-ai.org'\n",
    "#host = 'dev.eye-ai.org' #for dev testing\n",
    "catalog_id = \"eye-ai\"\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ee433-9dce-460f-ab4d-0aff7d4eea0e",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40db10-6f64-4b6e-a22d-3c7011e2a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7340a9-2356-481b-bbd9-2f1f30955ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_dataset = \"2-277G\"  #\"2-N93J\"\n",
    "asset_RID = [\"2-C8JM\"]\n",
    "ml_instance = DerivaML(host, catalog_id=\"eye-ai\")\n",
    "\n",
    "#ml_instance.increment_dataset_version(dataset_rid='2-277M', component= VersionPart.patch, description='Update to latest deriva-ml schema')\n",
    "\n",
    "preds_workflow = EA.add_workflow( \n",
    "    Workflow(\n",
    "        name=\"LAC data template\",\n",
    "        url=\"https://github.com/informatics-isi-edu/eye-ai-exec/blob/main/notebooks/Sandbox_KB/Get_VGGPreds.ipynb\",\n",
    "        workflow_type=\"Test Workflow\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=[\n",
    "        {\n",
    "            \"rid\": source_dataset,\n",
    "            \"materialize\": False,\n",
    "            \"version\": ml_instance.dataset_version(source_dataset),\n",
    "        }\n",
    "    ],\n",
    "    assets=asset_RID,\n",
    "    workflow=preds_workflow,\n",
    "    description=\"Instance of linking VGG19 predictions to patient-level data\",\n",
    "    )\n",
    "\n",
    "exec = ml_instance.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db71483-dce2-4fdf-bcbc-0c952989d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a356d7-7958-4555-8229-baeda05ee0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my test\n",
    "\n",
    "\n",
    "ds_bag = exec.datasets[0]\n",
    "imageDF = ds_bag.get_table_as_dataframe('Image_Diagnosis')\n",
    "angle2DF = EA.filter_angle_2( ds_bag )\n",
    "trainDF = EA.image_tall(ds_bag, 'Initial Diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21cf8c-a085-4bf8-978b-d7b54f8f786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDF = pd.merge( angle2DF, imageDF[imageDF['Diagnosis_Tag'] == 'Initial Diagnosis'],\n",
    "                  how = 'left', left_on = 'RID', right_on = 'Image')\n",
    "\n",
    "mergeDF['Diagnosis_Image'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046699e0-b957-4285-adf0-5eb4d8a6501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a5b6e-723e-457e-bfd0-bb1d75569e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDF[imageDF['Diagnosis_Tag'] == 'Initial Diagnosis'].loc[:,'Diagnosis_Image'].value_counts()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0a959fb-44f5-4681-b2fa-a4ba380842e2",
   "metadata": {},
   "source": [
    "# Get Pertinent Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64273618-87e3-40ed-8e39-a8d176728fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bag = exec.datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03121ac5-83e9-483a-a4b4-13d0ae191757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get expert consensus diagnosis\n",
    "experts = ['Benjamin Xu', 'Brandon Wong', 'Van Nguyen']\n",
    "dxExpertOG = EA.image_tall(ds_bag, 'AI_glaucomasuspect_test')\n",
    "dxExpertOG = dxExpertOG[ dxExpertOG['Full_Name'].isin(experts) ]\n",
    "\n",
    "ridStore = []\n",
    "dxStore = []\n",
    "cDxStore = []\n",
    "cdrStore = []\n",
    "byxStore = []\n",
    "bwStore = []\n",
    "vnStore = []\n",
    "\n",
    "for id in list(dxExpertOG['Image_RID'].unique()):\n",
    "    ridStore.append(id)\n",
    "    dxTemp = dxExpertOG[ dxExpertOG['Image_RID'] == id ]\n",
    "    byxStore.append( dxTemp[ dxTemp['Full_Name'] == 'Benjamin Xu' ].loc[:,'Diagnosis_Image'].iloc[0] )\n",
    "    bwStore.append( dxTemp[ dxTemp['Full_Name'] == 'Brandon Wong' ].loc[:,'Diagnosis_Image'].iloc[0] )\n",
    "    vnStore.append( dxTemp[ dxTemp['Full_Name'] == 'Van Nguyen' ].loc[:,'Diagnosis_Image'].iloc[0] )\n",
    "    dxCDR = dxTemp[dxTemp['Cup_Disk_Ratio'].apply(type) == float] \n",
    "    if len(dxCDR) > 0:\n",
    "        cdrStore.append( round( dxCDR['Cup_Disk_Ratio'].sum() / len(dxCDR['Cup_Disk_Ratio']), 1 ) )\n",
    "        if (dxTemp['Diagnosis_Image'] == 'Suspected Glaucoma').sum() > 1:\n",
    "            dxStore.append('Suspected Glaucoma')\n",
    "            cDxStore.append( (dxTemp['Diagnosis_Image'] == 'Suspected Glaucoma').sum() )\n",
    "        else:\n",
    "            dxStore.append('No Glaucoma')\n",
    "            cDxStore.append( (dxTemp['Diagnosis_Image'] == 'No Glaucoma').sum() )\n",
    "    else:\n",
    "        cdrStore.append('')\n",
    "        dxStore.append('Not Graded, Bad Quality')\n",
    "        cDxStore.append(3)\n",
    "\n",
    "dxExpert = pd.DataFrame({'RID_Image':ridStore, 'Diagnosis_Image_Expert':dxStore, 'Diagnosis_Image_Expert_Count':cDxStore, 'Diagnosis_BYX':byxStore, 'Diagnosis_BW':bwStore, 'Diagnosis_VN':vnStore, 'CDR_Expert':cdrStore})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0aa74e-ad66-4587-91db-4dfdca3da10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update column names\n",
    "pd.options.mode.copy_on_write = True\n",
    "def updateCols(df, cols, colDict):\n",
    "    df = df[cols]\n",
    "    df.rename( columns = colDict, inplace = True )\n",
    "    for c in set(cols).intersection( set(colDict) ): cols[cols.index(c)] = colDict.get(c)\n",
    "    return df\n",
    "\n",
    "cols = ['Image', 'Diagnosis_Image_Optom', 'Diagnosis_Image_CNN']\n",
    "colDict = {'Image':'RID_Image', 'Observation':'RID_Observation', 'Subject':'RID_Subject'}\n",
    "\n",
    "# Build up diagnosis DF for Optom and CNN\n",
    "diags = ds_bag.get_table_as_dataframe('Image_Diagnosis')\n",
    "diags = pd.merge( diags[diags['Execution'] == '2-C6E0'],\n",
    "                   diags[diags['Diagnosis_Tag'] == 'Initial Diagnosis'],\n",
    "                   on = 'Image', how = 'left', suffixes = ['_CNN', '_Optom'])\n",
    "\n",
    "diags = updateCols( diags, cols, colDict )\n",
    "del(cols[0])\n",
    "cols[:0] = ['RID_Image', 'Diagnosis_Image_Expert', 'Diagnosis_Image_Expert_Count', 'Diagnosis_BYX', 'Diagnosis_BW', 'Diagnosis_VN', 'CDR_Expert']\n",
    "\n",
    "# Merge onto diagnosis DF for Expert\n",
    "diags = pd.merge( dxExpert, diags, on = 'RID_Image', how = 'left' )\n",
    "\n",
    "# Link to image data\n",
    "linkdDF = pd.merge( ds_bag.get_table_as_dataframe('Image'),\n",
    "                  diags,\n",
    "                  left_on = 'RID', right_on = 'RID_Image', \n",
    "                  how = 'right')\n",
    "\n",
    "cols[:0] = ['Observation', 'Image_Side']\n",
    "linkdDF = updateCols( linkdDF, cols, colDict )\n",
    "\n",
    "# Link to observation data\n",
    "linkdDF = pd.merge( ds_bag.get_table_as_dataframe('Observation'),\n",
    "                   linkdDF,\n",
    "                   left_on = 'RID', right_on = 'RID_Observation', \n",
    "                   how = 'right')\n",
    "\n",
    "cols[:0] = ['Subject', 'date_of_encounter', 'Age', 'hba1c', 'dr_level', 'glaucoma_hx', 'consultant', 'Subject_image_quality']  # removed site_mrn\n",
    "linkdDF = updateCols( linkdDF, cols, colDict )\n",
    "\n",
    "# Link to subject data\n",
    "linkdDF = pd.merge( ds_bag.get_table_as_dataframe('Subject'),\n",
    "                   linkdDF,\n",
    "                   left_on = 'RID', right_on = 'RID_Subject', \n",
    "                   how = 'right')\n",
    "\n",
    "cols[:0] = ['RID_Subject', 'Subject_Gender', 'Subject_Ethnicity']  # removed site_mrn\n",
    "del(cols[ np.where( np.array(cols)=='RID_Subject' )[0][1] ]) # remove duplicated RID_Subject\n",
    "linkdDF = updateCols( linkdDF, cols, colDict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e1043-4812-45d8-baa4-4582dd3682dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions from Execution 2-C6E0 (VGG19 on test set)\n",
    "preds = pd.read_csv(exec.asset_paths[0])\n",
    "\n",
    "# Get RID Image from Filename\n",
    "preds['Filename'] = preds['Filename'].apply(lambda x: x.split(\"_\")[3].split(\".\")[0])\n",
    "\n",
    "# Link back to full DF\n",
    "linkdDF = pd.merge( linkdDF,\n",
    "                   preds[['Filename', 'Probability Score']],\n",
    "                   left_on = 'RID_Image', right_on = 'Filename', \n",
    "                   how = 'left')\n",
    "\n",
    "cols.append('Probability Score')\n",
    "colDict = {'Probability Score':'Diagnosis_CNN_Prob'}\n",
    "linkdDF = updateCols( linkdDF, cols, colDict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff13e6-7a50-447f-912e-b6525138c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subject level DF\n",
    "def getMaxDx(dxList):\n",
    "    if (dxList == 'Suspected Glaucoma').sum() > 0:\n",
    "        return 'Suspected Glaucoma'\n",
    "    elif (dxList == 'Not Graded, Bad Quality').sum() > 0:\n",
    "        return 'Not Graded, Bad Quality'\n",
    "    else:\n",
    "        return 'No Glaucoma'\n",
    "\n",
    "def getMaxCDR(cdrList):\n",
    "    t = [x for x in tempDF['CDR_Expert'] if isinstance(x, (int, float))]\n",
    "    if len(t) > 0:\n",
    "        return max(t)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "idList = []\n",
    "genderList = []\n",
    "ethnicityList = []\n",
    "dxExpertList = []\n",
    "cdrMaxList = []\n",
    "dxOptomList = []\n",
    "dxCNNList = []\n",
    "probCNNList = []\n",
    "\n",
    "for id in pd.unique( linkdDF['RID_Subject'] ):\n",
    "    tempDF = linkdDF[ linkdDF['RID_Subject'] == id ]\n",
    "    idList.append(id)\n",
    "    genderList.append( tempDF['Subject_Gender'].iloc[0] )\n",
    "    ethnicityList.append( tempDF['Subject_Ethnicity'].iloc[0] )\n",
    "    dxExpertList.append( getMaxDx( tempDF['Diagnosis_Image_Expert'] ) )\n",
    "    cdrMaxList.append( getMaxCDR( tempDF['CDR_Expert'] ) )\n",
    "    dxOptomList.append( getMaxDx( tempDF['Diagnosis_Image_Optom'] ) )\n",
    "    dxCNNList.append( getMaxDx( tempDF['Diagnosis_Image_CNN'] ) )\n",
    "    probCNNList.append( tempDF['Diagnosis_CNN_Prob'].max() )\n",
    "\n",
    "dxSubjectDF = pd.DataFrame({'RID_Subject':idList, 'Subject_Gender':genderList, 'Subject_Ethnicity':ethnicityList, 'Diagnosis_Image_Expert':dxExpertList, 'CDR_Expert':cdrMaxList, 'Diagnosis_Image_Optom':dxOptomList, 'Diagnosis_Image_CNN':dxCNNList, 'Diagnosis_CNN_Prob':probCNNList})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2794d09-ff63-487d-ac7a-5f9c61364982",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7e2aa-ea93-4152-b2b9-2be8e9a7f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique( dxSubjectDF['Subject_Ethnicity'], return_counts=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930383e-2223-4248-b96d-9dae1e85fc69",
   "metadata": {},
   "source": [
    "##### DEFINE Parity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcd923-c483-41f6-9038-6ea3d4e42831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for Parity Metrics\n",
    "\n",
    "def glcRate(xTab):\n",
    "    return (xTab.iloc[0,1] + xTab.iloc[1,1]) / xTab.to_numpy().sum()\n",
    "\n",
    "def predPosRate(xTab):\n",
    "    return (xTab.iloc[1,0] + xTab.iloc[1,1]) / xTab.to_numpy().sum()\n",
    "    \n",
    "def accuracy(xTab):\n",
    "    return (xTab.iloc[0,0] + xTab.iloc[1,1]) / xTab.to_numpy().sum()\n",
    "\n",
    "def tpr(xTab):\n",
    "    return xTab.iloc[1,1] / (xTab.iloc[1,1] + xTab.iloc[0,1])\n",
    "\n",
    "def tnr(xTab):\n",
    "    return xTab.iloc[0,0] / (xTab.iloc[1,0] + xTab.iloc[0,0])\n",
    "\n",
    "def fpr(xTab):\n",
    "    return xTab.iloc[1,0] / (xTab.iloc[1,0] + xTab.iloc[0,0])\n",
    "\n",
    "def fnr(xTab):\n",
    "    return xTab.iloc[0,1] / (xTab.iloc[0,1] + xTab.iloc[1,1])\n",
    "\n",
    "def getParityMetrics(matrixList):\n",
    "    vals = { 'n':{}, 'glcRate':{}, 'accuracy':{}, 'tpr':{}, 'tnr':{}, 'fpr':{}, 'fnr':{} }\n",
    "    for e in matrixList.keys():\n",
    "        vals['n'][e] = matrixList[e].to_numpy().sum()\n",
    "        vals['glcRate'][e] = glcRate( matrixList[e] )\n",
    "        vals['accuracy'][e] = accuracy( matrixList[e] )\n",
    "        vals['tpr'][e] = tpr( matrixList[e] )\n",
    "        vals['tnr'][e] = tnr( matrixList[e] )\n",
    "        vals['fpr'][e] = fpr( matrixList[e] )\n",
    "        vals['fnr'][e] = fnr( matrixList[e] )\n",
    "    return pd.DataFrame.from_dict(vals).transpose().loc[:,['All', 'Latin American', 'African Descent', 'Asian', 'Caucasian', 'ethnicity not specified', 'Other']]\n",
    "\n",
    "def getParityMetrics2(factorSeries, dxSeriesPred, dxSeriesActual):\n",
    "    tempDF = pd.DataFrame({ 'Factor': factorSeries, 'DxPred': dxSeriesPred, 'DxActual': dxSeriesActual })\n",
    "    tempDF['DxPred'] = tempDF['DxPred'].astype('category')\n",
    "    tempDF['DxActual'] = tempDF['DxActual'].astype('category')\n",
    "    matrixList = {}\n",
    "    matrixList['All'] = pd.crosstab( dxSeriesPred, dxSeriesActual )\n",
    "    for e in pd.unique( factorSeries ):\n",
    "        matrixList[e] = pd.crosstab( tempDF[ tempDF['Factor'] == e ]['DxPred'], tempDF[ tempDF['Factor'] == e ]['DxActual'], dropna=False )\n",
    "\n",
    "    vals = { 'n':{}, 'glcRate':{}, 'predPosRate':{}, 'accuracy':{}, 'tpr':{}, 'tnr':{}, 'fpr':{}, 'fnr':{} }\n",
    "    for e in matrixList.keys():\n",
    "        vals['n'][e] = matrixList[e].to_numpy().sum()\n",
    "        vals['glcRate'][e] = glcRate( matrixList[e] )\n",
    "        vals['predPosRate'][e] = predPosRate( matrixList[e] )\n",
    "        vals['accuracy'][e] = accuracy( matrixList[e] )\n",
    "        vals['tpr'][e] = tpr( matrixList[e] )\n",
    "        vals['tnr'][e] = tnr( matrixList[e] )\n",
    "        vals['fpr'][e] = fpr( matrixList[e] )\n",
    "        vals['fnr'][e] = fnr( matrixList[e] )\n",
    "    return pd.DataFrame.from_dict(vals).transpose()#.loc[:,['All', 'Latin American', 'African Descent', 'Asian', 'Caucasian', 'ethnicity not specified', 'Other']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5e952d0-bdbd-4a38-bf62-a3c3b8468557",
   "metadata": {},
   "source": [
    "# Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e822ba-c167-46cf-8155-4321fd5e232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF = dxSubjectDF[ dxSubjectDF['CDR_Expert'] != '' ]\n",
    "parityDF = getParityMetrics2( tempDF['CDR_Expert'], tempDF['Diagnosis_Image_CNN'], tempDF['Diagnosis_Image_Optom'] )\n",
    "\n",
    "\n",
    "# SCATTER PLOTS FOR METRICS vs. CDR  -----\n",
    "\n",
    "# test = parityDF.loc['accuracy'].to_frame()\n",
    "# inds = [x for x in test.index if x != 'All']\n",
    "# test = test.loc[inds]\n",
    "# test['CDR'] = test.index\n",
    "# test = test.sort_values( by='CDR' )\n",
    "# # test.plot.scatter( x='CDR', y='tnr')\n",
    "# test.plot.line( x='CDR', y='accuracy' )\n",
    "\n",
    "# test = parityDF.loc['n'][1:10].to_frame()\n",
    "# test['CDR'] = test.index\n",
    "\n",
    "\n",
    "# HISTOGRAM BY CDR ALL  -----\n",
    "\n",
    "#plt.bar(test['CDR'], test['n'], width=0.05, align='center')\n",
    "\n",
    "\n",
    "# HISTOGRAM BY CDR GROUPED BY ETHNICITY  -----\n",
    "\n",
    "tempDF['Subject_Ethnicity'] = tempDF['Subject_Ethnicity'].astype('category')\n",
    "cdrEthCounts = {}\n",
    "for i in pd.unique( tempDF['CDR_Expert'] ):\n",
    "    cdrEthCounts[i] = tempDF[ tempDF['CDR_Expert'] == i ]['Subject_Ethnicity'].value_counts()\n",
    "\n",
    "test = cdrEthCounts[ list( cdrEthCounts )[0] ].to_frame(name=list( cdrEthCounts )[0])\n",
    "for i in list( cdrEthCounts )[1:len(list( cdrEthCounts ))]:\n",
    "    test = pd.concat([test, cdrEthCounts[i].to_frame(name=i)], axis=1)\n",
    "\n",
    "test = test.transpose()\n",
    "test['CDR'] = test.index\n",
    "\n",
    "test = test.sort_values( by='CDR' )\n",
    "test\n",
    "\n",
    "# HISTOGRAM BY CDR GROUPED BY ETHNICITY AND NORMALIZED -----\n",
    "\n",
    "# testNorm = test.copy()\n",
    "\n",
    "# for i in [x for x in test.columns if x != 'CDR']:\n",
    "#     testNorm[i] = test[i] / test[i].sum()\n",
    "\n",
    "# test.plot(x='CDR', kind='bar', stacked=False).legend(bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "# tempDF.groupby('Subject_Ethnicity').plot.scatter( x='CDR_Expert', y='Diagnosis_CNN_Prob', ax=ax, color="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b980db67-6e33-4a78-b085-913f31a2a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(y_true=dxSubjectDF['Diagnosis_Image_Optom'], y_prob=dxSubjectDF['Diagnosis_CNN_Prob'], pos_label='Suspected Glaucoma', n_bins=5)\n",
    "plt.plot(prob_pred,prob_true)\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.axline((0,0), slope=1, color='0.0', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6aeec-0976-4c20-95ec-93085eed4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true = {}\n",
    "prob_pred = {}\n",
    "\n",
    "# CALIBRATION CURVES GROUPED BY ETHNICITY\n",
    "\n",
    "for e in ['Latin American', 'African Descent', 'ethnicity not specified', 'Asian', 'Other','Caucasian']:\n",
    "    tempDF = dxSubjectDF[dxSubjectDF['Subject_Ethnicity'] == e]\n",
    "    prob_true[e], prob_pred[e] = calibration_curve(y_true=tempDF['Diagnosis_Image_Optom'], y_prob=tempDF['Diagnosis_CNN_Prob'], pos_label='Suspected Glaucoma', n_bins=10)\n",
    "    plt.plot(prob_pred[e],prob_true[e], label=e)\n",
    "\n",
    "\n",
    "# CALIBRATION CURVES GROUPED BY GENDER\n",
    "\n",
    "# for e in ['M', 'F']:\n",
    "#     tempDF = dxSubjectDF[dxSubjectDF['Subject_Gender'] == e]\n",
    "#     prob_true[e], prob_pred[e] = calibration_curve(y_true=tempDF['Diagnosis_Image_Optom'], y_prob=tempDF['Diagnosis_CNN_Prob'], pos_label='Suspected Glaucoma', n_bins=10)\n",
    "#     plt.plot(prob_pred[e],prob_true[e], label=e)\n",
    "    \n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
    "plt.axline((0,0), slope=1, color='0.0', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d852693-68cf-40a5-8e0c-1f1cd4298c3b",
   "metadata": {},
   "source": [
    "# Calculate Parity Metrics at IMAGE Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4d94c-34ff-48e5-8af5-844ee46f2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity metrics for CNN vs. Optom\n",
    "getParityMetrics2( linkdDF['Subject_Ethnicity'], linkdDF['Diagnosis_Image_CNN'], linkdDF['Diagnosis_Image_Optom'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c02572-8a0f-4194-b019-295dc5161a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity metrics for CNN vs. Expert labels\n",
    "expertGradedDF = linkdDF[linkdDF['Diagnosis_Image_Expert'] != 'Not Graded, Bad Quality']\n",
    "getParityMetrics2( expertGradedDF['Subject_Ethnicity'], expertGradedDF['Diagnosis_Image_CNN'], expertGradedDF['Diagnosis_Image_Expert'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e555f-b4db-4736-97f3-4b338562ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity metrics for Optom vs. Expert labels\n",
    "getParityMetrics2( expertGradedDF['Subject_Ethnicity'], expertGradedDF['Diagnosis_Image_Optom'], expertGradedDF['Diagnosis_Image_Expert'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ede89-8648-4d76-a872-d238519f85f9",
   "metadata": {},
   "source": [
    "# Calculate Parity Metrics at SUBJECT Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760810dc-a920-4d2a-8f56-722029130692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity metrics for CNN vs. Optom\n",
    "getParityMetrics2( dxSubjectDF['Subject_Ethnicity'], dxSubjectDF['Diagnosis_Image_CNN'], dxSubjectDF['Diagnosis_Image_Optom'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179de07-8e7c-42d2-80df-cce3943d97fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity metrics for CNN vs. Expert labels\n",
    "expertGradedDF = dxSubjectDF[dxSubjectDF['Diagnosis_Image_Expert'] != 'Not Graded, Bad Quality']\n",
    "getParityMetrics2( expertGradedDF['Subject_Ethnicity'], expertGradedDF['Diagnosis_Image_CNN'], expertGradedDF['Diagnosis_Image_Expert'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1fea12-3872-441c-8882-e3df6a0558a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity metrics for Optom vs. Expert labels\n",
    "getParityMetrics2( expertGradedDF['Subject_Ethnicity'], expertGradedDF['Diagnosis_Image_Optom'], expertGradedDF['Diagnosis_Image_Expert'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284303d-b46e-4866-b510-b03cfab5e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Space to stop autoscroll\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b9906-7733-4320-a776-c7adfa893ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(linkdDF['consultant'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f4c40-d50b-481a-b55b-d253ea01c37f",
   "metadata": {},
   "source": [
    "# Upload Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d4849-0230-4722-afa5-47f03a9d90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crete asset path\n",
    "asset_type_name = \"Diagnosis_Analysis\"\n",
    "asset_path = exec.execution_asset_path(asset_type_name)\n",
    "\n",
    "# save assets to asset_path\n",
    "linkdDF.to_csv(asset_path/'ImagesToVGG19.csv', index=False)\n",
    "#dxSubjectDF.to_csv(asset_path/'SubjectsToVGG19.csv', index=False)\n",
    "#parityMetrics.to_csv(asset_path/'ParityMetrics.csv', index=False)\n",
    "\n",
    "# upload assets to catalog\n",
    "exec.upload_execution_outputs(clean_folder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf78fd5-8f9e-4abf-a946-c716b9c86ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
