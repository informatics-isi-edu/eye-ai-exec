{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install pytorch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 pytorch-cuda=12.1 -c pytorch -c nvidia -y\n",
    "!cd ~/Repos && git clone --branch eye-ai-compatible https://github.com/huynguyentran/RETFound_MAE.git \n",
    "!cd ~/Repos/RETFound_MAE && git pull\n",
    "!cd ~/Repos/RETFound_MAE && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "True\n",
      "NVIDIA A10G\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Should print \"12.1\"\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # Should print \"NVIDIA A10G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"RETFound_MAE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:43:27.590096: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-24 00:43:27.590161: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-24 00:43:27.726099: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-24 00:43:27.988335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 00:43:29.824320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:43:31,971 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-24 00:43:31,972 - INFO - Loading dirty model.  Consider commiting and tagging: 1.1.0.post123+git.84bdec8f.dirty\n"
     ]
    }
   ],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 00:43:37,434 - WARNING - File /home/nguyent8/Repos/eye-ai-exec/notebooks/Multimodal_Huy/multimodal_glaucoma_vs_suspected.ipynb has been modified since last commit. Consider commiting before executing\n",
      "2025-03-24 00:43:38,821 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-24 00:43:39,557 - INFO - Loading /data/4-4116_5a611f3561ac538bae3767ae4c1bafa1533b9722fca8a1fc78085f422c5290f6/Dataset_4-4116\n",
      "2025-03-24 00:43:40,331 - INFO - Creating new database for dataset: 4-4116 in /data/nguyent8/EyeAI_working/4-4116@330-B1Z0-2NHT.db\n",
      "2025-03-24 00:43:41,465 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-24 00:43:42,440 - INFO - Loading /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d70f7b3bfd0a0cd3931d4e2edbade797d/Dataset_4-411G\n",
      "2025-03-24 00:43:42,958 - INFO - Creating new database for dataset: 4-411G in /data/nguyent8/EyeAI_working/4-411G@330-B1Z0-GC2Y.db\n",
      "2025-03-24 00:43:43,682 - WARNING - nbstripout is not installed in repository. Please run nbstripout --install\n",
      "2025-03-24 00:43:44,753 - INFO - Loading /data/2-7P5P_52942baeabd3e1cee91bbbea4e58f3aca680a8f59aa72d4184823e7df474fd2a/Dataset_2-7P5P\n",
      "2025-03-24 00:43:50,449 - INFO - Creating new database for dataset: 2-7P5P in /data/nguyent8/EyeAI_working/2-7P5P@330-B1YY-G4RR.db\n",
      "2025-03-24 00:44:51,495 - INFO - File [/data/nguyent8/EyeAI_working/4-S412/asset/4-NKSJ_uncropped_Mar_09_2025.pth] transfer successful. 3471.44 MB transferred at 57.27 MB/second. Elapsed time: 0:01:00.615956.\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    '4-4116', # Selected images for training\n",
    "    '4-411G', # Selected images for testing\n",
    "    '2-7P5P', # Full multimodal dataset\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.create_workflow(\n",
    "    name=\"Multimodal workflow\",\n",
    "    workflow_type=\"Multimodal workflow\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download,\n",
    "    assets = ['4-QA7T',],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of applying CV modelsto multimodal data. We are attempting to increase the accuracy of prediction by including table values into images prediction.\")\n",
    "\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching_dir: /data\n",
      "_working_dir: /data/nguyent8/EyeAI_working\n",
      "execution_rid: 4-S412\n",
      "workflow_rid: 4-S3YC\n",
      "asset_paths: [PosixPath('/data/nguyent8/EyeAI_working/4-S412/asset/4-NKSJ_uncropped_Mar_09_2025.pth')]\n",
      "configuration: datasets=[DatasetSpec(rid='4-4116', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0)), DatasetSpec(rid='4-411G', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0)), DatasetSpec(rid='2-7P5P', materialize=True, version=DatasetVersion(major=2, minor=1, patch=0))] assets=['4-QA7T'] workflow='4-S3YC' description='Instance of applying CV modelsto multimodal data. We are attempting to increase the accuracy of prediction by including table values into images prediction.'\n"
     ]
    }
   ],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds_bag = execution.datasets[0]\n",
    "testing_ds_bag = execution.datasets[1]\n",
    "\n",
    "multimodal_full_ds_bag = execution.datasets[2]\n",
    "retfound_pretrained_weight = execution.asset_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_bag(ds_bag: DatasetBag, multimodal_full_ds_bag: DatasetBag):\n",
    "    observation_table = ds_bag.get_table_as_dataframe('Observation')\n",
    "    image_table = ds_bag.get_table_as_dataframe('Image')\n",
    "    laterality_table = ds_bag.get_table_as_dataframe('Execution_Image_Fundus_Laterality')\n",
    "\n",
    "    image_table_filtered = image_table[['RID', 'Filename', 'Observation']].rename(columns={'RID': 'RID_Image'})\n",
    "    laterality_table_filtered = laterality_table[['Image', 'Image_Side']].rename(columns={'Image': 'RID_Image'})\n",
    "    image_laterality = pd.merge(image_table_filtered, laterality_table_filtered, left_on='RID_Image', right_on='RID_Image', how='inner')\n",
    "    observation_table_filtered = observation_table[['RID',  'Subject']].rename(columns={'RID': 'RID_Observation'})\n",
    "    image_laterality_observation = pd.merge(image_laterality, observation_table_filtered, left_on='Observation', right_on='RID_Observation', how='inner')\n",
    "\n",
    "    wide = EA.multimodal_wide(multimodal_full_ds_bag) \n",
    "\n",
    "    image_observation_laterality_subject_wide = pd.merge(\n",
    "     wide, \n",
    "     image_laterality_observation, \n",
    "     left_on=['RID_Subject', 'Image_Side'], \n",
    "     right_on=['Subject', 'Image_Side'], \n",
    "     how='inner'\n",
    "    )\n",
    "\n",
    "    return image_observation_laterality_subject_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyent8/Repos/eye-ai-ml/eye_ai/eye_ai.py:425: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hvf_clean.loc[:, 'priority'] = hvf_clean['Field_Size'].map(priority)\n",
      "/home/nguyent8/Repos/eye-ai-ml/eye_ai/eye_ai.py:425: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hvf_clean.loc[:, 'priority'] = hvf_clean['Field_Size'].map(priority)\n"
     ]
    }
   ],
   "source": [
    "train_df = get_dataframe_from_bag(training_ds_bag, multimodal_full_ds_bag)\n",
    "test_df= get_dataframe_from_bag(testing_ds_bag, multimodal_full_ds_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_Image</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Condition_Label</th>\n",
       "      <th>Condition_Display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-BRVR</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Primary open-angle glaucoma, bilateral, modera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-BVYT</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Primary open-angle glaucoma, bilateral, modera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-BETR</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Open angle with borderline findings, low risk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-BE0E</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Unspecified blepharitis unspecified eye, unspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-BGP2</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Unspecified blepharitis unspecified eye, unspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>2-C0CE</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Other long term (current) drug therapy_ Ocular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>2-BFV2</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Low-tension glaucoma, bilateral, mild stage_ A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>2-BTPM</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Low-tension glaucoma, bilateral, mild stage_ A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>2-BXQW</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Wilson's disease_ Type 2 diabetes mellitus wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2-BSKR</td>\n",
       "      <td>/data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Wilson's disease_ Type 2 diabetes mellitus wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RID_Image                                           Filename  \\\n",
       "0       2-BRVR  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "1       2-BVYT  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "2       2-BETR  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "3       2-BE0E  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "4       2-BGP2  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "...        ...                                                ...   \n",
       "1392    2-C0CE  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "1393    2-BFV2  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "1394    2-BTPM  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "1395    2-BXQW  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "1396    2-BSKR  /data/4-4116_5a611f3561ac538bae3767ae4c1bafa15...   \n",
       "\n",
       "     Condition_Label                                  Condition_Display  \n",
       "0               POAG  Primary open-angle glaucoma, bilateral, modera...  \n",
       "1               POAG  Primary open-angle glaucoma, bilateral, modera...  \n",
       "2                 GS  Open angle with borderline findings, low risk,...  \n",
       "3                 GS  Unspecified blepharitis unspecified eye, unspe...  \n",
       "4                 GS  Unspecified blepharitis unspecified eye, unspe...  \n",
       "...              ...                                                ...  \n",
       "1392              GS  Other long term (current) drug therapy_ Ocular...  \n",
       "1393            POAG  Low-tension glaucoma, bilateral, mild stage_ A...  \n",
       "1394            POAG  Low-tension glaucoma, bilateral, mild stage_ A...  \n",
       "1395              GS  Wilson's disease_ Type 2 diabetes mellitus wit...  \n",
       "1396              GS  Wilson's disease_ Type 2 diabetes mellitus wit...  \n",
       "\n",
       "[1397 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_df = train_df[['RID_Image', 'Filename','Condition_Label', 'Condition_Display']]\n",
    "filtered_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_Image</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Condition_Label</th>\n",
       "      <th>Condition_Display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-C1TP</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Presence of intraocular lens_ Other long term ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-BYZR</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Type 2 diabetes mellitus with diabetic catarac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-BTK6</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>GS</td>\n",
       "      <td>Type 2 diabetes mellitus with diabetic catarac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-BW42</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Primary open-angle glaucoma, bilateral, severe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-BMJC</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Primary open-angle glaucoma, bilateral, severe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2-BWWG</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Presence of intraocular lens_ Low-tension glau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2-BT0E</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>PACG</td>\n",
       "      <td>Type 2 diabetes mellitus without complications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2-BDQT</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>PACG</td>\n",
       "      <td>Type 2 diabetes mellitus without complications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2-BJ6M</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Primary open-angle glaucoma, bilateral, modera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2-BTG6</td>\n",
       "      <td>/data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...</td>\n",
       "      <td>POAG</td>\n",
       "      <td>Primary open-angle glaucoma, bilateral, modera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RID_Image                                           Filename  \\\n",
       "0      2-C1TP  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "1      2-BYZR  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "2      2-BTK6  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "3      2-BW42  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "4      2-BMJC  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "..        ...                                                ...   \n",
       "338    2-BWWG  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "339    2-BT0E  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "340    2-BDQT  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "341    2-BJ6M  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "342    2-BTG6  /data/4-411G_d5fd9f998a7b713e17b9b70eec4cef9d7...   \n",
       "\n",
       "    Condition_Label                                  Condition_Display  \n",
       "0                GS  Presence of intraocular lens_ Other long term ...  \n",
       "1                GS  Type 2 diabetes mellitus with diabetic catarac...  \n",
       "2                GS  Type 2 diabetes mellitus with diabetic catarac...  \n",
       "3              POAG  Primary open-angle glaucoma, bilateral, severe...  \n",
       "4              POAG  Primary open-angle glaucoma, bilateral, severe...  \n",
       "..              ...                                                ...  \n",
       "338            POAG  Presence of intraocular lens_ Low-tension glau...  \n",
       "339            PACG  Type 2 diabetes mellitus without complications...  \n",
       "340            PACG  Type 2 diabetes mellitus without complications...  \n",
       "341            POAG  Primary open-angle glaucoma, bilateral, modera...  \n",
       "342            POAG  Primary open-angle glaucoma, bilateral, modera...  \n",
       "\n",
       "[343 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_test_df = test_df[['RID_Image', 'Filename','Condition_Label', 'Condition_Display']]\n",
    "filtered_test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/nguyent8/EyeAI_working')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_dir = execution._working_dir\n",
    "working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\"Glaucoma_Suspect\": 0 ,\n",
    "            \"Glaucoma\": 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "\n",
    "def create_dataset_folder(df, output_path, output_name):\n",
    "    output_path =  output_path / output_name\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_path_suspected = output_path / \"Glaucoma_Suspect\"\n",
    "    output_path_glaucoma = output_path / \"Glaucoma\"\n",
    "    \n",
    "    output_path_suspected.mkdir(parents=True, exist_ok=True)\n",
    "    output_path_glaucoma.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    for index, row in df.iterrows():     \n",
    "        src_path = row[\"Filename\"]\n",
    "        dest_name = row[\"RID_Image\"] + \".jpg\"\n",
    "        label = row['Condition_Label']\n",
    "        if label == \"GS\":\n",
    "            dest_path = os.path.join(output_path_suspected, dest_name)\n",
    "        elif label == \"POAG\" or label == \"PACG\":\n",
    "            dest_path = os.path.join(output_path_glaucoma, dest_name)\n",
    "        else: \n",
    "            continue    \n",
    "        shutil.copy2(src_path, dest_path)\n",
    "        \n",
    "    return output_path \n",
    "\n",
    "train_dir = create_dataset_folder(filtered_train_df, working_dir, \"train\")\n",
    "test_dir = create_dataset_folder(filtered_test_df, working_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/data/nguyent8/EyeAI_working/train'),\n",
       " PosixPath('/data/nguyent8/EyeAI_working/test'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set(train_dir, val_dir, split_ratio=0.15):\n",
    "     os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "     for class_name in os.listdir(train_dir):\n",
    "          class_train_path = os.path.join(train_dir, class_name)\n",
    "          class_val_path = os.path.join(val_dir, class_name)\n",
    "\n",
    "          if os.path.isdir(class_train_path):  \n",
    "               os.makedirs(class_val_path, exist_ok=True)\n",
    "\n",
    "               images = [f for f in os.listdir(class_train_path) if os.path.isfile(os.path.join(class_train_path, f))]\n",
    "               num_val = int(len(images) * split_ratio)\n",
    "\n",
    "               val_images = random.sample(images, num_val)\n",
    "               for img in val_images:\n",
    "                    shutil.move(os.path.join(class_train_path, img), os.path.join(class_val_path, img))\n",
    "\n",
    "val_dir = working_dir / \"val\"\n",
    "create_validation_set(train_dir, val_dir, split_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "  Glaucoma_Suspect: 373 images\n",
      "  Glaucoma: 728 images\n",
      "\n",
      "Validation Set:\n",
      "  Glaucoma_Suspect: 108 images\n",
      "  Glaucoma: 225 images\n",
      "\n",
      "Test Set:\n",
      "  Glaucoma_Suspect: 108 images\n",
      "  Glaucoma: 225 images\n"
     ]
    }
   ],
   "source": [
    "def count_images_per_class(directory):\n",
    "     class_counts = {}\n",
    "     for class_name in os.listdir(directory):\n",
    "          class_path = os.path.join(directory, class_name)\n",
    "          if os.path.isdir(class_path): \n",
    "               num_images = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
    "               class_counts[class_name] = num_images\n",
    "     return class_counts\n",
    "\n",
    "\n",
    "train_counts = count_images_per_class(train_dir)\n",
    "test_counts = count_images_per_class(test_dir)\n",
    "val_counts = count_images_per_class(val_dir)\n",
    "\n",
    "print(\"Training Set:\")\n",
    "for class_name, count in train_counts.items():\n",
    "     print(f\"  {class_name}: {count} images\")\n",
    "\n",
    "print(\"\\nValidation Set:\")\n",
    "for class_name, count in test_counts.items():\n",
    "     print(f\"  {class_name}: {count} images\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "for class_name, count in test_counts.items():\n",
    "     print(f\"  {class_name}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# def get_rid_images_from_folder(folder_path, df):\n",
    "#     # Get all the filenames in the folder (excluding the path)\n",
    "#     filenames = os.listdir(folder_path)\n",
    "    \n",
    "#     # Extract the 'RID_Image' values from the DataFrame that match the filenames (without the extension)\n",
    "#     rid_images_in_folder = df[df['RID_Image'].isin([os.path.splitext(f)[0] for f in filenames])]\n",
    "    \n",
    "#     return rid_images_in_folder\n",
    "\n",
    "# # Example usage for the 'train_dir', 'val_dir', and 'test_dir' folders:\n",
    "\n",
    "# # For train directory\n",
    "# train_glaucoma_suspect_folder = os.path.join(train_dir, \"Glaucoma_Suspect\")\n",
    "# train_glaucoma_folder = os.path.join(train_dir, \"Glaucoma\")\n",
    "\n",
    "# train_glaucoma_suspect_rid_images = get_rid_images_from_folder(train_glaucoma_suspect_folder, filtered_train_df)\n",
    "# train_glaucoma_rid_images = get_rid_images_from_folder(train_glaucoma_folder, filtered_train_df)\n",
    "\n",
    "# # For validation directory\n",
    "# val_glaucoma_suspect_folder = os.path.join(val_dir, \"Glaucoma_Suspect\")\n",
    "# val_glaucoma_folder = os.path.join(val_dir, \"Glaucoma\")\n",
    "\n",
    "# val_glaucoma_suspect_rid_images = get_rid_images_from_folder(val_glaucoma_suspect_folder, filtered_train_df)\n",
    "# val_glaucoma_rid_images = get_rid_images_from_folder(val_glaucoma_folder, filtered_train_df)\n",
    "\n",
    "# # For test directory\n",
    "# test_glaucoma_suspect_folder = os.path.join(test_dir, \"Glaucoma_Suspect\")\n",
    "# test_glaucoma_folder = os.path.join(test_dir, \"Glaucoma\")\n",
    "\n",
    "# test_glaucoma_suspect_rid_images = get_rid_images_from_folder(test_glaucoma_suspect_folder, filtered_test_df)\n",
    "# test_glaucoma_rid_images = get_rid_images_from_folder(test_glaucoma_folder, filtered_test_df)\n",
    "\n",
    "# # Convert 'RID_Image' column to lists\n",
    "# train_glaucoma_suspect_rid_images_list = train_glaucoma_suspect_rid_images['RID_Image'].tolist()\n",
    "# train_glaucoma_rid_images_list = train_glaucoma_rid_images['RID_Image'].tolist()\n",
    "\n",
    "# val_glaucoma_suspect_rid_images_list = val_glaucoma_suspect_rid_images['RID_Image'].tolist()\n",
    "# val_glaucoma_rid_images_list = val_glaucoma_rid_images['RID_Image'].tolist()\n",
    "\n",
    "# test_glaucoma_suspect_rid_images_list = test_glaucoma_suspect_rid_images['RID_Image'].tolist()\n",
    "# test_glaucoma_rid_images_list = test_glaucoma_rid_images['RID_Image'].tolist()\n",
    "\n",
    "\n",
    "# def save_to_text_file(file_path, data_list):\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         for item in data_list:\n",
    "#             file.write(f\"{item}\\n\")\n",
    "\n",
    "# # Save 'RID_Image' lists to text files\n",
    "# save_to_text_file(\"train_glaucoma_suspect_rid_images.txt\", train_glaucoma_suspect_rid_images_list)\n",
    "# save_to_text_file(\"train_glaucoma_rid_images.txt\", train_glaucoma_rid_images_list)\n",
    "\n",
    "# save_to_text_file(\"val_glaucoma_suspect_rid_images.txt\", val_glaucoma_suspect_rid_images_list)\n",
    "# save_to_text_file(\"val_glaucoma_rid_images.txt\", val_glaucoma_rid_images_list)\n",
    "\n",
    "# save_to_text_file(\"test_glaucoma_suspect_rid_images.txt\", test_glaucoma_suspect_rid_images_list)\n",
    "# save_to_text_file(\"test_glaucoma_rid_images.txt\", test_glaucoma_rid_images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Model_Prediction\")\n",
    "asset_path_logs = execution.execution_asset_path(\"Training_Log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mar_24_2025\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%b_%d_%Y\") \n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/data/nguyent8/EyeAI_working/train'),\n",
       " PosixPath('/data/nguyent8/EyeAI_working/val'),\n",
       " PosixPath('/data/nguyent8/EyeAI_working/test'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir, val_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:48:13.656620] Not using distributed mode\n",
      "[00:48:13.656814] [00:48:13.656807] [00:48:13.656833] job dir: /home/nguyent8/Repos/RETFound_MAE\n",
      "[00:48:13.656893] [00:48:13.656889] [00:48:13.656907] Namespace(batch_size=16,\n",
      "epochs=100,\n",
      "accum_iter=1,\n",
      "model='RETFound_mae',\n",
      "input_size=224,\n",
      "drop_path=0.2,\n",
      "clip_grad=None,\n",
      "weight_decay=0.05,\n",
      "lr=None,\n",
      "blr=0.005,\n",
      "layer_decay=0.65,\n",
      "min_lr=1e-06,\n",
      "warmup_epochs=10,\n",
      "color_jitter=None,\n",
      "aa='rand-m9-mstd0.5-inc1',\n",
      "smoothing=0.1,\n",
      "reprob=0.25,\n",
      "remode='pixel',\n",
      "recount=1,\n",
      "resplit=False,\n",
      "mixup=0,\n",
      "cutmix=0,\n",
      "cutmix_minmax=None,\n",
      "mixup_prob=1.0,\n",
      "mixup_switch_prob=0.5,\n",
      "mixup_mode='batch',\n",
      "finetune='/data/nguyent8/EyeAI_working/4-S412/asset/4-NKSJ_uncropped_Mar_09_2025.pth',\n",
      "task='/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction',\n",
      "global_pool=True,\n",
      "data_path='/data/nguyent8/EyeAI_working/',\n",
      "nb_classes=2,\n",
      "output_dir='/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction',\n",
      "log_dir='./output_logs',\n",
      "device='cuda',\n",
      "seed=0,\n",
      "resume='',\n",
      "start_epoch=0,\n",
      "eval=False,\n",
      "dist_eval=False,\n",
      "num_workers=10,\n",
      "pin_mem=True,\n",
      "world_size=1,\n",
      "local_rank=-1,\n",
      "dist_on_itp=False,\n",
      "dist_url='env://',\n",
      "savemodel=True,\n",
      "norm='IMAGENET',\n",
      "enhance=False,\n",
      "datasets_seed=2026,\n",
      "distributed=False)\n",
      "[00:48:39.640367] [00:48:39.639610] [00:48:39.641630] Load pre-trained checkpoint from: /data/nguyent8/EyeAI_working/4-S412/asset/4-NKSJ_uncropped_Mar_09_2025.pth\n",
      "[00:48:39.646242] [00:48:39.646233] [00:48:39.646260] Removing key head.weight from pretrained checkpoint\n",
      "[00:48:39.646278] [00:48:39.646275] [00:48:39.646289] Removing key head.bias from pretrained checkpoint\n",
      "[00:48:39.785767] [00:48:39.785752] [00:48:39.785794] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f126816b400>\n",
      "[00:48:39.803698] [00:48:39.803689] [00:48:39.803718] len of train_set: 1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyent8/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:48:40.239712] [00:48:40.239691] [00:48:40.239812] number of model params (M): 303.30\n",
      "[00:48:40.239842] [00:48:40.239839] [00:48:40.239854] base lr: 5.00e-03\n",
      "[00:48:40.239873] [00:48:40.239870] [00:48:40.239884] actual lr: 3.13e-04\n",
      "[00:48:40.239900] [00:48:40.239897] [00:48:40.239911] accumulate grad iterations: 1\n",
      "[00:48:40.239925] [00:48:40.239923] [00:48:40.239937] effective batch size: 16\n",
      "[00:48:40.244721] [00:48:40.244713] [00:48:40.244740] criterion = CrossEntropyLoss()\n",
      "[00:48:40.244759] [00:48:40.244755] [00:48:40.244770] Start training for 100 epochs\n",
      "[00:48:40.270528] [00:48:40.270520] [00:48:40.270547] log_dir: /data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction\n",
      "[00:48:51.708280] [00:48:51.708249] [00:48:51.708480] Epoch: [0]  [ 0/68]  eta: 0:12:57  lr: 0.000000  loss: 0.6932 (0.6932)  time: 11.4303  data: 7.5269  max mem: 4706\n",
      "[00:48:57.003841] [00:48:57.003827] [00:48:57.010499] Epoch: [0]  [20/68]  eta: 0:00:38  lr: 0.000009  loss: 0.6921 (0.6909)  time: 0.2647  data: 0.0025  max mem: 6824\n",
      "[00:49:06.279843] [00:49:06.279829] [00:49:06.279947] Epoch: [0]  [40/68]  eta: 0:00:17  lr: 0.000018  loss: 0.6730 (0.6832)  time: 0.4634  data: 0.1926  max mem: 6824\n",
      "[00:49:16.307176] [00:49:16.307162] [00:49:16.307444] Epoch: [0]  [60/68]  eta: 0:00:04  lr: 0.000028  loss: 0.6402 (0.6680)  time: 0.5013  data: 0.2334  max mem: 6824\n",
      "[00:49:17.942991] [00:49:17.942979] [00:49:17.943074] Epoch: [0]  [67/68]  eta: 0:00:00  lr: 0.000031  loss: 0.5949 (0.6606)  time: 0.3976  data: 0.1471  max mem: 6824\n",
      "[00:49:18.536499] [00:49:18.536488] [00:49:18.536582] Epoch: [0] Total time: 0:00:38 (0.5627 s / it)\n",
      "[00:49:18.536797] [00:49:18.536791] [00:49:18.536811] Averaged stats: lr: 0.000031  loss: 0.5949 (0.6606)\n",
      "[00:49:25.796001] [00:49:25.795981] [00:49:25.796564] val:  [ 0/34]  eta: 0:04:06  loss: 0.3667 (0.3667)  time: 7.2556  data: 7.1183  max mem: 6824\n",
      "[00:49:33.539922] [00:49:33.539907] [00:49:33.540032] val:  [10/34]  eta: 0:00:32  loss: 0.3887 (0.3882)  time: 1.3635  data: 1.2912  max mem: 6824\n",
      "[00:49:39.805357] [00:49:39.805343] [00:49:39.805463] val:  [20/34]  eta: 0:00:14  loss: 0.3878 (0.3885)  time: 0.7003  data: 0.6356  max mem: 6824\n",
      "[00:49:42.022157] [00:49:42.022144] [00:49:42.022469] val:  [30/34]  eta: 0:00:03  loss: 0.3942 (0.5080)  time: 0.4240  data: 0.3653  max mem: 6824\n",
      "[00:49:42.311207] [00:49:42.311196] [00:49:42.311298] val:  [33/34]  eta: 0:00:00  loss: 0.3979 (0.5616)  time: 0.4284  data: 0.3657  max mem: 6824\n",
      "[00:49:42.913795] [00:49:42.913785] [00:49:42.913880] val: Total time: 0:00:24 (0.7169 s / it)\n",
      "[00:49:42.946793] [00:49:42.946784] [00:49:42.946815] val loss: 0.5616001802332261\n",
      "[00:49:42.946841] [00:49:42.946838] [00:49:42.946853] Accuracy: 0.7561, F1 Score: 0.4451, ROC AUC: 0.6214, Hamming Loss: 0.2439,\n",
      " Jaccard Score: 0.3851, Precision: 0.5069, Recall: 0.5006,\n",
      " Average Precision: 0.5828, Kappa: 0.0016, Score: 0.3560\n",
      "[00:49:45.806414] [00:49:45.806384] [00:49:45.806506] Best epoch = 0, Best score = 0.3560\n",
      "[00:49:45.817996] [00:49:45.817989] [00:49:45.818015] log_dir: /data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyent8/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:49:53.718670] [00:49:53.718561] [00:49:53.718877] Epoch: [1]  [ 0/68]  eta: 0:08:55  lr: 0.000031  loss: 0.7058 (0.7058)  time: 7.8799  data: 7.6101  max mem: 6824\n",
      "[00:50:03.719582] [00:50:03.719569] [00:50:03.719688] Epoch: [1]  [20/68]  eta: 0:00:40  lr: 0.000040  loss: 0.6545 (0.6587)  time: 0.5000  data: 0.2178  max mem: 6824\n",
      "[00:50:14.412081] [00:50:14.412065] [00:50:14.412185] Epoch: [1]  [40/68]  eta: 0:00:19  lr: 0.000050  loss: 0.6506 (0.6505)  time: 0.5345  data: 0.2588  max mem: 6824\n",
      "[00:50:23.535389] [00:50:23.535377] [00:50:23.535473] Epoch: [1]  [60/68]  eta: 0:00:04  lr: 0.000059  loss: 0.6272 (0.6431)  time: 0.4561  data: 0.1926  max mem: 6824\n",
      "[00:50:25.102832] [00:50:25.102820] [00:50:25.102924] Epoch: [1]  [67/68]  eta: 0:00:00  lr: 0.000062  loss: 0.5869 (0.6363)  time: 0.3933  data: 0.1527  max mem: 6824\n",
      "[00:50:25.718266] [00:50:25.718253] [00:50:25.718347] Epoch: [1] Total time: 0:00:39 (0.5868 s / it)\n",
      "[00:50:25.718577] [00:50:25.718570] [00:50:25.718593] Averaged stats: lr: 0.000062  loss: 0.5869 (0.6363)\n",
      "[00:50:33.050187] [00:50:33.050163] [00:50:33.050368] val:  [ 0/34]  eta: 0:04:09  loss: 0.3024 (0.3024)  time: 7.3270  data: 7.2262  max mem: 6824\n",
      "[00:50:41.005633] [00:50:41.005620] [00:50:41.005742] val:  [10/34]  eta: 0:00:33  loss: 0.3185 (0.3270)  time: 1.3892  data: 1.3195  max mem: 6824\n",
      "[00:50:47.281190] [00:50:47.281176] [00:50:47.281298] val:  [20/34]  eta: 0:00:14  loss: 0.3247 (0.3283)  time: 0.7114  data: 0.6448  max mem: 6824\n",
      "[00:50:49.340100] [00:50:49.340087] [00:50:49.340198] val:  [30/34]  eta: 0:00:03  loss: 0.3341 (0.4732)  time: 0.4166  data: 0.3542  max mem: 6824\n",
      "[00:50:49.735053] [00:50:49.735042] [00:50:49.735144] val:  [33/34]  eta: 0:00:00  loss: 0.3506 (0.5398)  time: 0.4193  data: 0.3591  max mem: 6824\n",
      "[00:50:50.357857] [00:50:50.357846] [00:50:50.357947] val: Total time: 0:00:24 (0.7246 s / it)\n",
      "[00:50:50.398962] [00:50:50.398950] [00:50:50.398989] val loss: 0.5398166635457207\n",
      "[00:50:50.399015] [00:50:50.399012] [00:50:50.399027] Accuracy: 0.7561, F1 Score: 0.4653, ROC AUC: 0.6969, Hamming Loss: 0.2439,\n",
      " Jaccard Score: 0.3953, Precision: 0.5619, Recall: 0.5087,\n",
      " Average Precision: 0.6354, Kappa: 0.0251, Score: 0.3957\n",
      "[00:50:53.215696] [00:50:53.215678] [00:50:53.215788] Best epoch = 1, Best score = 0.3957\n",
      "[00:50:53.226625] [00:50:53.226617] [00:50:53.226644] log_dir: /data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyent8/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:51:01.772572] [00:51:01.772500] [00:51:01.773144] Epoch: [2]  [ 0/68]  eta: 0:09:40  lr: 0.000063  loss: 0.7389 (0.7389)  time: 8.5414  data: 8.2374  max mem: 6824\n",
      "[00:51:12.916969] [00:51:12.916951] [00:51:12.917095] Epoch: [2]  [20/68]  eta: 0:00:44  lr: 0.000072  loss: 0.6132 (0.6517)  time: 0.5569  data: 0.2575  max mem: 6824\n",
      "[00:51:23.660082] [00:51:23.660067] [00:51:23.660189] Epoch: [2]  [40/68]  eta: 0:00:20  lr: 0.000081  loss: 0.6215 (0.6399)  time: 0.5371  data: 0.2209  max mem: 6824\n",
      "[00:51:34.398277] [00:51:34.398264] [00:51:34.398368] Epoch: [2]  [60/68]  eta: 0:00:05  lr: 0.000090  loss: 0.5745 (0.6289)  time: 0.5368  data: 0.2572  max mem: 6824\n",
      "[00:51:35.975231] [00:51:35.975219] [00:51:35.975327] Epoch: [2]  [67/68]  eta: 0:00:00  lr: 0.000093  loss: 0.5614 (0.6243)  time: 0.4702  data: 0.2125  max mem: 6824\n",
      "[00:51:36.644338] [00:51:36.644327] [00:51:36.644421] Epoch: [2] Total time: 0:00:43 (0.6385 s / it)\n",
      "[00:51:36.644662] [00:51:36.644653] [00:51:36.644681] Averaged stats: lr: 0.000093  loss: 0.5614 (0.6243)\n",
      "[00:51:43.762487] [00:51:43.762464] [00:51:43.762665] val:  [ 0/34]  eta: 0:04:01  loss: 0.2490 (0.2490)  time: 7.1140  data: 7.0520  max mem: 6824\n",
      "[00:51:52.427410] [00:51:52.427396] [00:51:52.427665] val:  [10/34]  eta: 0:00:34  loss: 0.3055 (0.3172)  time: 1.4342  data: 1.3713  max mem: 6824\n",
      "[00:51:58.669544] [00:51:58.669530] [00:51:58.669805] val:  [20/34]  eta: 0:00:14  loss: 0.3177 (0.3211)  time: 0.7452  data: 0.6684  max mem: 6824\n",
      "[00:52:01.146751] [00:52:01.146737] [00:52:01.146852] val:  [30/34]  eta: 0:00:03  loss: 0.3501 (0.4511)  time: 0.4358  data: 0.3623  max mem: 6824\n",
      "[00:52:01.529637] [00:52:01.529626] [00:52:01.529727] val:  [33/34]  eta: 0:00:00  loss: 0.4061 (0.5169)  time: 0.4432  data: 0.3744  max mem: 6824\n",
      "[00:52:02.097478] [00:52:02.097467] [00:52:02.097556] val: Total time: 0:00:25 (0.7485 s / it)\n",
      "[00:52:02.121653] [00:52:02.121645] [00:52:02.121676] val loss: 0.5169191781212302\n",
      "[00:52:02.121702] [00:52:02.121698] [00:52:02.121715] Accuracy: 0.7616, F1 Score: 0.5908, ROC AUC: 0.7265, Hamming Loss: 0.2384,\n",
      " Jaccard Score: 0.4710, Precision: 0.6448, Recall: 0.5830,\n",
      " Average Precision: 0.6564, Kappa: 0.2010, Score: 0.5061\n",
      "[00:52:04.027476] [00:52:04.027458] [00:52:04.027574] Best epoch = 2, Best score = 0.5061\n",
      "[00:52:04.034925] [00:52:04.034917] [00:52:04.034944] log_dir: /data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyent8/.conda/envs/my-tensorflow-conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:11.661182] [00:52:11.661164] [00:52:11.661475] Epoch: [3]  [ 0/68]  eta: 0:08:38  lr: 0.000094  loss: 0.7939 (0.7939)  time: 7.6251  data: 7.3600  max mem: 6824\n",
      "[00:52:21.429977] [00:52:21.429963] [00:52:21.439980] Epoch: [3]  [20/68]  eta: 0:00:39  lr: 0.000103  loss: 0.6197 (0.6390)  time: 0.4884  data: 0.2089  max mem: 6824\n",
      "[00:52:31.675799] [00:52:31.675785] [00:52:31.676063] Epoch: [3]  [40/68]  eta: 0:00:18  lr: 0.000112  loss: 0.6293 (0.6368)  time: 0.5117  data: 0.2339  max mem: 6824\n",
      "[00:52:41.359640] [00:52:41.359627] [00:52:41.359900] Epoch: [3]  [60/68]  eta: 0:00:04  lr: 0.000121  loss: 0.5466 (0.6203)  time: 0.4841  data: 0.2139  max mem: 6824\n"
     ]
    }
   ],
   "source": [
    "from main_finetune import main, get_args_parser \n",
    "import torch\n",
    "\n",
    "with execution.execute() as exec:\n",
    "    args_list = [\n",
    "        \"--model\", \"RETFound_mae\",\n",
    "        \"--savemodel\",\n",
    "        \"--global_pool\",\n",
    "        \"--batch_size\", \"16\",\n",
    "        \"--world_size\", \"1\",\n",
    "        \"--epochs\", \"100\",\n",
    "        \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "        \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "        \"--nb_classes\", \"2\",\n",
    "        \"--data_path\", \"/data/nguyent8/EyeAI_working/\",\n",
    "        \"--input_size\", \"224\",\n",
    "        \"--task\", str(asset_path_output),\n",
    "        \"--output_dir\", str(asset_path_output),\n",
    "        \"--finetune\", str(retfound_pretrained_weight),\n",
    "    ]\n",
    "\n",
    "    args = get_args_parser().parse_args(args_list)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    main(args, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:42.597745] [09:33:42.597728] [09:33:42.597915] /data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction\n"
     ]
    }
   ],
   "source": [
    "print(str(asset_path_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_diagnosis_train import train_and_evaluate\n",
    "with execution.execute() as exec:\n",
    "        predictions_results, metrics_summary, model_save_path, training_history_csv = train_and_evaluate(\n",
    "            train_path=train_dir,\n",
    "            valid_path=val_dir, \n",
    "            test_path=test_dir, \n",
    "            model_path=asset_path_models,\n",
    "            log_path=asset_path_logs,\n",
    "            eval_path=asset_path_output,\n",
    "            model_name = f\"VGG19_Multimodal_{current_date}\",\n",
    "            classes = classes,\n",
    "            )\n",
    "        print(\"Execution Results:\")\n",
    "        print(predictions_results, metrics_summary, model_save_path, training_history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredictions_results\u001b[49m, metrics_summary, model_save_path, training_history_csv)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions_results' is not defined"
     ]
    }
   ],
   "source": [
    "print(predictions_results, metrics_summary, model_save_path, training_history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 09:34:08,087 - INFO - Initializing uploader: GenericUploader v1.7.7 [Python 3.10.13, Linux-5.10.210-201.852.amzn2.x86_64-x86_64-with-glibc2.26]\n",
      "2025-03-24 09:34:08,141 - INFO - Scanning files in directory [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412]...\n",
      "2025-03-24 09:34:08,146 - INFO - Skipping file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/events.out.tfevents.1742802519.compute.eye-ai.org.12203.0] -- Invalid file type or directory location.\n",
      "2025-03-24 09:34:08,147 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Execution_Config/configuration.json].\n",
      "2025-03-24 09:34:08,148 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/environment_snapshot_ne8wqm2a.txt].\n",
      "2025-03-24 09:34:08,148 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint].\n",
      "2025-03-24 09:34:08,149 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_val.csv].\n",
      "2025-03-24 09:34:08,150 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/checkpoint-best.pth].\n",
      "2025-03-24 09:34:08,150 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/log.txt].\n",
      "2025-03-24 09:34:08,151 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_test.csv].\n",
      "2025-03-24 09:34:08,151 - INFO - Including file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/confusion_matrix_test.jpg].\n",
      "2025-03-24 09:34:08,152 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Execution_Config/configuration.json]\n",
      "2025-03-24 09:34:08,153 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Execution_Config/configuration.json].\n",
      "2025-03-24 09:34:08,154 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Execution_Config/configuration.json]. Please wait...\n",
      "2025-03-24 09:34:08,173 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Execution_Config/configuration.json] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:08,718 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/environment_snapshot_ne8wqm2a.txt]\n",
      "2025-03-24 09:34:08,719 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/environment_snapshot_ne8wqm2a.txt].\n",
      "2025-03-24 09:34:08,719 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/environment_snapshot_ne8wqm2a.txt]. Please wait...\n",
      "2025-03-24 09:34:08,745 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/environment_snapshot_ne8wqm2a.txt] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:09,043 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint]\n",
      "2025-03-24 09:34:09,044 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint].\n",
      "2025-03-24 09:34:09,045 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint]. Please wait...\n",
      "2025-03-24 09:34:09,061 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-metadata/Runtime_Env/Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:09,182 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_val.csv]\n",
      "2025-03-24 09:34:09,183 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_val.csv].\n",
      "2025-03-24 09:34:09,183 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_val.csv]. Please wait...\n",
      "2025-03-24 09:34:09,195 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_val.csv] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:09,343 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/checkpoint-best.pth]\n",
      "2025-03-24 09:34:09,344 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/checkpoint-best.pth].\n",
      "2025-03-24 09:34:09,344 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/checkpoint-best.pth]. Please wait...\n",
      "2025-03-24 09:34:17,637 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/checkpoint-best.pth] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:44,797 - INFO - File [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/checkpoint-best.pth] upload successful. 1157.12 MB transferred at 42.83 MB/second. Elapsed time: 0:00:27.018808.\n",
      "2025-03-24 09:34:45,020 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/log.txt]\n",
      "2025-03-24 09:34:45,021 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/log.txt].\n",
      "2025-03-24 09:34:45,021 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/log.txt]. Please wait...\n",
      "2025-03-24 09:34:45,037 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/log.txt] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:45,154 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_test.csv]\n",
      "2025-03-24 09:34:45,154 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_test.csv].\n",
      "2025-03-24 09:34:45,155 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_test.csv]. Please wait...\n",
      "2025-03-24 09:34:45,168 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/metrics_test.csv] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:45,263 - INFO - Processing: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/confusion_matrix_test.jpg]\n",
      "2025-03-24 09:34:45,264 - INFO - Computed metadata for: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/confusion_matrix_test.jpg].\n",
      "2025-03-24 09:34:45,264 - INFO - Computing checksums for file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/confusion_matrix_test.jpg]. Please wait...\n",
      "2025-03-24 09:34:45,275 - INFO - Uploading file: [/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/confusion_matrix_test.jpg] to host https://www.eye-ai.org. Please wait...\n",
      "2025-03-24 09:34:45,451 - WARNING - The following 1 file(s) were skipped because they did not satisfy the matching criteria of the configuration:\n",
      "\n",
      "/data/nguyent8/EyeAI_working/deriva-ml/execution/4-S412/execution-asset/Model_Prediction/events.out.tfevents.1742802519.compute.eye-ai.org.12203.0\n",
      "\n",
      "2025-03-24 09:34:45,452 - INFO - File upload processing completed: 8 files were uploaded successfully, 0 files failed to upload due to errors, 1 files were skipped because they did not satisfy the matching criteria of the configuration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Execution_Config/configuration.json': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_metadata/65d8686c5e76717066c6aaff1a1e606f.configuration.json:bWQ0z9I5CM.S3GrckFzgji2pb1VGqtaM', 'RID': '4-S41C', 'RCT': '2025-03-24T16:34:08.656474+00:00', 'RMT': '2025-03-24T16:34:08.656474+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'configuration.json', 'Description': None, 'Length': 500, 'MD5': '65d8686c5e76717066c6aaff1a1e606f', 'Execution_Metadata_Type': 'Execution_Config'}, rid='4-S41C'),\n",
       " 'Runtime_Env/environment_snapshot_ne8wqm2a.txt': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_metadata/40971cca3301a88d64b75ef8964cd2f1.environment_snapshot_ne8wqm2a.txt:w1TT16Lv20XXERSUyucRSQ.hiesRgluS', 'RID': '4-S41E', 'RCT': '2025-03-24T16:34:08.999145+00:00', 'RMT': '2025-03-24T16:34:08.999145+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'environment_snapshot_ne8wqm2a.txt', 'Description': None, 'Length': 13274, 'MD5': '40971cca3301a88d64b75ef8964cd2f1', 'Execution_Metadata_Type': 'Runtime_Env'}, rid='4-S41E'),\n",
       " 'Runtime_Env/Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_metadata/4e2dc91e1c7ec35a0dce036cb8da1af2.Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint:wjJLqKqOQ_eWOYHFFFtihzTMGPvaLh3E', 'RID': '4-S41G', 'RCT': '2025-03-24T16:34:09.150789+00:00', 'RMT': '2025-03-24T16:34:09.150789+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'Repos_eye-ai-exec_notebooks_Multimodal_Huy_multimodal_glaucoma_vs_suspected.ipynb.checkpoint', 'Description': None, 'Length': 44977, 'MD5': '4e2dc91e1c7ec35a0dce036cb8da1af2', 'Execution_Metadata_Type': 'Runtime_Env'}, rid='4-S41G'),\n",
       " 'Model_Prediction/metrics_val.csv': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_asset/8dbca4be1b9326401601236a4ac0de72.metrics_val.csv:YQf0eAPFkaU054Kv.ofZw5xzqwAfksdK', 'RID': '4-S41J', 'RCT': '2025-03-24T16:34:09.287382+00:00', 'RMT': '2025-03-24T16:34:09.287382+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'metrics_val.csv', 'Description': None, 'Length': 19212, 'MD5': '8dbca4be1b9326401601236a4ac0de72', 'Execution_Asset_Type': 'Model_Prediction'}, rid='4-S41J'),\n",
       " 'Model_Prediction/checkpoint-best.pth': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_asset/51d71d94765ec1699cc037a4103ad49d.checkpoint-best.pth:hVdTL77jsi1KFDIWmHM7YCNPzW90aCy5', 'RID': '4-S41M', 'RCT': '2025-03-24T16:34:44.986845+00:00', 'RMT': '2025-03-24T16:34:44.986845+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'checkpoint-best.pth', 'Description': None, 'Length': 1213332290, 'MD5': '51d71d94765ec1699cc037a4103ad49d', 'Execution_Asset_Type': 'Model_Prediction'}, rid='4-S41M'),\n",
       " 'Model_Prediction/log.txt': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_asset/38f63b21974c1bc3781ff7ed7256962e.log.txt:9.JrudP6uiEer1OtGQzDdlHTBaqLbzec', 'RID': '4-S41P', 'RCT': '2025-03-24T16:34:45.113892+00:00', 'RMT': '2025-03-24T16:34:45.113892+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'log.txt', 'Description': None, 'Length': 11062, 'MD5': '38f63b21974c1bc3781ff7ed7256962e', 'Execution_Asset_Type': 'Model_Prediction'}, rid='4-S41P'),\n",
       " 'Model_Prediction/metrics_test.csv': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_asset/8821b070f2ad5d3794f7eb4682a04b19.metrics_test.csv:Kk4nyW2Vz.2RDOHduNTZbgSDt.1NBVUx', 'RID': '4-S41R', 'RCT': '2025-03-24T16:34:45.242802+00:00', 'RMT': '2025-03-24T16:34:45.242802+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'metrics_test.csv', 'Description': None, 'Length': 279, 'MD5': '8821b070f2ad5d3794f7eb4682a04b19', 'Execution_Asset_Type': 'Model_Prediction'}, rid='4-S41R'),\n",
       " 'Model_Prediction/confusion_matrix_test.jpg': FileUploadState(state=<UploadState.success: 0>, status='Complete', result={'URL': '/hatrac/execution_asset/211246d12d4c2e769e9c8157307fe159.confusion_matrix_test.jpg:2ahtxphjO4Kc78P99kF3gWGeDbcgj0.u', 'RID': '4-S41T', 'RCT': '2025-03-24T16:34:45.43239+00:00', 'RMT': '2025-03-24T16:34:45.43239+00:00', 'RCB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'RMB': 'https://auth.globus.org/2f447519-873e-447c-931d-27dbed78582e', 'Filename': 'confusion_matrix_test.jpg', 'Description': None, 'Length': 260026, 'MD5': '211246d12d4c2e769e9c8157307fe159', 'Execution_Asset_Type': 'Model_Prediction'}, rid='4-S41T')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
