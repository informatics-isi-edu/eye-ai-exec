{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install pytorch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 pytorch-cuda=12.1 -c pytorch -c nvidia -y\n",
    "!cd ~/Repos && git clone --branch eye-ai-compatible https://github.com/huynguyentran/RETFound_MAE.git \n",
    "!cd ~/Repos/RETFound_MAE && git pull\n",
    "!cd ~/Repos/RETFound_MAE && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Should print \"12.1\"\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # Should print \"NVIDIA A10G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"Repos\"   # Set this to be where your github repos are located.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Update the load path so python can find modules for the model\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-ml\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"eye-ai-exec\" / \"models\" / \"vgg19\"))\n",
    "sys.path.insert(0, str(Path.home() / repo_dir / \"RETFound_MAE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "import json\n",
    "import os\n",
    "from eye_ai.eye_ai import EyeAI\n",
    "import pandas as pd\n",
    "from pathlib import Path, PurePath\n",
    "import logging\n",
    "\n",
    "from deriva_ml import DatasetBag, Workflow, ExecutionConfiguration, DatasetVersion\n",
    "from deriva_ml import MLVocab as vc\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "catalog_id = \"eye-ai\" #@param\n",
    "host = 'www.eye-ai.org'\n",
    "\n",
    "\n",
    "gnl = GlobusNativeLogin(host=host)\n",
    "if gnl.is_logged_in([host]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/data'\n",
    "working_dir = '/data'\n",
    "EA = EyeAI(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    '4-4116', # Selected images for training\n",
    "    '4-411G', # Selected images for testing\n",
    "    '2-7P5P', # Full multimodal dataset\n",
    "    ]\n",
    "\n",
    "to_be_download = []\n",
    "for dataset in datasets:\n",
    "    ds_dict = {\n",
    "        'rid': dataset,\n",
    "        'materialize':True,\n",
    "        'version':EA.dataset_version(dataset_rid=dataset),\n",
    "    }\n",
    "    to_be_download.append(ds_dict)\n",
    "\n",
    "workflow_instance = EA.create_workflow(\n",
    "    name=\"Multimodal workflow\",\n",
    "    workflow_type=\"Multimodal workflow\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=to_be_download,\n",
    "    assets = ['4-S4TJ',],\n",
    "    workflow=workflow_instance,\n",
    "    description=\"Instance of applying CV modelsto multimodal data. We are attempting to increase the accuracy of prediction by including table values into images prediction.\")\n",
    "\n",
    "execution = EA.create_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds_bag = execution.datasets[0]\n",
    "testing_ds_bag = execution.datasets[1]\n",
    "\n",
    "multimodal_full_ds_bag = execution.datasets[2]\n",
    "retfound_pretrained_weight = execution.asset_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_bag(ds_bag: DatasetBag, multimodal_full_ds_bag: DatasetBag):\n",
    "    observation_table = ds_bag.get_table_as_dataframe('Observation')\n",
    "    image_table = ds_bag.get_table_as_dataframe('Image')\n",
    "    laterality_table = ds_bag.get_table_as_dataframe('Execution_Image_Fundus_Laterality')\n",
    "\n",
    "    image_table_filtered = image_table[['RID', 'Filename', 'Observation']].rename(columns={'RID': 'RID_Image'})\n",
    "    laterality_table_filtered = laterality_table[['Image', 'Image_Side']].rename(columns={'Image': 'RID_Image'})\n",
    "    image_laterality = pd.merge(image_table_filtered, laterality_table_filtered, left_on='RID_Image', right_on='RID_Image', how='inner')\n",
    "    observation_table_filtered = observation_table[['RID',  'Subject']].rename(columns={'RID': 'RID_Observation'})\n",
    "    image_laterality_observation = pd.merge(image_laterality, observation_table_filtered, left_on='Observation', right_on='RID_Observation', how='inner')\n",
    "\n",
    "    wide = EA.multimodal_wide(multimodal_full_ds_bag) \n",
    "\n",
    "    image_observation_laterality_subject_wide = pd.merge(\n",
    "     wide, \n",
    "     image_laterality_observation, \n",
    "     left_on=['RID_Subject', 'Image_Side'], \n",
    "     right_on=['Subject', 'Image_Side'], \n",
    "     how='inner'\n",
    "    )\n",
    "\n",
    "    return image_observation_laterality_subject_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_dataframe_from_bag(training_ds_bag, multimodal_full_ds_bag)\n",
    "test_df= get_dataframe_from_bag(testing_ds_bag, multimodal_full_ds_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_df = train_df[['RID_Image', 'Filename','Condition_Label', 'Condition_Display']]\n",
    "filtered_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_df = test_df[['RID_Image', 'Filename','Condition_Label', 'Condition_Display']]\n",
    "filtered_test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = execution._working_dir / execution.execution_rid\n",
    "working_dir.mkdir(parents=True, exist_ok=True)\n",
    "working_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    \"0_Glaucoma_Suspect\": 0,\n",
    "    \"1_Glaucoma\": 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "\n",
    "def create_dataset_folder(df, output_path, output_name):\n",
    "    output_path =  output_path / output_name\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_path_suspected = output_path / \"0_Glaucoma_Suspect\"\n",
    "    output_path_glaucoma = output_path / \"1_Glaucoma\"\n",
    "    \n",
    "    output_path_suspected.mkdir(parents=True, exist_ok=True)\n",
    "    output_path_glaucoma.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    for index, row in df.iterrows():     \n",
    "        src_path = row[\"Filename\"]\n",
    "        dest_name = row[\"RID_Image\"] + \".jpg\"\n",
    "        label = row['Condition_Label']\n",
    "        if label == \"GS\":\n",
    "            dest_path = os.path.join(output_path_suspected, dest_name)\n",
    "        elif label == \"POAG\" or label == \"PACG\":\n",
    "            dest_path = os.path.join(output_path_glaucoma, dest_name)\n",
    "        else: \n",
    "            continue    \n",
    "        shutil.copy2(src_path, dest_path)\n",
    "        \n",
    "    return output_path \n",
    "\n",
    "train_dir = create_dataset_folder(filtered_train_df, working_dir, \"train\")\n",
    "test_dir = create_dataset_folder(filtered_test_df, working_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set(train_dir, val_dir, split_ratio=0.15):\n",
    "     os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "     for class_name in os.listdir(train_dir):\n",
    "          class_train_path = os.path.join(train_dir, class_name)\n",
    "          class_val_path = os.path.join(val_dir, class_name)\n",
    "\n",
    "          if os.path.isdir(class_train_path):  \n",
    "               os.makedirs(class_val_path, exist_ok=True)\n",
    "\n",
    "               images = [f for f in os.listdir(class_train_path) if os.path.isfile(os.path.join(class_train_path, f))]\n",
    "               num_val = int(len(images) * split_ratio)\n",
    "\n",
    "               val_images = random.sample(images, num_val)\n",
    "               for img in val_images:\n",
    "                    shutil.move(os.path.join(class_train_path, img), os.path.join(class_val_path, img))\n",
    "\n",
    "val_dir = working_dir / \"val\"\n",
    "create_validation_set(train_dir, val_dir, split_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_images_per_class(directory):\n",
    "     class_counts = {}\n",
    "     for class_name in os.listdir(directory):\n",
    "          class_path = os.path.join(directory, class_name)\n",
    "          if os.path.isdir(class_path): \n",
    "               num_images = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
    "               class_counts[class_name] = num_images\n",
    "     return class_counts\n",
    "\n",
    "\n",
    "train_counts = count_images_per_class(train_dir)\n",
    "test_counts = count_images_per_class(test_dir)\n",
    "val_counts = count_images_per_class(val_dir)\n",
    "\n",
    "print(\"Training Set:\")\n",
    "for class_name, count in train_counts.items():\n",
    "     print(f\"  {class_name}: {count} images\")\n",
    "\n",
    "print(\"\\nValidation Set:\")\n",
    "for class_name, count in test_counts.items():\n",
    "     print(f\"  {class_name}: {count} images\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "for class_name, count in test_counts.items():\n",
    "     print(f\"  {class_name}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_rid_images_from_folder(folder_path, df):\n",
    "    # Get all the filenames in the folder (excluding the path)\n",
    "    filenames = os.listdir(folder_path)\n",
    "    \n",
    "    # Extract the 'RID_Image' values from the DataFrame that match the filenames (without the extension)\n",
    "    rid_images_in_folder = df[df['RID_Image'].isin([os.path.splitext(f)[0] for f in filenames])]\n",
    "    \n",
    "    return rid_images_in_folder\n",
    "\n",
    "# Example usage for the 'train_dir', 'val_dir', and 'test_dir' folders:\n",
    "\n",
    "# For train directory\n",
    "train_glaucoma_suspect_folder = os.path.join(train_dir, \"Glaucoma_Suspect\")\n",
    "train_glaucoma_folder = os.path.join(train_dir, \"Glaucoma\")\n",
    "\n",
    "train_glaucoma_suspect_rid_images = get_rid_images_from_folder(train_glaucoma_suspect_folder, filtered_train_df)\n",
    "train_glaucoma_rid_images = get_rid_images_from_folder(train_glaucoma_folder, filtered_train_df)\n",
    "\n",
    "# For validation directory\n",
    "val_glaucoma_suspect_folder = os.path.join(val_dir, \"Glaucoma_Suspect\")\n",
    "val_glaucoma_folder = os.path.join(val_dir, \"Glaucoma\")\n",
    "\n",
    "val_glaucoma_suspect_rid_images = get_rid_images_from_folder(val_glaucoma_suspect_folder, filtered_train_df)\n",
    "val_glaucoma_rid_images = get_rid_images_from_folder(val_glaucoma_folder, filtered_train_df)\n",
    "\n",
    "# For test directory\n",
    "test_glaucoma_suspect_folder = os.path.join(test_dir, \"Glaucoma_Suspect\")\n",
    "test_glaucoma_folder = os.path.join(test_dir, \"Glaucoma\")\n",
    "\n",
    "test_glaucoma_suspect_rid_images = get_rid_images_from_folder(test_glaucoma_suspect_folder, filtered_test_df)\n",
    "test_glaucoma_rid_images = get_rid_images_from_folder(test_glaucoma_folder, filtered_test_df)\n",
    "\n",
    "# Convert 'RID_Image' column to lists\n",
    "train_glaucoma_suspect_rid_images_list = train_glaucoma_suspect_rid_images['RID_Image'].tolist()\n",
    "train_glaucoma_rid_images_list = train_glaucoma_rid_images['RID_Image'].tolist()\n",
    "\n",
    "val_glaucoma_suspect_rid_images_list = val_glaucoma_suspect_rid_images['RID_Image'].tolist()\n",
    "val_glaucoma_rid_images_list = val_glaucoma_rid_images['RID_Image'].tolist()\n",
    "\n",
    "test_glaucoma_suspect_rid_images_list = test_glaucoma_suspect_rid_images['RID_Image'].tolist()\n",
    "test_glaucoma_rid_images_list = test_glaucoma_rid_images['RID_Image'].tolist()\n",
    "\n",
    "\n",
    "def save_to_text_file(file_path, data_list):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in data_list:\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "# Save 'RID_Image' lists to text files\n",
    "save_to_text_file(\"train_glaucoma_suspect_rid_images.txt\", train_glaucoma_suspect_rid_images_list)\n",
    "save_to_text_file(\"train_glaucoma_rid_images.txt\", train_glaucoma_rid_images_list)\n",
    "\n",
    "save_to_text_file(\"val_glaucoma_suspect_rid_images.txt\", val_glaucoma_suspect_rid_images_list)\n",
    "save_to_text_file(\"val_glaucoma_rid_images.txt\", val_glaucoma_rid_images_list)\n",
    "\n",
    "save_to_text_file(\"test_glaucoma_suspect_rid_images.txt\", test_glaucoma_suspect_rid_images_list)\n",
    "save_to_text_file(\"test_glaucoma_rid_images.txt\", test_glaucoma_rid_images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path_models = execution.execution_asset_path(\"Diagnosis_Model\")\n",
    "asset_path_output = execution.execution_asset_path(\"Model_Prediction\")\n",
    "asset_path_logs = execution.execution_asset_path(\"Training_Log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%b_%d_%Y\") \n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, val_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_finetune import main, get_args_parser \n",
    "import torch\n",
    "\n",
    "# Train\n",
    "with execution.execute() as exec:\n",
    "    args_list = [\n",
    "        \"--model\", \"RETFound_mae\",\n",
    "        \"--savemodel\",\n",
    "        \"--global_pool\",\n",
    "        \"--batch_size\", \"16\",\n",
    "        \"--world_size\", \"1\",\n",
    "        \"--epochs\", \"100\",\n",
    "        \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "        \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "        \"--nb_classes\", \"2\",\n",
    "        \"--data_path\", \"/data/nguyent8/EyeAI_working/\",\n",
    "        \"--input_size\", \"224\",\n",
    "        \"--task\", str(asset_path_output),\n",
    "        \"--output_dir\", str(asset_path_output),\n",
    "        \"--finetune\", str(retfound_pretrained_weight),\n",
    "    ]\n",
    "\n",
    "    args = get_args_parser().parse_args(args_list)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    main(args, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_finetune import main, get_args_parser \n",
    "import torch\n",
    "\n",
    "#Eval\n",
    "with execution.execute() as exec:\n",
    "    args_list = [\n",
    "        \"--model\", \"RETFound_mae\",\n",
    "        \"--savemodel\",\n",
    "        \"--eval\",\n",
    "        \"--global_pool\",\n",
    "        \"--batch_size\", \"16\",\n",
    "        \"--world_size\", \"1\",\n",
    "        \"--epochs\", \"100\",\n",
    "        \"--blr\", \"5e-3\", \"--layer_decay\", \"0.65\",\n",
    "        \"--weight_decay\", \"0.05\", \"--drop_path\", \"0.2\",\n",
    "        \"--nb_classes\", \"2\",\n",
    "        \"--data_path\", \"/data/nguyent8/EyeAI_working/\",\n",
    "        \"--input_size\", \"224\",\n",
    "        \"--task\", str(asset_path_output),\n",
    "        \"--output_dir\", str(asset_path_output),\n",
    "        \"--resume\", str(retfound_pretrained_weight),\n",
    "    ]\n",
    "\n",
    "    args = get_args_parser().parse_args(args_list)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if args.output_dir:\n",
    "        Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    main(args, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(asset_path_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg19_diagnosis_train import train_and_evaluate\n",
    "with execution.execute() as exec:\n",
    "        predictions_results, metrics_summary, model_save_path, training_history_csv = train_and_evaluate(\n",
    "            train_path=train_dir,\n",
    "            valid_path=val_dir, \n",
    "            test_path=test_dir, \n",
    "            model_path=asset_path_models,\n",
    "            log_path=asset_path_logs,\n",
    "            eval_path=asset_path_output,\n",
    "            model_name = f\"VGG19_Multimodal_{current_date}\",\n",
    "            classes = classes,\n",
    "            )\n",
    "        print(\"Execution Results:\")\n",
    "        print(predictions_results, metrics_summary, model_save_path, training_history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions_results, metrics_summary, model_save_path, training_history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.upload_execution_outputs(clean_folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My TensorFlow (Conda)",
   "language": "python",
   "name": "my-tensorflow-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
